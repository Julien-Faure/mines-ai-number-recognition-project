{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c0b8e1d",
   "metadata": {},
   "source": [
    "# Rapport du projet de résolution de problème\n",
    "\n",
    "- Paul Achard\n",
    "- Julien Faure\n",
    "\n",
    "    \n",
    "- *Date : 20/01/2022*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1070770",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42622bf2",
   "metadata": {},
   "source": [
    "## Problématique\n",
    "\n",
    "Notre problématique est d'identifier un chiffre à partir d'une image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb3a0c6",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "\n",
    "- Trouver un modèle permettant d'identifier un chiffre à partir d'une image\n",
    "- Comparer différentes stratégies de solveur pour le modèle trouvé\n",
    "\n",
    "## Analyse du dataset\n",
    "\n",
    "Identifier un chiffre à partir d'une image est une tache qui peut s'avérer très complexe. Afin d'avoir une difficulté raisonnable et adapté au contexte de ce projet, nous avons fixé certains paramètres dans notre dataset.\n",
    "\n",
    "- La résolution de nos images est identiques pour tout le dataset. Cette résolution est **8 pixels par 8 pixels**.\n",
    "- Chaque pixel est codé sur **4 bits**.\n",
    "- Les images contiennent uniquement un chiffre sans élément parasite, sans effet et sans traitement.\n",
    "\n",
    "Nous utilisons le dataset `digits` de `seaborn`.\n",
    "\n",
    "### Forme du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894968c2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n",
      "Label Data Shape (1797,)\n"
     ]
    }
   ],
   "source": [
    "# Import du dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Affiche le nombre d'images et leur format\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "\n",
    "# Affiche le nombre de labels\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311b24e7",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir ci-dessus, le dataset est composé de **1797** images labellisées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58fb1ba9",
   "metadata": {},
   "source": [
    "### Répartition des images du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1826bdc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'n° labellisé'), Text(0, 0.5, 'Occurrence')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graphique = sns.countplot(x=digits.target)\n",
    "graphique.set(xlabel=\"n° labellisé\", ylabel = \"Occurrence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee617b1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Les données labellisées sont équitablement distribuées (environ 175 par label)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc387e8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Représentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17d087b6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Création de 10 figures de 10 par 3 pixels\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(10, 3))\n",
    "\n",
    "# Pour chaque figure, on affiche l'image du chiffre et son label en titre\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_title(\"Label: %i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e6cc1",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Représentation des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb283e09",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "\n",
      " Type de chaque valeur : <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# Affiche le tableau représentant la première image\n",
    "print(digits.images[0])\n",
    "print(\"\\n Type de chaque valeur :\", type(digits.images[0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4aa72f5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> Comme nous l'avons vu précédemment, chaque image possède une résolution de 8x8 pixels en niveaux de gris codés sur 4bits par pixel.\n",
    "\n",
    "Dans notre programme, une image est représentée par une matrice de dimension 8x8. Chaque élément représente un pixel avec un niveau de gris codé sur 4bits (de 0 à 15). Plus la valeur est élevée, plus la couleur est foncée.\n",
    "\n",
    "> Exemple :\n",
    "* 0 : Blanc\n",
    "* 15 : Noir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e3675a",
   "metadata": {},
   "source": [
    "\n",
    "## Modèles\n",
    "\n",
    "Pour résoudre notre problème, nous allons essayer les modèles suivants :\n",
    "* [Modèle de regréssion logistique multiclasse](#Mod%C3%A8le-de-regr%C3%A9ssion-logistique-multiclasse)\n",
    "* [Modèle de Bayes](#Mod%C3%A8le-de-Bayes)\n",
    "\n",
    "### Mise en forme des données d'entrées\n",
    "\n",
    "Pour commencer, nous devons redimenssionner nos données d'entrées.\n",
    "\n",
    "Actuellement, nous avons des données sous la forme d'un tableau de matrice.\n",
    "\n",
    "Il nous faut les mettre sous forme d'une matrice où chaque vecteur correspond aux pixels de l'image.\n",
    "\n",
    "Donc si nous avons 1797 images, la matrice d'entrée est composée de 1797 vecteurs.\n",
    "\n",
    "Avec une résolution de 8x8, la taille d'un vecteur est de 64 valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "74b2574d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Redimensionne la matrice en vecteur\n",
    "print(digits.images[0].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10f7524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "# Redimenssionne le tableau de matrice en matrice\n",
    "x = digits.images.reshape((len(digits.images), -1))\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9331fa9",
   "metadata": {},
   "source": [
    "### Jeu de test et jeu d'entraînement\n",
    "\n",
    "Il nous faut maintenant séparer notre jeu de test et notre jeu d'entraînement du dataset.\n",
    "\n",
    "Pour choisir la taille de notre jeu de test, il est nécessaire de faire attention à plusieurs points :\n",
    "* Le temps d'entrainement de notre modèle\n",
    "* La taille de notre dataset\n",
    "\n",
    "Plus la proportion du jeu d'entraînement est faible, plus notre modèle à un niveau de variance élevé. Ainsi, on augmente les chances d'avoir de l'*over fitting*.\n",
    "\n",
    "A contrario, plus la proportion du jeu de test est faible, plus notre modèle à un niveau de variance faible. Ainsi, on augmente les chances d'avoir de l'*under fitting*.\n",
    "\n",
    "Le but est donc de trouver la valeur qui nous permet d'avoir le taux de variance optimal.\n",
    "\n",
    "\n",
    "Pour trouver cette valeur, nous avons appliqué la procédure suivante, nous avons essayé avec plusieurs valeurs en partant de 20% jusqu'à 80% avec un pas de 5%. Nous avons déterminé que la meilleure valeur est **35%**.\n",
    "\n",
    "\n",
    "> [https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio](https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de94e710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation du dataset en données \"d'apprentissage\" et de test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ad595",
   "metadata": {},
   "source": [
    "### Modèle de regréssion logistique multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc863948",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 18 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "45 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.97231332 0.97231332 0.96489613 0.96631329 0.95546507        nan\n",
      " 0.96917575 0.96917575 0.95719648 0.96631329 0.95546507        nan\n",
      " 0.96889207 0.96946187 0.95633934 0.96631329 0.95546507        nan]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.99600438 1.         1.                nan\n",
      " 1.         1.         0.99978594 1.         1.                nan\n",
      " 1.         1.         1.         1.         1.                nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.625355</td>\n",
       "      <td>0.055884</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.972313</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.618404</td>\n",
       "      <td>0.534624</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.972313</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088304</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.964896</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994647</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>0.994647</td>\n",
       "      <td>0.995722</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.992505</td>\n",
       "      <td>0.996788</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.995722</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.996788</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175708</td>\n",
       "      <td>0.020515</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.1</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'none', 'solver': 'newto...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.966313</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063431</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'none', 'solver': 'libli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.942083</td>\n",
       "      <td>0.156450</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969176</td>\n",
       "      <td>0.010046</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.515374</td>\n",
       "      <td>0.713929</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969176</td>\n",
       "      <td>0.010046</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.155098</td>\n",
       "      <td>0.028966</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.927350</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.957196</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>11</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998930</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.176597</td>\n",
       "      <td>0.013957</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 5, 'penalty': 'none', 'solver': 'newton-...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.966313</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.058872</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 5, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'penalty': 'none', 'solver': 'libline...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.118927</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.968892</td>\n",
       "      <td>0.010662</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.685158</td>\n",
       "      <td>0.901583</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969462</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.146287</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.956339</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.164898</td>\n",
       "      <td>0.021833</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'penalty': 'none', 'solver': 'newton...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.966313</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.059620</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'penalty': 'none', 'solver': 'liblin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.625355      0.055884         0.000564        0.000081     0.1   \n",
       "1        1.618404      0.534624         0.000552        0.000050     0.1   \n",
       "2        0.088304      0.008677         0.000625        0.000065     0.1   \n",
       "3        0.175708      0.020515         0.000533        0.000109     0.1   \n",
       "4        0.063431      0.005503         0.000558        0.000100     0.1   \n",
       "5        0.000475      0.000084         0.000000        0.000000     0.1   \n",
       "6        0.942083      0.156450         0.000588        0.000061       5   \n",
       "7        2.515374      0.713929         0.000547        0.000101       5   \n",
       "8        0.155098      0.028966         0.000627        0.000062       5   \n",
       "9        0.176597      0.013957         0.000550        0.000054       5   \n",
       "10       0.058872      0.006545         0.000547        0.000079       5   \n",
       "11       0.000492      0.000320         0.000000        0.000000       5   \n",
       "12       0.839482      0.118927         0.000538        0.000095      10   \n",
       "13       2.685158      0.901583         0.000560        0.000069      10   \n",
       "14       0.146287      0.017993         0.000597        0.000091      10   \n",
       "15       0.164898      0.021833         0.000528        0.000085      10   \n",
       "16       0.059620      0.004877         0.000529        0.000084      10   \n",
       "17       0.000474      0.000129         0.000000        0.000000      10   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "0             l2    newton-cg   \n",
       "1             l2        lbfgs   \n",
       "2             l2    liblinear   \n",
       "3           none    newton-cg   \n",
       "4           none        lbfgs   \n",
       "5           none    liblinear   \n",
       "6             l2    newton-cg   \n",
       "7             l2        lbfgs   \n",
       "8             l2    liblinear   \n",
       "9           none    newton-cg   \n",
       "10          none        lbfgs   \n",
       "11          none    liblinear   \n",
       "12            l2    newton-cg   \n",
       "13            l2        lbfgs   \n",
       "14            l2    liblinear   \n",
       "15          none    newton-cg   \n",
       "16          none        lbfgs   \n",
       "17          none    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...           0.978632   \n",
       "1      {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}           0.978632   \n",
       "2   {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...           0.978632   \n",
       "3   {'C': 0.1, 'penalty': 'none', 'solver': 'newto...           0.970085   \n",
       "4    {'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}           0.957265   \n",
       "5   {'C': 0.1, 'penalty': 'none', 'solver': 'libli...                NaN   \n",
       "6    {'C': 5, 'penalty': 'l2', 'solver': 'newton-cg'}           0.978632   \n",
       "7        {'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}           0.978632   \n",
       "8    {'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}           0.970085   \n",
       "9   {'C': 5, 'penalty': 'none', 'solver': 'newton-...           0.970085   \n",
       "10     {'C': 5, 'penalty': 'none', 'solver': 'lbfgs'}           0.957265   \n",
       "11  {'C': 5, 'penalty': 'none', 'solver': 'libline...                NaN   \n",
       "12  {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}           0.974359   \n",
       "13      {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}           0.974359   \n",
       "14  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}           0.970085   \n",
       "15  {'C': 10, 'penalty': 'none', 'solver': 'newton...           0.970085   \n",
       "16    {'C': 10, 'penalty': 'none', 'solver': 'lbfgs'}           0.957265   \n",
       "17  {'C': 10, 'penalty': 'none', 'solver': 'liblin...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.965812           0.974359           0.982833   \n",
       "1            0.965812           0.974359           0.982833   \n",
       "2            0.965812           0.961538           0.969957   \n",
       "3            0.957265           0.965812           0.974249   \n",
       "4            0.948718           0.965812           0.944206   \n",
       "5                 NaN                NaN                NaN   \n",
       "6            0.970085           0.965812           0.974249   \n",
       "7            0.970085           0.965812           0.974249   \n",
       "8            0.965812           0.952991           0.965665   \n",
       "9            0.957265           0.965812           0.974249   \n",
       "10           0.948718           0.965812           0.944206   \n",
       "11                NaN                NaN                NaN   \n",
       "12           0.965812           0.965812           0.978541   \n",
       "13           0.970085           0.965812           0.978541   \n",
       "14           0.965812           0.944444           0.969957   \n",
       "15           0.957265           0.965812           0.974249   \n",
       "16           0.948718           0.965812           0.944206   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.969957           0.974359           0.987179   \n",
       "1            0.969957           0.974359           0.987179   \n",
       "2            0.952790           0.957265           0.982906   \n",
       "3            0.961373           0.978632           0.982906   \n",
       "4            0.948498           0.970085           0.970085   \n",
       "5                 NaN                NaN                NaN   \n",
       "6            0.965665           0.974359           0.978632   \n",
       "7            0.965665           0.974359           0.978632   \n",
       "8            0.952790           0.957265           0.974359   \n",
       "9            0.961373           0.978632           0.982906   \n",
       "10           0.948498           0.970085           0.970085   \n",
       "11                NaN                NaN                NaN   \n",
       "12           0.965665           0.978632           0.978632   \n",
       "13           0.965665           0.978632           0.978632   \n",
       "14           0.952790           0.957265           0.974359   \n",
       "15           0.961373           0.978632           0.982906   \n",
       "16           0.948498           0.970085           0.970085   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0            0.970085           0.957082           0.982833   \n",
       "1            0.970085           0.957082           0.982833   \n",
       "2            0.952991           0.948498           0.982833   \n",
       "3            0.974359           0.957082           0.974249   \n",
       "4            0.965812           0.922747           0.969957   \n",
       "5                 NaN                NaN                NaN   \n",
       "6            0.965812           0.965665           0.987124   \n",
       "7            0.965812           0.965665           0.987124   \n",
       "8            0.927350           0.948498           0.969957   \n",
       "9            0.974359           0.957082           0.974249   \n",
       "10           0.965812           0.922747           0.969957   \n",
       "11                NaN                NaN                NaN   \n",
       "12           0.965812           0.965665           0.987124   \n",
       "13           0.965812           0.965665           0.987124   \n",
       "14           0.935897           0.944206           0.965665   \n",
       "15           0.974359           0.957082           0.974249   \n",
       "16           0.965812           0.922747           0.969957   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0             0.970085            0.961538            0.982906   \n",
       "1             0.970085            0.961538            0.982906   \n",
       "2             0.952991            0.961538            0.974359   \n",
       "3             0.965812            0.961538            0.978632   \n",
       "4             0.948718            0.957265            0.965812   \n",
       "5                  NaN                 NaN                 NaN   \n",
       "6             0.957265            0.957265            0.982906   \n",
       "7             0.957265            0.957265            0.982906   \n",
       "8             0.935897            0.940171            0.974359   \n",
       "9             0.965812            0.961538            0.978632   \n",
       "10            0.948718            0.957265            0.965812   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "12            0.952991            0.957265            0.982906   \n",
       "13            0.957265            0.957265            0.982906   \n",
       "14            0.931624            0.940171            0.974359   \n",
       "15            0.965812            0.961538            0.978632   \n",
       "16            0.948718            0.957265            0.965812   \n",
       "17                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.969957            0.957082         0.972313        0.009115   \n",
       "1             0.969957            0.957082         0.972313        0.009115   \n",
       "2             0.961373            0.969957         0.964896        0.010858   \n",
       "3             0.957082            0.935622         0.966313        0.011621   \n",
       "4             0.957082            0.939914         0.955465        0.013029   \n",
       "5                  NaN                 NaN              NaN             NaN   \n",
       "6             0.965665            0.948498         0.969176        0.010046   \n",
       "7             0.965665            0.948498         0.969176        0.010046   \n",
       "8             0.965665            0.957082         0.957196        0.013863   \n",
       "9             0.957082            0.935622         0.966313        0.011621   \n",
       "10            0.957082            0.939914         0.955465        0.013029   \n",
       "11                 NaN                 NaN              NaN             NaN   \n",
       "12            0.965665            0.948498         0.968892        0.010662   \n",
       "13            0.965665            0.948498         0.969462        0.010246   \n",
       "14            0.965665            0.952790         0.956339        0.013886   \n",
       "15            0.957082            0.935622         0.966313        0.011621   \n",
       "16            0.957082            0.939914         0.955465        0.013029   \n",
       "17                 NaN                 NaN              NaN             NaN   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 1            1.000000            1.000000   \n",
       "1                 1            1.000000            1.000000   \n",
       "2                10            0.994647            0.998929   \n",
       "3                 7            1.000000            1.000000   \n",
       "4                13            1.000000            1.000000   \n",
       "5                17                 NaN                 NaN   \n",
       "6                 4            1.000000            1.000000   \n",
       "7                 4            1.000000            1.000000   \n",
       "8                11            0.998929            1.000000   \n",
       "9                 7            1.000000            1.000000   \n",
       "10               13            1.000000            1.000000   \n",
       "11               16                 NaN                 NaN   \n",
       "12                6            1.000000            1.000000   \n",
       "13                3            1.000000            1.000000   \n",
       "14               12            1.000000            1.000000   \n",
       "15                7            1.000000            1.000000   \n",
       "16               13            1.000000            1.000000   \n",
       "17               18                 NaN                 NaN   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             1.000000            1.000000            1.000000   \n",
       "2             0.994647            0.995722            0.996791   \n",
       "3             1.000000            1.000000            1.000000   \n",
       "4             1.000000            1.000000            1.000000   \n",
       "5                  NaN                 NaN                 NaN   \n",
       "6             1.000000            1.000000            1.000000   \n",
       "7             1.000000            1.000000            1.000000   \n",
       "8             1.000000            1.000000            1.000000   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "12            1.000000            1.000000            1.000000   \n",
       "13            1.000000            1.000000            1.000000   \n",
       "14            1.000000            1.000000            1.000000   \n",
       "15            1.000000            1.000000            1.000000   \n",
       "16            1.000000            1.000000            1.000000   \n",
       "17                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             1.000000            1.000000            1.000000   \n",
       "2             0.992505            0.996788            0.995717   \n",
       "3             1.000000            1.000000            1.000000   \n",
       "4             1.000000            1.000000            1.000000   \n",
       "5                  NaN                 NaN                 NaN   \n",
       "6             1.000000            1.000000            1.000000   \n",
       "7             1.000000            1.000000            1.000000   \n",
       "8             1.000000            0.998929            1.000000   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "12            1.000000            1.000000            1.000000   \n",
       "13            1.000000            1.000000            1.000000   \n",
       "14            1.000000            1.000000            1.000000   \n",
       "15            1.000000            1.000000            1.000000   \n",
       "16            1.000000            1.000000            1.000000   \n",
       "17                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split8_train_score  split9_train_score  split10_train_score  \\\n",
       "0             1.000000            1.000000             1.000000   \n",
       "1             1.000000            1.000000             1.000000   \n",
       "2             0.995722            0.996791             0.995717   \n",
       "3             1.000000            1.000000             1.000000   \n",
       "4             1.000000            1.000000             1.000000   \n",
       "5                  NaN                 NaN                  NaN   \n",
       "6             1.000000            1.000000             1.000000   \n",
       "7             1.000000            1.000000             1.000000   \n",
       "8             1.000000            1.000000             1.000000   \n",
       "9             1.000000            1.000000             1.000000   \n",
       "10            1.000000            1.000000             1.000000   \n",
       "11                 NaN                 NaN                  NaN   \n",
       "12            1.000000            1.000000             1.000000   \n",
       "13            1.000000            1.000000             1.000000   \n",
       "14            1.000000            1.000000             1.000000   \n",
       "15            1.000000            1.000000             1.000000   \n",
       "16            1.000000            1.000000             1.000000   \n",
       "17                 NaN                 NaN                  NaN   \n",
       "\n",
       "    split11_train_score  split12_train_score  split13_train_score  \\\n",
       "0              1.000000             1.000000             1.000000   \n",
       "1              1.000000             1.000000             1.000000   \n",
       "2              0.996788             0.995717             0.996791   \n",
       "3              1.000000             1.000000             1.000000   \n",
       "4              1.000000             1.000000             1.000000   \n",
       "5                   NaN                  NaN                  NaN   \n",
       "6              1.000000             1.000000             1.000000   \n",
       "7              1.000000             1.000000             1.000000   \n",
       "8              1.000000             1.000000             1.000000   \n",
       "9              1.000000             1.000000             1.000000   \n",
       "10             1.000000             1.000000             1.000000   \n",
       "11                  NaN                  NaN                  NaN   \n",
       "12             1.000000             1.000000             1.000000   \n",
       "13             1.000000             1.000000             1.000000   \n",
       "14             1.000000             1.000000             1.000000   \n",
       "15             1.000000             1.000000             1.000000   \n",
       "16             1.000000             1.000000             1.000000   \n",
       "17                  NaN                  NaN                  NaN   \n",
       "\n",
       "    split14_train_score  mean_train_score  std_train_score  \n",
       "0              1.000000          1.000000         0.000000  \n",
       "1              1.000000          1.000000         0.000000  \n",
       "2              0.996791          0.996004         0.001381  \n",
       "3              1.000000          1.000000         0.000000  \n",
       "4              1.000000          1.000000         0.000000  \n",
       "5                   NaN               NaN              NaN  \n",
       "6              1.000000          1.000000         0.000000  \n",
       "7              1.000000          1.000000         0.000000  \n",
       "8              0.998930          0.999786         0.000428  \n",
       "9              1.000000          1.000000         0.000000  \n",
       "10             1.000000          1.000000         0.000000  \n",
       "11                  NaN               NaN              NaN  \n",
       "12             1.000000          1.000000         0.000000  \n",
       "13             1.000000          1.000000         0.000000  \n",
       "14             1.000000          1.000000         0.000000  \n",
       "15             1.000000          1.000000         0.000000  \n",
       "16             1.000000          1.000000         0.000000  \n",
       "17                  NaN               NaN              NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création du modèle de régression\n",
    "lRModel = LogisticRegression(verbose=False, max_iter=10000)\n",
    "\n",
    "# Dictionnaire contenant les différents paramètres à essayer\n",
    "paramDict = dict()\n",
    "paramDict['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "paramDict['penalty'] = ['l2', 'none']\n",
    "paramDict['C'] = [0.1,5 , 10]\n",
    "\n",
    "# Création de nos itérations\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "# Création de notre modèle de validation croisée\n",
    "model_cv = GridSearchCV(estimator=lRModel,\n",
    "                        param_grid=paramDict,\n",
    "                        scoring='accuracy',\n",
    "                        cv=kFold,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "# Entrainement du modèle\n",
    "model_cv.fit(x_train, y_train)\n",
    "# cv results\n",
    "pd.set_option('display.max_columns', None)\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31144b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "La validation croisée nous permet de determiner les paramètres optimaux pour notre modèle d'apprentissage.\n",
    "Les résultats de nos tests avec de nombreux paramètres différents (dont la plupart ne sont pas présent dans l'exemple ci-dessus).\n",
    "* Le **paramètre C** correspond à l'inverse de la force de régularisation des données. Plus ce paramètre est grand, plus le risque d'overfitting est grand. Une valeur de 0.1 semble être optimale.\n",
    "* Le **paramètre de pénalité** permet de réduire les coefficients θ. On remarque une perte de précision si l'on n'applique pas de pénalité. La meilleure pénalité semble être la norme L2.\n",
    "* Le **solveur** correspond à l'algorithme d'optimisation utilisé pour l'entrainement. Dans notre cas, lbfgs permet d'obtenir la precision la plus élevée malgré un temps d'entrainement significativement plus long que ses concurrents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324b3aae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification naïve bayésienne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9833fcac",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\paula\\desktop\\mines\\machine_learning\\mines-ai-number-recognition-project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 7 is smaller than n_iter=30. Running 7 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n0       0.009690      0.009860         0.001047        0.002370           0   \n1       0.003794      0.004041         0.000674        0.002037      0.0001   \n2       0.005864      0.004474         0.000000        0.000000       0.001   \n3       0.003928      0.004083         0.000000        0.000000        0.01   \n4       0.003391      0.004037         0.001492        0.002713         0.1   \n5       0.002990      0.004121         0.000539        0.002019         0.5   \n6       0.005213      0.004970         0.000677        0.002047         1.0   \n\n              params  split0_test_score  split1_test_score  split2_test_score  \\\n0       {'alpha': 0}           0.837607           0.871795           0.854701   \n1  {'alpha': 0.0001}           0.841880           0.884615           0.854701   \n2   {'alpha': 0.001}           0.846154           0.884615           0.854701   \n3    {'alpha': 0.01}           0.850427           0.884615           0.854701   \n4     {'alpha': 0.1}           0.854701           0.880342           0.854701   \n5     {'alpha': 0.5}           0.850427           0.876068           0.850427   \n6     {'alpha': 1.0}           0.850427           0.871795           0.850427   \n\n   split3_test_score  ...  split8_test_score  split9_test_score  \\\n0           0.836910  ...           0.819742           0.875536   \n1           0.849785  ...           0.828326           0.879828   \n2           0.849785  ...           0.836910           0.875536   \n3           0.849785  ...           0.841202           0.875536   \n4           0.849785  ...           0.841202           0.884120   \n5           0.845494  ...           0.836910           0.884120   \n6           0.841202  ...           0.832618           0.879828   \n\n   split10_test_score  split11_test_score  split12_test_score  \\\n0            0.833333            0.854701            0.858974   \n1            0.854701            0.858974            0.867521   \n2            0.854701            0.858974            0.867521   \n3            0.858974            0.858974            0.863248   \n4            0.867521            0.858974            0.854701   \n5            0.871795            0.850427            0.854701   \n6            0.871795            0.841880            0.854701   \n\n   split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n0            0.866953            0.871245         0.853594        0.015985   \n1            0.871245            0.884120         0.863296        0.015941   \n2            0.871245            0.884120         0.864722        0.014346   \n3            0.871245            0.884120         0.864154        0.012277   \n4            0.871245            0.888412         0.864442        0.012759   \n5            0.854077            0.875536         0.859300        0.013215   \n6            0.854077            0.875536         0.857587        0.013731   \n\n   rank_test_score  \n0                7  \n1                4  \n2                1  \n3                3  \n4                2  \n5                5  \n6                6  \n\n[7 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mean_fit_time</th>\n      <th>std_fit_time</th>\n      <th>mean_score_time</th>\n      <th>std_score_time</th>\n      <th>param_alpha</th>\n      <th>params</th>\n      <th>split0_test_score</th>\n      <th>split1_test_score</th>\n      <th>split2_test_score</th>\n      <th>split3_test_score</th>\n      <th>...</th>\n      <th>split8_test_score</th>\n      <th>split9_test_score</th>\n      <th>split10_test_score</th>\n      <th>split11_test_score</th>\n      <th>split12_test_score</th>\n      <th>split13_test_score</th>\n      <th>split14_test_score</th>\n      <th>mean_test_score</th>\n      <th>std_test_score</th>\n      <th>rank_test_score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.009690</td>\n      <td>0.009860</td>\n      <td>0.001047</td>\n      <td>0.002370</td>\n      <td>0</td>\n      <td>{'alpha': 0}</td>\n      <td>0.837607</td>\n      <td>0.871795</td>\n      <td>0.854701</td>\n      <td>0.836910</td>\n      <td>...</td>\n      <td>0.819742</td>\n      <td>0.875536</td>\n      <td>0.833333</td>\n      <td>0.854701</td>\n      <td>0.858974</td>\n      <td>0.866953</td>\n      <td>0.871245</td>\n      <td>0.853594</td>\n      <td>0.015985</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.003794</td>\n      <td>0.004041</td>\n      <td>0.000674</td>\n      <td>0.002037</td>\n      <td>0.0001</td>\n      <td>{'alpha': 0.0001}</td>\n      <td>0.841880</td>\n      <td>0.884615</td>\n      <td>0.854701</td>\n      <td>0.849785</td>\n      <td>...</td>\n      <td>0.828326</td>\n      <td>0.879828</td>\n      <td>0.854701</td>\n      <td>0.858974</td>\n      <td>0.867521</td>\n      <td>0.871245</td>\n      <td>0.884120</td>\n      <td>0.863296</td>\n      <td>0.015941</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.005864</td>\n      <td>0.004474</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.001</td>\n      <td>{'alpha': 0.001}</td>\n      <td>0.846154</td>\n      <td>0.884615</td>\n      <td>0.854701</td>\n      <td>0.849785</td>\n      <td>...</td>\n      <td>0.836910</td>\n      <td>0.875536</td>\n      <td>0.854701</td>\n      <td>0.858974</td>\n      <td>0.867521</td>\n      <td>0.871245</td>\n      <td>0.884120</td>\n      <td>0.864722</td>\n      <td>0.014346</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.003928</td>\n      <td>0.004083</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.01</td>\n      <td>{'alpha': 0.01}</td>\n      <td>0.850427</td>\n      <td>0.884615</td>\n      <td>0.854701</td>\n      <td>0.849785</td>\n      <td>...</td>\n      <td>0.841202</td>\n      <td>0.875536</td>\n      <td>0.858974</td>\n      <td>0.858974</td>\n      <td>0.863248</td>\n      <td>0.871245</td>\n      <td>0.884120</td>\n      <td>0.864154</td>\n      <td>0.012277</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.003391</td>\n      <td>0.004037</td>\n      <td>0.001492</td>\n      <td>0.002713</td>\n      <td>0.1</td>\n      <td>{'alpha': 0.1}</td>\n      <td>0.854701</td>\n      <td>0.880342</td>\n      <td>0.854701</td>\n      <td>0.849785</td>\n      <td>...</td>\n      <td>0.841202</td>\n      <td>0.884120</td>\n      <td>0.867521</td>\n      <td>0.858974</td>\n      <td>0.854701</td>\n      <td>0.871245</td>\n      <td>0.888412</td>\n      <td>0.864442</td>\n      <td>0.012759</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.002990</td>\n      <td>0.004121</td>\n      <td>0.000539</td>\n      <td>0.002019</td>\n      <td>0.5</td>\n      <td>{'alpha': 0.5}</td>\n      <td>0.850427</td>\n      <td>0.876068</td>\n      <td>0.850427</td>\n      <td>0.845494</td>\n      <td>...</td>\n      <td>0.836910</td>\n      <td>0.884120</td>\n      <td>0.871795</td>\n      <td>0.850427</td>\n      <td>0.854701</td>\n      <td>0.854077</td>\n      <td>0.875536</td>\n      <td>0.859300</td>\n      <td>0.013215</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.005213</td>\n      <td>0.004970</td>\n      <td>0.000677</td>\n      <td>0.002047</td>\n      <td>1.0</td>\n      <td>{'alpha': 1.0}</td>\n      <td>0.850427</td>\n      <td>0.871795</td>\n      <td>0.850427</td>\n      <td>0.841202</td>\n      <td>...</td>\n      <td>0.832618</td>\n      <td>0.879828</td>\n      <td>0.871795</td>\n      <td>0.841880</td>\n      <td>0.854701</td>\n      <td>0.854077</td>\n      <td>0.875536</td>\n      <td>0.857587</td>\n      <td>0.013731</td>\n      <td>6</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "NB_model = BernoulliNB()\n",
    "\n",
    "params = {'alpha': [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]}\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(NB_model, params, n_iter=30, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "# NB = RCV.fit(x_train, y_train).best_estimator_\n",
    "RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(RCV.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Le seul paramètre testé dans ce modèle, alpha, correspond à la force du lissage de Laplace a appliqué au modèle.\n",
    "En d'autres termes, ce paramètre permet de palier la présence d'une caractéristique dans le jeu de test qui n'existe pas dans le jeu d'entrainement.\n",
    "> https://towardsdatascience.com/laplace-smoothing-in-na%C3%AFve-bayes-algorithm-9c237a8bdece\n",
    "\n",
    "Au vu des résultats, le paramètre alpha optimal semble être autour de 0.001\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification par arbre de décision"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT_model = DecisionTreeClassifier()\n",
    "\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"min_samples_leaf\": [1, 2, 3, 4],\n",
    "              \"criterion\": [\"gini\", \"entropy\"],\n",
    "              \"splitter\": [\"best\", \"random\"]}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "RCV = RandomizedSearchCV(DT_model, param_dist, n_iter=50, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "DT = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(DT.cv_results_)\n",
    "cv_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification par boosting de gradient"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642551df",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Building Gradient Boosting Classifier\n",
    "\n",
    "GB_model = GradientBoostingClassifier()\n",
    "param_dist = {\n",
    "    \"n_estimators\": [5, 20, 100],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(GB_model, param_dist, n_iter=36, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "GB = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(GB.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification par voisin le plus proche"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "KNN_model = KNeighborsClassifier()\n",
    "\n",
    "knn_param = {\"n_neighbors\": [i for i in range(1, 30, 5)],\n",
    "             \"weights\": [\"uniform\", \"distance\"],\n",
    "             \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "             \"leaf_size\": [1, 10, 30],\n",
    "             \"p\": [1, 2]}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(KNN_model, knn_param, n_iter=50, scoring='accuracy', n_jobs=-1, cv=cv, random_state=1)\n",
    "\n",
    "KNN = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(KNN.cv_results_)\n",
    "cv_results"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Citation :\n",
    "Stephanie Glen. \"Regularization: Simple Definition, L1 & L2 Penalties\" From StatisticsHowTo.com: Elementary Statistics for the rest of us! https://www.statisticshowto.com/regularization/"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}