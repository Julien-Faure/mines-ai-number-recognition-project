{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "662ec01d",
   "metadata": {},
   "source": [
    "# Rapport du projet de résolution de problème\n",
    "\n",
    "- Paul Achard\n",
    "- Julien Faure\n",
    "\n",
    "    \n",
    "- *Date : 20/01/2022*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aebe9f9c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdcdfec",
   "metadata": {},
   "source": [
    "## Problématique\n",
    "\n",
    "Notre problématique est d'identifier un chiffre à partir d'une image.\n",
    "Plus spécifiquement, une image de 8x8 pixels en niveau de gris."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a277c79c",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "\n",
    "- Trouver un modèle permettant d'identifier un chiffre à partir d'une image\n",
    "- Comparer différentes stratégies de solveur pour le modèle trouvé\n",
    "\n",
    "## Analyse du dataset\n",
    "\n",
    "Identifier un chiffre à partir d'une image est une tache qui peut s'avérer très complexe. Afin d'avoir une difficulté raisonnable et adapté au contexte de ce projet, nous avons fixé certains paramètres dans notre dataset.\n",
    "\n",
    "- La résolution de nos images est identiques pour tout le dataset. Cette résolution est **8 pixels par 8 pixels**.\n",
    "- Chaque pixel est codé sur **4 bits**.\n",
    "- Les images contiennent uniquement un chiffre sans élément parasite, sans effet et sans traitement.\n",
    "\n",
    "Nous utilisons le dataset `digits` de `seaborn`.\n",
    "\n",
    "### Forme du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc4cd07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n",
      "Label Data Shape (1797,)\n"
     ]
    }
   ],
   "source": [
    "# Import du dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Affiche le nombre d'images et leur format\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "\n",
    "# Affiche le nombre de labels\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e60f92",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir ci-dessus, le dataset est composé de **1797** images labellisées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606f3739",
   "metadata": {},
   "source": [
    "### Répartition des images du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22242354",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'n° labellisé'), Text(0, 0.5, 'Occurrence')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVXElEQVR4nO3de7QlZX3m8e9jN0RuCkrLEC7T4BDiZbSBs0CDIBEvSLwmjoEZb9HYMAMJjImOlxUlmWUmGW9ZClHbwEhWkCAgo+MQBcElo0vR09BCczFyU7pt6RNBAUUCzW/+2HWKTXua3t3n7KpDn+9nrb266q296/1x6N7Pqbeq3kpVIUkSwOP6LkCSNH8YCpKklqEgSWoZCpKklqEgSWot7ruA2dh9991r6dKlfZchSY8pK1eu/JeqWjLTtsd0KCxdupTJycm+y5Ckx5QkP9jUNoePJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEktQ0GS1DIUJEmtx/QdzZrfvnbk8zvr6/lXfK2zvqRtmaEwx374F/++s772fe+1nfWl2Xn/617TWV/v+YcLOutL2x5DQdu80//k/3TSz8kfenkn/czGDe+/vJN+nvaeF3TSj+aeoSBJPXn2BV/urK/vvuYlI73PUJDUqdNOO22b7GtbsU2FwiFv//tO+ln5gTd00o8kdW1sl6QmOSvJ+iSrh9rOS7Kqed2WZFXTvjTJfUPbPjGuuiRJmzbOI4VPA6cD7a/vVfX708tJPgT8bOj9N1fVsjHWs6Ac/rHDO+nnG3/0jU76kdSNsYVCVV2RZOlM25IEeC3gJQqSNI/0dUfzEcAdVfX9obb9klyd5GtJjtjUB5MsTzKZZHJqamr8lUrSAtLXiebjgXOH1tcB+1bVT5IcAvzvJM+oqrs3/mBVrQBWAExMTFQn1Ura5nz2/EM76ee1/+HbnfQzVzo/UkiyGPhd4Lzptqq6v6p+0iyvBG4GfqPr2iRpoetj+OiFwI1VtWa6IcmSJIua5f2BA4BbeqhNkha0cV6Sei7wTeDAJGuSvKXZdByPHDoCOBK4prlE9QLgxKq6c1y1SZJmNs6rj47fRPubZmi7ELhwXLVIkkbj8xQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSS1DQZLUMhQkSa2xhUKSs5KsT7J6qO20JGuTrGpexw5te1eSm5J8L8lLxlWXJGnTxnmk8GngmBnaP1JVy5rXxQBJng4cBzyj+czfJlk0xtokSTMYWyhU1RXAnSO+/ZXAP1bV/VV1K3ATcOi4apMkzayPcwonJ7mmGV7arWnbC7h96D1rmrZfkWR5kskkk1NTU+OuVZIWlK5D4ePAU4FlwDrgQ1u6g6paUVUTVTWxZMmSOS5Pkha2TkOhqu6oqg1V9RDwKR4eIloL7DP01r2bNklShzoNhSR7Dq2+Gpi+MukLwHFJfi3JfsABwLe7rE2SBIvHteMk5wJHAbsnWQO8DzgqyTKggNuAEwCq6roknwWuBx4ETqqqDeOqTZI0s7GFQlUdP0PzmY/y/vcD7x9XPZKkzfOOZklSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSy1CQJLUMBUlSa2yhkOSsJOuTrB5q+0CSG5Nck+SiJLs27UuT3JdkVfP6xLjqkiRt2jiPFD4NHLNR26XAM6vqWcA/A+8a2nZzVS1rXieOsS5J0iaMLRSq6grgzo3aLqmqB5vVbwF7j6t/SdKW6/OcwpuBfxpa3y/J1Um+luSITX0oyfIkk0kmp6amxl+lJC0gvYRCkvcADwLnNE3rgH2r6iDgbcBnkjxhps9W1YqqmqiqiSVLlnRTsCQtEJ2HQpI3AS8D/lNVFUBV3V9VP2mWVwI3A7/RdW2StNB1GgpJjgHeAbyiqn4x1L4kyaJmeX/gAOCWLmuTJMHice04ybnAUcDuSdYA72NwtdGvAZcmAfhWc6XRkcBfJHkAeAg4sarunHHHkqSxGVsoVNXxMzSfuYn3XghcOK5aJEmj8Y5mSVJrpFDIwOuSvLdZ3zfJoeMtTZLUtVGPFP4WeC4wPSR0D3DGWCqSJPVm1HMKh1XVwUmuBqiqu5JsP8a6JEk9GPVI4YHmktGCwSWkDK4SkiRtQ0YNhY8CFwFPSfJ+4OvAX46tKklSL0YaPqqqc5KsBI4GAryqqm4Ya2WSpM6NFApJngNcV1VnNOtPSHJYVV051uokSZ0adfjo48C9Q+v3Nm2SpG3IqKGQ6cnrAKrqIcZ4N7QkqR+jhsItSf44yXbN6xScsE6StjmjhsKJwG8Ba4E1wGHA8nEVJUnqx6hXH60HjhtzLZKkno169dES4K3A0uHPVNWbx1OWJKkPo54s/jzw/4CvABvGV44kqU+jhsKOVfXfxlqJJKl3o55o/mKSY8daiSSpd6OGwikMguGXSe5Ock+Su8dZmCSpe6NefbTLuAuRJPVvS5+89mfN+j6jPHktyVlJ1idZPdT2pCSXJvl+8+duQ318NMlNSa5JcvDW/kdJkrbOlj557T826/cy2pPXPg0cs1HbO4HLquoA4LJmHeClwAHNaznOrSRJnRs1FA6rqpOAX8LgyWvAZp+8VlVXAHdu1PxK4Oxm+WzgVUPtf18D3wJ2TbLniPVJkuZAH09e26Oq1jXLPwb2aJb3Am4fet+apk2S1JFen7zWzLxam33jkCTLk0wmmZyampptCZKkIZu9+ijJ44BbgXcwN09euyPJnlW1rhkeWt+0rwX2GXrf3k3bI1TVCmAFwMTExBYFiiTp0W32SKF5dsIZVXVjVZ1RVafP8lGcXwDe2Cy/kcEUGtPtb2iuQnoO8LOhYSZJUgdGHT66LMnvJcmW7DzJucA3gQOTrEnyFuCvgBcl+T7wwmYd4GIGz2i4CfgU8F+2pC9J0uyNOvfRCcDbgAeT/JLBEFJV1RMe7UNVdfwmNh09w3sLOGnEeiRJYzDqOYVjquobHdQjSerRqOcUTu+gFklSz8Z6TkGS9NgyaiicAJwP3O8sqZK07XKWVElSa9RnNB85U3szt5EkaRsx6iWpbx9afjxwKLASeMGcVyRJ6s2ow0cvH15Psg/wN+MoSJLUn1FPNG9sDfC0uSxEktS/Uc8pfIyHZzN9HLAMuGpMNUmSejLqOYXJoeUHgXO9w1mStj2jhsIFwC+ragNAkkVJdqyqX4yvNElS10a+oxnYYWh9B+Arc1+OJKlPo4bC46vq3umVZnnH8ZQkSerLqKHw8yQHT68kOQS4bzwlSZL6Muo5hVOB85P8iMGzFP4N8PvjKkqS1I9Rb177TpLfBA5smr5XVQ+MryxJUh9GGj5KchKwU1WtrqrVwM5JfFymJG1jRj2n8Naq+un0SlXdBbx1LBVJknozaigsGn7ATpJFwPbjKUmS1JdRTzR/GTgvySeb9ROBL21Nh0kOBM4batofeC+wK4Ojj6mm/d1VdfHW9CFJ2jqjhsKfMfjCnj6P8GXgzK3psKq+x2DupOkjjrXARcAfAB+pqg9uzX4lSbP3qKGQZDHwlwy+sG9vmvcFbmEw9LRhlv0fDdxcVT/w8c+S1L/NnVP4APAkYP+qOriqDgb2A54IzMVv9McB5w6tn5zkmiRnJdltpg8kWZ5kMsnk1NTUTG+RJG2lzYXCyxhceXTPdEOz/J+BY2fTcZLtgVcA5zdNHweeymBoaR3woZk+V1UrqmqiqiaWLFkymxIkSRvZXChUVdUMjRt4+PkKW+ulwFVVdUezzzuqakNVPQR8isEjPyVJHdpcKFyf5A0bNyZ5HXDjLPs+nqGhoyR7Dm17NbB6lvuXJG2hzV19dBLwuSRvBlY2bRMMps5+9dZ2mmQn4EXACUPN/zPJMgZHILdttE2S1IFHDYWqWgscluQFwDOa5our6rLZdFpVPweevFHb62ezT0nS7I06Id7lwOVjrkWS1LNRp7mQJC0AhoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqTXS4zjHIcltwD3ABuDBqppI8iTgPGApcBvw2qq6q68aJWmh6ftI4berallVTTTr7wQuq6oDgMuadUlSR/oOhY29Eji7WT4beFV/pUjSwtNnKBRwSZKVSZY3bXtU1bpm+cfAHht/KMnyJJNJJqemprqqVZIWhN7OKQDPq6q1SZ4CXJrkxuGNVVVJauMPVdUKYAXAxMTEr2yXJG293o4Uqmpt8+d64CLgUOCOJHsCNH+u76s+SVqIegmFJDsl2WV6GXgxsBr4AvDG5m1vBD7fR32StFD1NXy0B3BRkukaPlNVX0ryHeCzSd4C/AB4bU/1SdKC1EsoVNUtwLNnaP8JcHT3FUmSYP5dkipJ6pGhIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpJahIElqGQqSpFbnoZBknyRfTXJ9kuuSnNK0n5ZkbZJVzevYrmuTpIVucQ99Pgj8SVVdlWQXYGWSS5ttH6mqD/ZQkySJHkKhqtYB65rle5LcAOzVdR2SpF/V6zmFJEuBg4Arm6aTk1yT5Kwku/VXmSQtTL2FQpKdgQuBU6vqbuDjwFOBZQyOJD60ic8tTzKZZHJqaqqrciVpQeglFJJsxyAQzqmqzwFU1R1VtaGqHgI+BRw602erakVVTVTVxJIlS7orWpIWgD6uPgpwJnBDVX14qH3Pobe9GljddW2StND1cfXR4cDrgWuTrGra3g0cn2QZUMBtwAk91CZJC1ofVx99HcgMmy7uuhZJ0iN5R7MkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJahoIkqWUoSJJa8y4UkhyT5HtJbkryzr7rkaSFZF6FQpJFwBnAS4GnA8cneXq/VUnSwjGvQgE4FLipqm6pqn8F/hF4Zc81SdKCkarqu4ZWktcAx1TVHzbrrwcOq6qTh96zHFjerB4IfG+W3e4O/Mss9zEX5kMd86EGmB91WMPD5kMd86EGmB91zEUN/7aqlsy0YfEsd9y5qloBrJir/SWZrKqJudrfY7mO+VDDfKnDGuZXHfOhhvlSx7hrmG/DR2uBfYbW927aJEkdmG+h8B3ggCT7JdkeOA74Qs81SdKCMa+Gj6rqwSQnA18GFgFnVdV1Y+52zoaiZmk+1DEfaoD5UYc1PGw+1DEfaoD5UcdYa5hXJ5olSf2ab8NHkqQeGQqSpNaCDoW+p9RIclaS9UlWd933RnXsk+SrSa5Pcl2SU3qo4fFJvp3ku00Nf951DUO1LEpydZIv9ljDbUmuTbIqyWSPdeya5IIkNya5IclzO+7/wOZnMP26O8mpXdbQ1PFfm7+Xq5Ocm+TxXdfQ1HFKU8N1Y/s5VNWCfDE4kX0zsD+wPfBd4Okd13AkcDCwuuefxZ7Awc3yLsA/9/CzCLBzs7wdcCXwnJ5+Hm8DPgN8scf/J7cBu/f596Kp42zgD5vl7YFde6xlEfBjBjdeddnvXsCtwA7N+meBN/Xw3/9MYDWwI4OLhL4C/Lu57mchHyn0PqVGVV0B3Nlln5uoY11VXdUs3wPcwOAfQpc1VFXd26xu17w6vwoiyd7A7wB/13Xf802SJzL4xeVMgKr616r6aY8lHQ3cXFU/6KHvxcAOSRYz+FL+UQ81PA24sqp+UVUPAl8DfneuO1nIobAXcPvQ+ho6/iKcj5IsBQ5i8Jt6130vSrIKWA9cWlWd1wD8DfAO4KEe+h5WwCVJVjZTu/RhP2AK+F/NcNrfJdmpp1pgcN/SuV13WlVrgQ8CPwTWAT+rqku6roPBUcIRSZ6cZEfgWB55s++cWMihoI0k2Rm4EDi1qu7uuv+q2lBVyxjcyX5okmd22X+SlwHrq2pll/1uwvOq6mAGMwaflOTIHmpYzGB48+NVdRDwc6CX6eybm1lfAZzfQ9+7MRhF2A/4dWCnJK/ruo6qugH4a+AS4EvAKmDDXPezkEPBKTWGJNmOQSCcU1Wf67OWZojiq8AxHXd9OPCKJLcxGE58QZJ/6LgGoP3tlKpaD1zEYLiza2uANUNHbBcwCIk+vBS4qqru6KHvFwK3VtVUVT0AfA74rR7qoKrOrKpDqupI4C4G5//m1EIOBafUaCQJg3HjG6rqwz3VsCTJrs3yDsCLgBu7rKGq3lVVe1fVUgZ/Hy6vqs5/I0yyU5JdppeBFzMYOuhUVf0YuD3JgU3T0cD1XdfROJ4eho4aPwSek2TH5t/K0QzOu3UuyVOaP/dlcD7hM3Pdx7ya5qJL1c+UGo+Q5FzgKGD3JGuA91XVmV3W0DgceD1wbTOmD/Duqrq4wxr2BM5uHrT0OOCzVdXbJaE92wO4aPD9w2LgM1X1pZ5q+SPgnOYXp1uAP+i6gCYYXwSc0HXfAFV1ZZILgKuAB4Gr6W+6iwuTPBl4ADhpHCf+neZCktRayMNHkqSNGAqSpJahIElqGQqSpJahID2GJfmdJM/quw5tOwwFCUjy60kuT/L55s7ujbe/Kcnpm9nHaUn+dAv7vbf5c+n0bLlJJpJ8dITPHgM8H7h2S/qUHs2CvU9B2sgfM7gmf3/gdcAn+iqkqiaBzU6X3dy70Nf9C9pGeaSgBaP5bfyGJJ9q5qO/pLl7GgY3MD7UvLKZ/bw8yZXNJHFfSbLH0OZnJ/lmku8neevQZ96e5DtJrtncsyKSHDX9LIckzx96lsDVQ3c6j7w/aUsYClpoDgDOqKpnAD8Ffq9pPx34JHAisLn5jr7O4FkPBzGYI+kdQ9ueBbwAeC7w3mZY6sVNv4cCy4BDtmCCuz9lcOfqMuAI4L5Z7k96VA4faaG5tapWNcsrgaUAzRz9o36x7g2cl2RPBg+euXVo2+er6j4GX95fZfDF/TwG8xdd3bxnZwZf6leM0Nc3gA8nOQf4XFWtaUJha/cnPSpDQQvN/UPLG4AdNvXGR/Ex4MNV9YUkRwGnDW3beN6YYjAc9T+q6pNb2lFV/VWS/8tg7vxvJHnJbPYnbY7DR9KWeyIPT7P+xo22vTKD500/mcFkh99hMOnim6evakqy1/Rsl5uT5KlVdW1V/XWzr9+czf6kzfFIQdpypwHnJ7kLuJzBw1emXcPgWRC7A/+9qn4E/CjJ04BvNjOf3svgCqf1I/R1apLfZnAC/Drgn6rq/lnsT3pUzpIqSWo5fCRJahkKkqSWoSBJahkKkqSWoSBJahkKkqSWoSBJav1/hVAL35rFGUMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graphique = sns.countplot(x=digits.target)\n",
    "graphique.set(xlabel=\"n° labellisé\", ylabel = \"Occurrence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63713b23",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Les données labellisées sont équitablement distribuées (environ 175 par label)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "412474d4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Représentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3bf114",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Création de 10 figures de 10 par 3 pixels\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(10, 3))\n",
    "\n",
    "# Pour chaque figure, on affiche l'image du chiffre et son label en titre\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_title(\"Label: %i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32066a0d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Représentation des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac79a3e2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "\n",
      " Type de chaque valeur : <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# Affiche le tableau représentant la première image\n",
    "print(digits.images[0])\n",
    "print(\"\\n Type de chaque valeur :\", type(digits.images[0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eeedcd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> Comme nous l'avons vu précédemment, chaque image possède une résolution de 8x8 pixels en niveaux de gris codés sur 4bits par pixel.\n",
    "\n",
    "Dans notre programme, une image est représentée par une matrice de dimension 8x8. Chaque élément représente un pixel avec un niveau de gris codé sur 4bits (de 0 à 15). Plus la valeur est élevée, plus la couleur est foncée.\n",
    "\n",
    "> Exemple :\n",
    "* 0 : Blanc\n",
    "* 15 : Noir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624c2d9b",
   "metadata": {},
   "source": [
    "### Mise en forme des données d'entrées\n",
    "\n",
    "Pour commencer, nous devons redimenssionner nos données d'entrées.\n",
    "\n",
    "Actuellement, nous avons des données sous la forme d'un tableau de matrice.\n",
    "\n",
    "Il nous faut les mettre sous forme d'une matrice où chaque vecteur correspond aux pixels de l'image.\n",
    "\n",
    "Donc si nous avons 1797 images, la matrice d'entrée est composée de 1797 vecteurs.\n",
    "\n",
    "Avec une résolution de 8x8, la taille d'un vecteur est de 64 valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04f179d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Redimensionne la matrice en vecteur\n",
    "print(digits.images[0].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87c882d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redimenssionne le tableau de matrice en matrice\n",
    "x = digits.images.reshape((len(digits.images), -1))\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8a57e5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Préparation des données\n",
    "\n",
    "### Jeu de test et jeu d'entraînement\n",
    "\n",
    "Il nous faut maintenant séparer notre jeu de test et notre jeu d'entraînement du dataset.\n",
    "\n",
    "Pour choisir la taille de notre jeu de test, il est nécessaire de faire attention à plusieurs points :\n",
    "* Le temps d'entrainement de notre modèle\n",
    "* La taille de notre dataset\n",
    "\n",
    "Plus la proportion du jeu d'entraînement est faible, plus notre modèle à un niveau de variance élevé. Ainsi, on augmente les chances d'avoir de l'*over fitting*.\n",
    "\n",
    "A contrario, plus la proportion du jeu de test est faible, plus notre modèle à un niveau de variance faible. Ainsi, on augmente les chances d'avoir de l'*under fitting*.\n",
    "\n",
    "Le but est donc de trouver la valeur qui nous permet d'avoir le taux de variance optimal.\n",
    "\n",
    "\n",
    "Pour trouver cette valeur, nous avons appliqué la procédure suivante, nous avons essayé avec plusieurs valeurs en partant de 20% jusqu'à 80% avec un pas de 5%. Nous avons déterminé que la meilleure valeur est **35%**.\n",
    "\n",
    "\n",
    "> [https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio](https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ee3365f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# séparation du dataset en données \"d'apprentissage\" et de test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38caa895",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Création du tableau de résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67a4981f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Mean Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (LR)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes Classifier (NB)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (DT)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting (GB)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines (SVM)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours (KNN)</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Best Mean Test Score\n",
       "Logistic Regression (LR)                        0.0\n",
       "Naïve Bayes Classifier (NB)                     0.0\n",
       "Decision Tree Classifier (DT)                   0.0\n",
       "Gradient Boosting (GB)                          0.0\n",
       "Support Vector Machines (SVM)                   0.0\n",
       "K Nearest Neighbours (KNN)                      0.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Evaluation_Results = pd.DataFrame(np.zeros((6, 1)), columns=['Best Mean Test Score'])\n",
    "Evaluation_Results.index = ['Logistic Regression (LR)', 'Naïve Bayes Classifier (NB)',\n",
    "                            'Decision Tree Classifier (DT)', 'Gradient Boosting (GB)',\n",
    "                            'Support Vector Machines (SVM)', 'K Nearest Neighbours (KNN)']\n",
    "Evaluation_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf07d329",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Test de différents modèles\n",
    "\n",
    "Pour résoudre notre problème, nous allons essayer les modèles suivants :\n",
    "* [Modèle de regréssion logistique multiclasse](#Mod%C3%A8le-de-regr%C3%A9ssion-logistique-multiclasse)\n",
    "* [Modèle de Bayes](#Mod%C3%A8le-de-Bayes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39243210",
   "metadata": {},
   "source": [
    "### Modèle de regréssion logistique multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55034f65",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 18 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\paula\\desktop\\mines\\machine_learning\\mines-ai-number-recognition-project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "45 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\paula\\desktop\\mines\\machine_learning\\mines-ai-number-recognition-project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\paula\\desktop\\mines\\machine_learning\\mines-ai-number-recognition-project\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"c:\\users\\paula\\desktop\\mines\\machine_learning\\mines-ai-number-recognition-project\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\users\\paula\\desktop\\mines\\machine_learning\\mines-ai-number-recognition-project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.97231332 0.97231332 0.96489613 0.96659819 0.95546507        nan\n",
      " 0.96917575 0.96946187 0.95748138 0.96659819 0.95546507        nan\n",
      " 0.96917697 0.96860595 0.95633934 0.96659819 0.95546507        nan]\n",
      "  warnings.warn(\n",
      "c:\\users\\paula\\desktop\\mines\\machine_learning\\mines-ai-number-recognition-project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.99600438 1.         1.                nan\n",
      " 1.         1.         0.99978594 1.         1.                nan\n",
      " 1.         1.         1.         1.         1.                nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.683046</td>\n",
       "      <td>0.132196</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.003466</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.972313</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.128768</td>\n",
       "      <td>0.747580</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.972313</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072832</td>\n",
       "      <td>0.039772</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.964896</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994647</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>0.994647</td>\n",
       "      <td>0.995722</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.992505</td>\n",
       "      <td>0.996788</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.995722</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.996788</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.394580</td>\n",
       "      <td>0.284408</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>0.1</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'none', 'solver': 'newto...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.966598</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067454</td>\n",
       "      <td>0.019222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.003239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'none', 'solver': 'libli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.821959</td>\n",
       "      <td>0.109122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969176</td>\n",
       "      <td>0.010046</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.117055</td>\n",
       "      <td>1.537822</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000703</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969462</td>\n",
       "      <td>0.010003</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100927</td>\n",
       "      <td>0.007633</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.002050</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.927350</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.957481</td>\n",
       "      <td>0.014251</td>\n",
       "      <td>11</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998930</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.160905</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 5, 'penalty': 'none', 'solver': 'newton-...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.966598</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.059094</td>\n",
       "      <td>0.008234</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 5, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'penalty': 'none', 'solver': 'libline...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.821337</td>\n",
       "      <td>0.083474</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969177</td>\n",
       "      <td>0.010284</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.843874</td>\n",
       "      <td>1.019567</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.968606</td>\n",
       "      <td>0.010692</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.103881</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.956339</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.155850</td>\n",
       "      <td>0.007297</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000512</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'penalty': 'none', 'solver': 'newton...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.966598</td>\n",
       "      <td>0.011553</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.056705</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'penalty': 'none', 'solver': 'liblin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.683046      0.132196         0.002031        0.003466     0.1   \n",
       "1        2.128768      0.747580         0.000545        0.002022     0.1   \n",
       "2        0.072832      0.039772         0.000274        0.000698     0.1   \n",
       "3        0.394580      0.284408         0.000540        0.002020     0.1   \n",
       "4        0.067454      0.019222         0.000000        0.000000     0.1   \n",
       "5        0.001620      0.003239         0.000000        0.000000     0.1   \n",
       "6        0.821959      0.109122         0.000000        0.000000       5   \n",
       "7        3.117055      1.537822         0.000276        0.000703       5   \n",
       "8        0.100927      0.007633         0.000679        0.002050       5   \n",
       "9        0.160905      0.011184         0.000000        0.000000       5   \n",
       "10       0.059094      0.008234         0.001078        0.002748       5   \n",
       "11       0.000000      0.000000         0.000000        0.000000       5   \n",
       "12       0.821337      0.083474         0.000138        0.000518      10   \n",
       "13       2.843874      1.019567         0.000069        0.000260      10   \n",
       "14       0.103881      0.004661         0.000676        0.002040      10   \n",
       "15       0.155850      0.007297         0.000137        0.000512      10   \n",
       "16       0.056705      0.004477         0.000138        0.000515      10   \n",
       "17       0.000275      0.000701         0.000000        0.000000      10   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "0             l2    newton-cg   \n",
       "1             l2        lbfgs   \n",
       "2             l2    liblinear   \n",
       "3           none    newton-cg   \n",
       "4           none        lbfgs   \n",
       "5           none    liblinear   \n",
       "6             l2    newton-cg   \n",
       "7             l2        lbfgs   \n",
       "8             l2    liblinear   \n",
       "9           none    newton-cg   \n",
       "10          none        lbfgs   \n",
       "11          none    liblinear   \n",
       "12            l2    newton-cg   \n",
       "13            l2        lbfgs   \n",
       "14            l2    liblinear   \n",
       "15          none    newton-cg   \n",
       "16          none        lbfgs   \n",
       "17          none    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...           0.978632   \n",
       "1      {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}           0.978632   \n",
       "2   {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...           0.978632   \n",
       "3   {'C': 0.1, 'penalty': 'none', 'solver': 'newto...           0.970085   \n",
       "4    {'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}           0.957265   \n",
       "5   {'C': 0.1, 'penalty': 'none', 'solver': 'libli...                NaN   \n",
       "6    {'C': 5, 'penalty': 'l2', 'solver': 'newton-cg'}           0.978632   \n",
       "7        {'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}           0.978632   \n",
       "8    {'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}           0.970085   \n",
       "9   {'C': 5, 'penalty': 'none', 'solver': 'newton-...           0.970085   \n",
       "10     {'C': 5, 'penalty': 'none', 'solver': 'lbfgs'}           0.957265   \n",
       "11  {'C': 5, 'penalty': 'none', 'solver': 'libline...                NaN   \n",
       "12  {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}           0.974359   \n",
       "13      {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}           0.974359   \n",
       "14  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}           0.970085   \n",
       "15  {'C': 10, 'penalty': 'none', 'solver': 'newton...           0.970085   \n",
       "16    {'C': 10, 'penalty': 'none', 'solver': 'lbfgs'}           0.957265   \n",
       "17  {'C': 10, 'penalty': 'none', 'solver': 'liblin...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.965812           0.974359           0.982833   \n",
       "1            0.965812           0.974359           0.982833   \n",
       "2            0.965812           0.961538           0.969957   \n",
       "3            0.957265           0.965812           0.974249   \n",
       "4            0.948718           0.965812           0.944206   \n",
       "5                 NaN                NaN                NaN   \n",
       "6            0.970085           0.965812           0.974249   \n",
       "7            0.970085           0.965812           0.974249   \n",
       "8            0.965812           0.952991           0.965665   \n",
       "9            0.957265           0.965812           0.974249   \n",
       "10           0.948718           0.965812           0.944206   \n",
       "11                NaN                NaN                NaN   \n",
       "12           0.965812           0.965812           0.978541   \n",
       "13           0.965812           0.965812           0.978541   \n",
       "14           0.965812           0.944444           0.969957   \n",
       "15           0.957265           0.965812           0.974249   \n",
       "16           0.948718           0.965812           0.944206   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.969957           0.974359           0.987179   \n",
       "1            0.969957           0.974359           0.987179   \n",
       "2            0.952790           0.957265           0.982906   \n",
       "3            0.961373           0.978632           0.982906   \n",
       "4            0.948498           0.970085           0.970085   \n",
       "5                 NaN                NaN                NaN   \n",
       "6            0.965665           0.974359           0.978632   \n",
       "7            0.969957           0.974359           0.978632   \n",
       "8            0.952790           0.957265           0.978632   \n",
       "9            0.961373           0.978632           0.982906   \n",
       "10           0.948498           0.970085           0.970085   \n",
       "11                NaN                NaN                NaN   \n",
       "12           0.965665           0.978632           0.978632   \n",
       "13           0.965665           0.974359           0.978632   \n",
       "14           0.952790           0.957265           0.974359   \n",
       "15           0.961373           0.978632           0.982906   \n",
       "16           0.948498           0.970085           0.970085   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0            0.970085           0.957082           0.982833   \n",
       "1            0.970085           0.957082           0.982833   \n",
       "2            0.952991           0.948498           0.982833   \n",
       "3            0.974359           0.957082           0.974249   \n",
       "4            0.965812           0.922747           0.969957   \n",
       "5                 NaN                NaN                NaN   \n",
       "6            0.965812           0.965665           0.987124   \n",
       "7            0.965812           0.965665           0.987124   \n",
       "8            0.927350           0.948498           0.969957   \n",
       "9            0.974359           0.957082           0.974249   \n",
       "10           0.965812           0.922747           0.969957   \n",
       "11                NaN                NaN                NaN   \n",
       "12           0.965812           0.965665           0.987124   \n",
       "13           0.965812           0.965665           0.987124   \n",
       "14           0.935897           0.944206           0.965665   \n",
       "15           0.974359           0.957082           0.974249   \n",
       "16           0.965812           0.922747           0.969957   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0             0.970085            0.961538            0.982906   \n",
       "1             0.970085            0.961538            0.982906   \n",
       "2             0.952991            0.961538            0.974359   \n",
       "3             0.965812            0.965812            0.978632   \n",
       "4             0.948718            0.957265            0.965812   \n",
       "5                  NaN                 NaN                 NaN   \n",
       "6             0.957265            0.957265            0.982906   \n",
       "7             0.957265            0.957265            0.982906   \n",
       "8             0.935897            0.940171            0.974359   \n",
       "9             0.965812            0.965812            0.978632   \n",
       "10            0.948718            0.957265            0.965812   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "12            0.957265            0.957265            0.982906   \n",
       "13            0.957265            0.957265            0.982906   \n",
       "14            0.931624            0.940171            0.974359   \n",
       "15            0.965812            0.965812            0.978632   \n",
       "16            0.948718            0.957265            0.965812   \n",
       "17                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.969957            0.957082         0.972313        0.009115   \n",
       "1             0.969957            0.957082         0.972313        0.009115   \n",
       "2             0.961373            0.969957         0.964896        0.010858   \n",
       "3             0.957082            0.935622         0.966598        0.011553   \n",
       "4             0.957082            0.939914         0.955465        0.013029   \n",
       "5                  NaN                 NaN              NaN             NaN   \n",
       "6             0.965665            0.948498         0.969176        0.010046   \n",
       "7             0.965665            0.948498         0.969462        0.010003   \n",
       "8             0.965665            0.957082         0.957481        0.014251   \n",
       "9             0.957082            0.935622         0.966598        0.011553   \n",
       "10            0.957082            0.939914         0.955465        0.013029   \n",
       "11                 NaN                 NaN              NaN             NaN   \n",
       "12            0.965665            0.948498         0.969177        0.010284   \n",
       "13            0.965665            0.944206         0.968606        0.010692   \n",
       "14            0.965665            0.952790         0.956339        0.013886   \n",
       "15            0.957082            0.935622         0.966598        0.011553   \n",
       "16            0.957082            0.939914         0.955465        0.013029   \n",
       "17                 NaN                 NaN              NaN             NaN   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 1            1.000000            1.000000   \n",
       "1                 1            1.000000            1.000000   \n",
       "2                10            0.994647            0.998929   \n",
       "3                 7            1.000000            1.000000   \n",
       "4                13            1.000000            1.000000   \n",
       "5                17                 NaN                 NaN   \n",
       "6                 5            1.000000            1.000000   \n",
       "7                 3            1.000000            1.000000   \n",
       "8                11            0.998929            1.000000   \n",
       "9                 7            1.000000            1.000000   \n",
       "10               13            1.000000            1.000000   \n",
       "11               16                 NaN                 NaN   \n",
       "12                4            1.000000            1.000000   \n",
       "13                6            1.000000            1.000000   \n",
       "14               12            1.000000            1.000000   \n",
       "15                7            1.000000            1.000000   \n",
       "16               13            1.000000            1.000000   \n",
       "17               18                 NaN                 NaN   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             1.000000            1.000000            1.000000   \n",
       "2             0.994647            0.995722            0.996791   \n",
       "3             1.000000            1.000000            1.000000   \n",
       "4             1.000000            1.000000            1.000000   \n",
       "5                  NaN                 NaN                 NaN   \n",
       "6             1.000000            1.000000            1.000000   \n",
       "7             1.000000            1.000000            1.000000   \n",
       "8             1.000000            1.000000            1.000000   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "12            1.000000            1.000000            1.000000   \n",
       "13            1.000000            1.000000            1.000000   \n",
       "14            1.000000            1.000000            1.000000   \n",
       "15            1.000000            1.000000            1.000000   \n",
       "16            1.000000            1.000000            1.000000   \n",
       "17                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             1.000000            1.000000            1.000000   \n",
       "2             0.992505            0.996788            0.995717   \n",
       "3             1.000000            1.000000            1.000000   \n",
       "4             1.000000            1.000000            1.000000   \n",
       "5                  NaN                 NaN                 NaN   \n",
       "6             1.000000            1.000000            1.000000   \n",
       "7             1.000000            1.000000            1.000000   \n",
       "8             1.000000            0.998929            1.000000   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "12            1.000000            1.000000            1.000000   \n",
       "13            1.000000            1.000000            1.000000   \n",
       "14            1.000000            1.000000            1.000000   \n",
       "15            1.000000            1.000000            1.000000   \n",
       "16            1.000000            1.000000            1.000000   \n",
       "17                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split8_train_score  split9_train_score  split10_train_score  \\\n",
       "0             1.000000            1.000000             1.000000   \n",
       "1             1.000000            1.000000             1.000000   \n",
       "2             0.995722            0.996791             0.995717   \n",
       "3             1.000000            1.000000             1.000000   \n",
       "4             1.000000            1.000000             1.000000   \n",
       "5                  NaN                 NaN                  NaN   \n",
       "6             1.000000            1.000000             1.000000   \n",
       "7             1.000000            1.000000             1.000000   \n",
       "8             1.000000            1.000000             1.000000   \n",
       "9             1.000000            1.000000             1.000000   \n",
       "10            1.000000            1.000000             1.000000   \n",
       "11                 NaN                 NaN                  NaN   \n",
       "12            1.000000            1.000000             1.000000   \n",
       "13            1.000000            1.000000             1.000000   \n",
       "14            1.000000            1.000000             1.000000   \n",
       "15            1.000000            1.000000             1.000000   \n",
       "16            1.000000            1.000000             1.000000   \n",
       "17                 NaN                 NaN                  NaN   \n",
       "\n",
       "    split11_train_score  split12_train_score  split13_train_score  \\\n",
       "0              1.000000             1.000000             1.000000   \n",
       "1              1.000000             1.000000             1.000000   \n",
       "2              0.996788             0.995717             0.996791   \n",
       "3              1.000000             1.000000             1.000000   \n",
       "4              1.000000             1.000000             1.000000   \n",
       "5                   NaN                  NaN                  NaN   \n",
       "6              1.000000             1.000000             1.000000   \n",
       "7              1.000000             1.000000             1.000000   \n",
       "8              1.000000             1.000000             1.000000   \n",
       "9              1.000000             1.000000             1.000000   \n",
       "10             1.000000             1.000000             1.000000   \n",
       "11                  NaN                  NaN                  NaN   \n",
       "12             1.000000             1.000000             1.000000   \n",
       "13             1.000000             1.000000             1.000000   \n",
       "14             1.000000             1.000000             1.000000   \n",
       "15             1.000000             1.000000             1.000000   \n",
       "16             1.000000             1.000000             1.000000   \n",
       "17                  NaN                  NaN                  NaN   \n",
       "\n",
       "    split14_train_score  mean_train_score  std_train_score  \n",
       "0              1.000000          1.000000         0.000000  \n",
       "1              1.000000          1.000000         0.000000  \n",
       "2              0.996791          0.996004         0.001381  \n",
       "3              1.000000          1.000000         0.000000  \n",
       "4              1.000000          1.000000         0.000000  \n",
       "5                   NaN               NaN              NaN  \n",
       "6              1.000000          1.000000         0.000000  \n",
       "7              1.000000          1.000000         0.000000  \n",
       "8              0.998930          0.999786         0.000428  \n",
       "9              1.000000          1.000000         0.000000  \n",
       "10             1.000000          1.000000         0.000000  \n",
       "11                  NaN               NaN              NaN  \n",
       "12             1.000000          1.000000         0.000000  \n",
       "13             1.000000          1.000000         0.000000  \n",
       "14             1.000000          1.000000         0.000000  \n",
       "15             1.000000          1.000000         0.000000  \n",
       "16             1.000000          1.000000         0.000000  \n",
       "17                  NaN               NaN              NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création du modèle de régression\n",
    "LR_model = LogisticRegression(verbose=False, max_iter=10000)\n",
    "\n",
    "# Dictionnaire contenant les différents paramètres à essayer\n",
    "LR_params = dict()\n",
    "LR_params['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "LR_params['penalty'] = ['l2', 'none']\n",
    "LR_params['C'] = [0.1, 5, 10]\n",
    "\n",
    "# Création de nos itérations\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "# Création de notre modèle de validation croisée\n",
    "model_cv = GridSearchCV(estimator=LR_model,\n",
    "                        param_grid=LR_params,\n",
    "                        scoring='accuracy',\n",
    "                        cv=kFold,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "# Entrainement du modèle\n",
    "model_cv.fit(x_train, y_train)\n",
    "# cv results\n",
    "pd.set_option('display.max_columns', None)\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "\n",
    "# Stockage du meilleur résultat dans le tableau des résultats\n",
    "Evaluation_Results.iloc[0]['Best Mean Test Score'] = max(cv_results['mean_test_score'])\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e87cf8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "La validation croisée nous permet de determiner les paramètres optimaux pour notre modèle d'apprentissage.\n",
    "Les résultats de nos tests avec de nombreux paramètres différents (dont la plupart ne sont pas présent dans l'exemple ci-dessus).\n",
    "* Le **paramètre C** correspond à l'inverse de la force de régularisation des données. Plus ce paramètre est grand, plus le risque d'overfitting est grand. Une valeur de 0.1 semble être optimale.\n",
    "* Le **paramètre de pénalité** permet de réduire les coefficients θ. On remarque une perte de précision si l'on n'applique pas de pénalité. La meilleure pénalité semble être la norme L2.\n",
    "* Le **solveur** correspond à l'algorithme d'optimisation utilisé pour l'entrainement. Dans notre cas, lbfgs permet d'obtenir la precision la plus élevée malgré un temps d'entrainement significativement plus long que ses concurrents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f3350",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Classification naïve bayésienne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fad82372",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011450</td>\n",
       "      <td>0.008957</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.004119</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.853594</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.005444</td>\n",
       "      <td>0.003133</td>\n",
       "      <td>0.006265</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.863296</td>\n",
       "      <td>0.015941</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004167</td>\n",
       "      <td>0.006910</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.864722</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.006255</td>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.006249</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.864154</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.003699</td>\n",
       "      <td>0.006330</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>0.008961</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.888412</td>\n",
       "      <td>0.864442</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.859300</td>\n",
       "      <td>0.013215</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007733</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.005267</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.857587</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.011450      0.008957         0.001478        0.004119           0   \n",
       "1       0.002959      0.005444         0.003133        0.006265      0.0001   \n",
       "2       0.004167      0.006910         0.000000        0.000000       0.001   \n",
       "3       0.003128      0.006255         0.003125        0.006249        0.01   \n",
       "4       0.003699      0.006330         0.004166        0.008961         0.1   \n",
       "5       0.006371      0.007587         0.000000        0.000000         0.5   \n",
       "6       0.005500      0.007733         0.002112        0.005267         1.0   \n",
       "\n",
       "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0       {'alpha': 0}           0.837607           0.871795           0.854701   \n",
       "1  {'alpha': 0.0001}           0.841880           0.884615           0.854701   \n",
       "2   {'alpha': 0.001}           0.846154           0.884615           0.854701   \n",
       "3    {'alpha': 0.01}           0.850427           0.884615           0.854701   \n",
       "4     {'alpha': 0.1}           0.854701           0.880342           0.854701   \n",
       "5     {'alpha': 0.5}           0.850427           0.876068           0.850427   \n",
       "6     {'alpha': 1.0}           0.850427           0.871795           0.850427   \n",
       "\n",
       "   split3_test_score  split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0           0.836910           0.845494           0.871795           0.850427   \n",
       "1           0.849785           0.854077           0.876068           0.880342   \n",
       "2           0.849785           0.858369           0.876068           0.884615   \n",
       "3           0.849785           0.858369           0.867521           0.876068   \n",
       "4           0.849785           0.858369           0.863248           0.871795   \n",
       "5           0.845494           0.845494           0.858974           0.867521   \n",
       "6           0.841202           0.845494           0.858974           0.867521   \n",
       "\n",
       "   split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0           0.854701           0.819742           0.875536   \n",
       "1           0.863248           0.828326           0.879828   \n",
       "2           0.867521           0.836910           0.875536   \n",
       "3           0.867521           0.841202           0.875536   \n",
       "4           0.867521           0.841202           0.884120   \n",
       "5           0.867521           0.836910           0.884120   \n",
       "6           0.867521           0.832618           0.879828   \n",
       "\n",
       "   split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0            0.833333            0.854701            0.858974   \n",
       "1            0.854701            0.858974            0.867521   \n",
       "2            0.854701            0.858974            0.867521   \n",
       "3            0.858974            0.858974            0.863248   \n",
       "4            0.867521            0.858974            0.854701   \n",
       "5            0.871795            0.850427            0.854701   \n",
       "6            0.871795            0.841880            0.854701   \n",
       "\n",
       "   split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.866953            0.871245         0.853594        0.015985   \n",
       "1            0.871245            0.884120         0.863296        0.015941   \n",
       "2            0.871245            0.884120         0.864722        0.014346   \n",
       "3            0.871245            0.884120         0.864154        0.012277   \n",
       "4            0.871245            0.888412         0.864442        0.012759   \n",
       "5            0.854077            0.875536         0.859300        0.013215   \n",
       "6            0.854077            0.875536         0.857587        0.013731   \n",
       "\n",
       "   rank_test_score  \n",
       "0                7  \n",
       "1                4  \n",
       "2                1  \n",
       "3                3  \n",
       "4                2  \n",
       "5                5  \n",
       "6                6  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model = BernoulliNB()\n",
    "\n",
    "NB_params = {'alpha': [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]}\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(NB_model, NB_params, n_iter=7, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(RCV.cv_results_)\n",
    "\n",
    "# Stockage du meilleur résultat dans le tableau des résultats\n",
    "Evaluation_Results.iloc[1]['Best Mean Test Score'] = max(cv_results['mean_test_score'])\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd587b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Le seul paramètre testé dans ce modèle, alpha, correspond à la force du lissage de Laplace a appliqué au modèle.\n",
    "En d'autres termes, ce paramètre permet de palier la présence d'une caractéristique dans le jeu de test qui n'existe pas dans le jeu d'entrainement.\n",
    "> https://towardsdatascience.com/laplace-smoothing-in-na%C3%AFve-bayes-algorithm-9c237a8bdece\n",
    "\n",
    "Au vu des résultats, le paramètre alpha semble être optimal autour de 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49e2522",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Classification par arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1895da67",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.001754</td>\n",
       "      <td>0.003208</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.484979</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.442060</td>\n",
       "      <td>0.453227</td>\n",
       "      <td>0.025252</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 1, ...</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.506438</td>\n",
       "      <td>0.562232</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.517094</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>0.502146</td>\n",
       "      <td>0.534188</td>\n",
       "      <td>0.440171</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.467811</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.507131</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.007585</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.002013</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.484979</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.467811</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.442060</td>\n",
       "      <td>0.452941</td>\n",
       "      <td>0.025060</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003125</td>\n",
       "      <td>0.004202</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.002041</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 2, ...</td>\n",
       "      <td>0.517094</td>\n",
       "      <td>0.568376</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.480687</td>\n",
       "      <td>0.369099</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.534188</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.367521</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.572650</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>0.502146</td>\n",
       "      <td>0.496827</td>\n",
       "      <td>0.061387</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006497</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.002026</td>\n",
       "      <td>best</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.484979</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.467811</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.442060</td>\n",
       "      <td>0.452941</td>\n",
       "      <td>0.025060</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 3, ...</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>0.502146</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.572650</td>\n",
       "      <td>0.510730</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.467811</td>\n",
       "      <td>0.515021</td>\n",
       "      <td>0.496302</td>\n",
       "      <td>0.044431</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006084</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>0.000541</td>\n",
       "      <td>0.002025</td>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.484979</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.442060</td>\n",
       "      <td>0.453227</td>\n",
       "      <td>0.025252</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 4, ...</td>\n",
       "      <td>0.418803</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.497854</td>\n",
       "      <td>0.459227</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.491453</td>\n",
       "      <td>0.454936</td>\n",
       "      <td>0.527897</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.431624</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.523605</td>\n",
       "      <td>0.416309</td>\n",
       "      <td>0.480308</td>\n",
       "      <td>0.036656</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.013635</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.814189</td>\n",
       "      <td>0.033082</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>0.000677</td>\n",
       "      <td>0.002036</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 1, ...</td>\n",
       "      <td>0.790598</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.831629</td>\n",
       "      <td>0.024134</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.014568</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.002829</td>\n",
       "      <td>0.010055</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.785408</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.804484</td>\n",
       "      <td>0.031329</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008216</td>\n",
       "      <td>0.007644</td>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 2, ...</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.813359</td>\n",
       "      <td>0.024801</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.014849</td>\n",
       "      <td>0.006752</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>best</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.747863</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.802208</td>\n",
       "      <td>0.029617</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.004726</td>\n",
       "      <td>0.004829</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.002037</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 3, ...</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.742489</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.802776</td>\n",
       "      <td>0.023656</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.012959</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.739316</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.759657</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.785408</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.776824</td>\n",
       "      <td>0.802766</td>\n",
       "      <td>0.032953</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.005125</td>\n",
       "      <td>0.004358</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 4, ...</td>\n",
       "      <td>0.790598</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.755365</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.800812</td>\n",
       "      <td>0.027118</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.006739</td>\n",
       "      <td>0.004015</td>\n",
       "      <td>0.000673</td>\n",
       "      <td>0.002035</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>0.553648</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.566524</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.003241</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 1, ...</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.600858</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.523605</td>\n",
       "      <td>0.502146</td>\n",
       "      <td>0.517705</td>\n",
       "      <td>0.042357</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.007833</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>0.553648</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.566524</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.003128</td>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 2, ...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.506438</td>\n",
       "      <td>0.527897</td>\n",
       "      <td>0.534188</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.553648</td>\n",
       "      <td>0.553648</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.497854</td>\n",
       "      <td>0.519403</td>\n",
       "      <td>0.039906</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.006635</td>\n",
       "      <td>0.004475</td>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.002064</td>\n",
       "      <td>best</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>0.553648</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.566524</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002571</td>\n",
       "      <td>0.003425</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.002015</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 3, ...</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.480687</td>\n",
       "      <td>0.527897</td>\n",
       "      <td>0.487179</td>\n",
       "      <td>0.491453</td>\n",
       "      <td>0.632479</td>\n",
       "      <td>0.454936</td>\n",
       "      <td>0.570815</td>\n",
       "      <td>0.457265</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.491453</td>\n",
       "      <td>0.523605</td>\n",
       "      <td>0.536481</td>\n",
       "      <td>0.519685</td>\n",
       "      <td>0.052629</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.007160</td>\n",
       "      <td>0.004114</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.575107</td>\n",
       "      <td>0.553648</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.566524</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.002026</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>0.002045</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 4, ...</td>\n",
       "      <td>0.517094</td>\n",
       "      <td>0.521368</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.540773</td>\n",
       "      <td>0.517094</td>\n",
       "      <td>0.470085</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.587983</td>\n",
       "      <td>0.523605</td>\n",
       "      <td>0.585470</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.540773</td>\n",
       "      <td>0.476395</td>\n",
       "      <td>0.533964</td>\n",
       "      <td>0.033680</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.019569</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.825046</td>\n",
       "      <td>0.040040</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.005675</td>\n",
       "      <td>0.004564</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 1, ...</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.827326</td>\n",
       "      <td>0.025063</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.033079</td>\n",
       "      <td>0.054565</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.755365</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.819632</td>\n",
       "      <td>0.037955</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.004490</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.002048</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 2, ...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.776824</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.785408</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.809056</td>\n",
       "      <td>0.022146</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.021869</td>\n",
       "      <td>0.021266</td>\n",
       "      <td>0.001077</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>best</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.818197</td>\n",
       "      <td>0.038561</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.004696</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 3, ...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.823615</td>\n",
       "      <td>0.031864</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.015668</td>\n",
       "      <td>0.004714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.785408</td>\n",
       "      <td>0.815342</td>\n",
       "      <td>0.035919</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.006887</td>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 4, ...</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.812215</td>\n",
       "      <td>0.022122</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.006213      0.005931         0.001754        0.003208   \n",
       "1        0.002709      0.003675         0.000674        0.002038   \n",
       "2        0.007585      0.004019         0.000538        0.002013   \n",
       "3        0.003125      0.004202         0.000674        0.002041   \n",
       "4        0.006497      0.005644         0.000541        0.002026   \n",
       "5        0.001899      0.003354         0.001076        0.002744   \n",
       "6        0.006084      0.004497         0.000541        0.002025   \n",
       "7        0.002706      0.003358         0.000137        0.000514   \n",
       "8        0.013635      0.004467         0.000537        0.002010   \n",
       "9        0.004720      0.004341         0.000677        0.002036   \n",
       "10       0.014568      0.005441         0.002829        0.010055   \n",
       "11       0.008216      0.007644         0.001355        0.003022   \n",
       "12       0.014849      0.006752         0.000137        0.000513   \n",
       "13       0.004726      0.004829         0.000672        0.002037   \n",
       "14       0.012959      0.003590         0.000000        0.000000   \n",
       "15       0.005125      0.004358         0.000271        0.000690   \n",
       "16       0.006739      0.004015         0.000673        0.002035   \n",
       "17       0.003241      0.004099         0.000000        0.000000   \n",
       "18       0.007833      0.003689         0.000136        0.000510   \n",
       "19       0.002026      0.003128         0.000138        0.000516   \n",
       "20       0.006635      0.004475         0.000810        0.002064   \n",
       "21       0.002571      0.003425         0.000538        0.002015   \n",
       "22       0.007160      0.004114         0.000141        0.000511   \n",
       "23       0.002026      0.003131         0.000679        0.002045   \n",
       "24       0.019569      0.011299         0.000672        0.002031   \n",
       "25       0.005675      0.004564         0.000538        0.002014   \n",
       "26       0.033079      0.054565         0.000538        0.002014   \n",
       "27       0.004871      0.004490         0.000675        0.002048   \n",
       "28       0.021869      0.021266         0.001077        0.002746   \n",
       "29       0.005539      0.004696         0.000000        0.000000   \n",
       "30       0.015668      0.004714         0.000000        0.000000   \n",
       "31       0.006887      0.004159         0.000000        0.000000   \n",
       "\n",
       "   param_splitter param_min_samples_leaf param_max_depth param_criterion  \\\n",
       "0            best                      1               3            gini   \n",
       "1          random                      1               3            gini   \n",
       "2            best                      2               3            gini   \n",
       "3          random                      2               3            gini   \n",
       "4            best                      3               3            gini   \n",
       "5          random                      3               3            gini   \n",
       "6            best                      4               3            gini   \n",
       "7          random                      4               3            gini   \n",
       "8            best                      1            None            gini   \n",
       "9          random                      1            None            gini   \n",
       "10           best                      2            None            gini   \n",
       "11         random                      2            None            gini   \n",
       "12           best                      3            None            gini   \n",
       "13         random                      3            None            gini   \n",
       "14           best                      4            None            gini   \n",
       "15         random                      4            None            gini   \n",
       "16           best                      1               3         entropy   \n",
       "17         random                      1               3         entropy   \n",
       "18           best                      2               3         entropy   \n",
       "19         random                      2               3         entropy   \n",
       "20           best                      3               3         entropy   \n",
       "21         random                      3               3         entropy   \n",
       "22           best                      4               3         entropy   \n",
       "23         random                      4               3         entropy   \n",
       "24           best                      1            None         entropy   \n",
       "25         random                      1            None         entropy   \n",
       "26           best                      2            None         entropy   \n",
       "27         random                      2            None         entropy   \n",
       "28           best                      3            None         entropy   \n",
       "29         random                      3            None         entropy   \n",
       "30           best                      4            None         entropy   \n",
       "31         random                      4            None         entropy   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'splitter': 'best', 'min_samples_leaf': 1, 'm...           0.410256   \n",
       "1   {'splitter': 'random', 'min_samples_leaf': 1, ...           0.504274   \n",
       "2   {'splitter': 'best', 'min_samples_leaf': 2, 'm...           0.410256   \n",
       "3   {'splitter': 'random', 'min_samples_leaf': 2, ...           0.517094   \n",
       "4   {'splitter': 'best', 'min_samples_leaf': 3, 'm...           0.410256   \n",
       "5   {'splitter': 'random', 'min_samples_leaf': 3, ...           0.470085   \n",
       "6   {'splitter': 'best', 'min_samples_leaf': 4, 'm...           0.410256   \n",
       "7   {'splitter': 'random', 'min_samples_leaf': 4, ...           0.418803   \n",
       "8   {'splitter': 'best', 'min_samples_leaf': 1, 'm...           0.769231   \n",
       "9   {'splitter': 'random', 'min_samples_leaf': 1, ...           0.790598   \n",
       "10  {'splitter': 'best', 'min_samples_leaf': 2, 'm...           0.752137   \n",
       "11  {'splitter': 'random', 'min_samples_leaf': 2, ...           0.773504   \n",
       "12  {'splitter': 'best', 'min_samples_leaf': 3, 'm...           0.747863   \n",
       "13  {'splitter': 'random', 'min_samples_leaf': 3, ...           0.803419   \n",
       "14  {'splitter': 'best', 'min_samples_leaf': 4, 'm...           0.739316   \n",
       "15  {'splitter': 'random', 'min_samples_leaf': 4, ...           0.790598   \n",
       "16  {'splitter': 'best', 'min_samples_leaf': 1, 'm...           0.495726   \n",
       "17  {'splitter': 'random', 'min_samples_leaf': 1, ...           0.487179   \n",
       "18  {'splitter': 'best', 'min_samples_leaf': 2, 'm...           0.495726   \n",
       "19  {'splitter': 'random', 'min_samples_leaf': 2, ...           0.500000   \n",
       "20  {'splitter': 'best', 'min_samples_leaf': 3, 'm...           0.495726   \n",
       "21  {'splitter': 'random', 'min_samples_leaf': 3, ...           0.461538   \n",
       "22  {'splitter': 'best', 'min_samples_leaf': 4, 'm...           0.495726   \n",
       "23  {'splitter': 'random', 'min_samples_leaf': 4, ...           0.517094   \n",
       "24  {'splitter': 'best', 'min_samples_leaf': 1, 'm...           0.769231   \n",
       "25  {'splitter': 'random', 'min_samples_leaf': 1, ...           0.820513   \n",
       "26  {'splitter': 'best', 'min_samples_leaf': 2, 'm...           0.782051   \n",
       "27  {'splitter': 'random', 'min_samples_leaf': 2, ...           0.777778   \n",
       "28  {'splitter': 'best', 'min_samples_leaf': 3, 'm...           0.764957   \n",
       "29  {'splitter': 'random', 'min_samples_leaf': 3, ...           0.777778   \n",
       "30  {'splitter': 'best', 'min_samples_leaf': 4, 'm...           0.777778   \n",
       "31  {'splitter': 'random', 'min_samples_leaf': 4, ...           0.782051   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.470085           0.410256           0.484979   \n",
       "1            0.538462           0.465812           0.506438   \n",
       "2            0.470085           0.410256           0.484979   \n",
       "3            0.568376           0.500000           0.480687   \n",
       "4            0.470085           0.410256           0.484979   \n",
       "5            0.500000           0.401709           0.502146   \n",
       "6            0.470085           0.410256           0.484979   \n",
       "7            0.521368           0.495726           0.497854   \n",
       "8            0.850427           0.854701           0.793991   \n",
       "9            0.850427           0.850427           0.845494   \n",
       "10           0.807692           0.841880           0.802575   \n",
       "11           0.846154           0.837607           0.798283   \n",
       "12           0.824786           0.837607           0.793991   \n",
       "13           0.820513           0.811966           0.793991   \n",
       "14           0.841880           0.829060           0.798283   \n",
       "15           0.794872           0.829060           0.815451   \n",
       "16           0.529915           0.555556           0.575107   \n",
       "17           0.529915           0.457265           0.600858   \n",
       "18           0.529915           0.555556           0.575107   \n",
       "19           0.470085           0.564103           0.506438   \n",
       "20           0.529915           0.555556           0.575107   \n",
       "21           0.615385           0.551282           0.480687   \n",
       "22           0.529915           0.555556           0.575107   \n",
       "23           0.521368           0.538462           0.545064   \n",
       "24           0.897436           0.820513           0.836910   \n",
       "25           0.871795           0.888889           0.824034   \n",
       "26           0.837607           0.811966           0.854077   \n",
       "27           0.833333           0.846154           0.828326   \n",
       "28           0.850427           0.824786           0.828326   \n",
       "29           0.816239           0.871795           0.802575   \n",
       "30           0.863248           0.807692           0.832618   \n",
       "31           0.846154           0.811966           0.828326   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.463519           0.423077           0.457265   \n",
       "1            0.562232           0.474359           0.517094   \n",
       "2            0.463519           0.423077           0.457265   \n",
       "3            0.369099           0.538462           0.534188   \n",
       "4            0.463519           0.423077           0.457265   \n",
       "5            0.493562           0.538462           0.474359   \n",
       "6            0.463519           0.423077           0.457265   \n",
       "7            0.459227           0.521368           0.487179   \n",
       "8            0.802575           0.841880           0.850427   \n",
       "9            0.806867           0.841880           0.841880   \n",
       "10           0.785408           0.837607           0.846154   \n",
       "11           0.841202           0.807692           0.803419   \n",
       "12           0.781116           0.837607           0.829060   \n",
       "13           0.789700           0.816239           0.829060   \n",
       "14           0.759657           0.837607           0.837607   \n",
       "15           0.806867           0.841880           0.786325   \n",
       "16           0.553648           0.576923           0.538462   \n",
       "17           0.493562           0.589744           0.559829   \n",
       "18           0.553648           0.576923           0.538462   \n",
       "19           0.527897           0.534188           0.465812   \n",
       "20           0.553648           0.576923           0.538462   \n",
       "21           0.527897           0.487179           0.491453   \n",
       "22           0.553648           0.576923           0.538462   \n",
       "23           0.540773           0.517094           0.470085   \n",
       "24           0.819742           0.833333           0.803419   \n",
       "25           0.793991           0.829060           0.824786   \n",
       "26           0.819742           0.841880           0.799145   \n",
       "27           0.793991           0.816239           0.786325   \n",
       "28           0.832618           0.841880           0.799145   \n",
       "29           0.811159           0.850427           0.876068   \n",
       "30           0.819742           0.829060           0.811966   \n",
       "31           0.793991           0.824786           0.833333   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0            0.457265           0.472103           0.472103   \n",
       "1            0.521368           0.519313           0.502146   \n",
       "2            0.457265           0.472103           0.467811   \n",
       "3            0.555556           0.519313           0.472103   \n",
       "4            0.457265           0.472103           0.467811   \n",
       "5            0.572650           0.510730           0.532189   \n",
       "6            0.457265           0.472103           0.472103   \n",
       "7            0.491453           0.454936           0.527897   \n",
       "8            0.769231           0.772532           0.781116   \n",
       "9            0.803419           0.836910           0.828326   \n",
       "10           0.824786           0.751073           0.768240   \n",
       "11           0.794872           0.768240           0.793991   \n",
       "12           0.799145           0.768240           0.768240   \n",
       "13           0.841880           0.742489           0.815451   \n",
       "14           0.811966           0.785408           0.751073   \n",
       "15           0.760684           0.755365           0.819742   \n",
       "16           0.581197           0.532189           0.566524   \n",
       "17           0.538462           0.532189           0.493562   \n",
       "18           0.581197           0.532189           0.566524   \n",
       "19           0.461538           0.553648           0.553648   \n",
       "20           0.581197           0.532189           0.566524   \n",
       "21           0.632479           0.454936           0.570815   \n",
       "22           0.581197           0.532189           0.566524   \n",
       "23           0.551282           0.587983           0.523605   \n",
       "24           0.858974           0.768240           0.828326   \n",
       "25           0.794872           0.815451           0.828326   \n",
       "26           0.854701           0.755365           0.815451   \n",
       "27           0.816239           0.776824           0.789700   \n",
       "28           0.846154           0.751073           0.811159   \n",
       "29           0.854701           0.836910           0.781116   \n",
       "30           0.846154           0.733906           0.824034   \n",
       "31           0.820513           0.806867           0.802575   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0             0.423077            0.452991            0.465812   \n",
       "1             0.534188            0.440171            0.581197   \n",
       "2             0.423077            0.452991            0.465812   \n",
       "3             0.367521            0.435897            0.572650   \n",
       "4             0.423077            0.452991            0.465812   \n",
       "5             0.435897            0.564103            0.465812   \n",
       "6             0.423077            0.452991            0.465812   \n",
       "7             0.495726            0.431624            0.461538   \n",
       "8             0.786325            0.846154            0.841880   \n",
       "9             0.841880            0.786325            0.850427   \n",
       "10            0.777778            0.820513            0.820513   \n",
       "11            0.820513            0.803419            0.824786   \n",
       "12            0.773504            0.816239            0.816239   \n",
       "13            0.773504            0.786325            0.816239   \n",
       "14            0.794872            0.811966            0.829060   \n",
       "15            0.777778            0.777778            0.803419   \n",
       "16            0.559829            0.576923            0.581197   \n",
       "17            0.529915            0.452991            0.474359   \n",
       "18            0.559829            0.576923            0.581197   \n",
       "19            0.551282            0.581197            0.559829   \n",
       "20            0.559829            0.576923            0.581197   \n",
       "21            0.457265            0.512821            0.491453   \n",
       "22            0.559829            0.576923            0.581197   \n",
       "23            0.585470            0.512821            0.581197   \n",
       "24            0.769231            0.905983            0.807692   \n",
       "25            0.846154            0.803419            0.816239   \n",
       "26            0.769231            0.905983            0.782051   \n",
       "27            0.807692            0.837607            0.829060   \n",
       "28            0.769231            0.910256            0.794872   \n",
       "29            0.764957            0.837607            0.816239   \n",
       "30            0.777778            0.871795            0.794872   \n",
       "31            0.756410            0.803419            0.829060   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.493562            0.442060         0.453227        0.025252   \n",
       "1             0.467811            0.472103         0.507131        0.037200   \n",
       "2             0.493562            0.442060         0.452941        0.025060   \n",
       "3             0.519313            0.502146         0.496827        0.061387   \n",
       "4             0.493562            0.442060         0.452941        0.025060   \n",
       "5             0.467811            0.515021         0.496302        0.044431   \n",
       "6             0.493562            0.442060         0.453227        0.025252   \n",
       "7             0.523605            0.416309         0.480308        0.036656   \n",
       "8             0.849785            0.802575         0.814189        0.033082   \n",
       "9             0.875536            0.824034         0.831629        0.024134   \n",
       "10            0.841202            0.789700         0.804484        0.031329   \n",
       "11            0.845494            0.841202         0.813359        0.024801   \n",
       "12            0.849785            0.789700         0.802208        0.029617   \n",
       "13            0.789700            0.811159         0.802776        0.023656   \n",
       "14            0.836910            0.776824         0.802766        0.032953   \n",
       "15            0.854077            0.798283         0.800812        0.027118   \n",
       "16            0.549356            0.545064         0.554508        0.023036   \n",
       "17            0.523605            0.502146         0.517705        0.042357   \n",
       "18            0.549356            0.545064         0.554508        0.023036   \n",
       "19            0.463519            0.497854         0.519403        0.039906   \n",
       "20            0.549356            0.545064         0.554508        0.023036   \n",
       "21            0.523605            0.536481         0.519685        0.052629   \n",
       "22            0.549356            0.545064         0.554508        0.023036   \n",
       "23            0.540773            0.476395         0.533964        0.033680   \n",
       "24            0.845494            0.811159         0.825046        0.040040   \n",
       "25            0.815451            0.836910         0.827326        0.025063   \n",
       "26            0.849785            0.815451         0.819632        0.037955   \n",
       "27            0.785408            0.811159         0.809056        0.022146   \n",
       "28            0.836910            0.811159         0.818197        0.038561   \n",
       "29            0.828326            0.828326         0.823615        0.031864   \n",
       "30            0.854077            0.785408         0.815342        0.035919   \n",
       "31            0.811159            0.832618         0.812215        0.022122   \n",
       "\n",
       "    rank_test_score  \n",
       "0                29  \n",
       "1                25  \n",
       "2                31  \n",
       "3                26  \n",
       "4                31  \n",
       "5                27  \n",
       "6                29  \n",
       "7                28  \n",
       "8                 8  \n",
       "9                 1  \n",
       "10               12  \n",
       "11                9  \n",
       "12               15  \n",
       "13               13  \n",
       "14               14  \n",
       "15               16  \n",
       "16               17  \n",
       "17               24  \n",
       "18               17  \n",
       "19               23  \n",
       "20               17  \n",
       "21               22  \n",
       "22               17  \n",
       "23               21  \n",
       "24                3  \n",
       "25                2  \n",
       "26                5  \n",
       "27               11  \n",
       "28                6  \n",
       "29                4  \n",
       "30                7  \n",
       "31               10  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DT_model = DecisionTreeClassifier()\n",
    "\n",
    "DT_params = dict()\n",
    "DT_params['max_depth'] = [3, None]\n",
    "DT_params['min_samples_leaf'] = [1, 2, 3, 4]\n",
    "DT_params['criterion'] = [\"gini\", \"entropy\"]\n",
    "DT_params['splitter'] = [\"best\", \"random\"]\n",
    "\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "RCV = RandomizedSearchCV(DT_model, DT_params, n_iter=32, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "DT = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(DT.cv_results_)\n",
    "\n",
    "# Stockage du meilleur résultat dans le tableau des résultats\n",
    "Evaluation_Results.iloc[2]['Best Mean Test Score'] = max(cv_results['mean_test_score'])\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c633587c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Les paramètres testés pour ce modèle sont :\n",
    "-le max_depth, correspondant à la profondeur de l'arbre qui doit être illimité pour garantir une précision maximale du modèle.\n",
    "-le min_samples_leaf, correspondant au nombre d'échantillons minimal par feuille qui doit être de 1.\n",
    "-le criterion est une fonction permettant de mesurer la qualité d'un split, nous obtenons des meilleurs résultats avec 'entropy'.\n",
    "-le splitter est la méthode choisie pour selectionner le split à chaque noeud. Modifier ce paramètre ne semble pas impacter significativement les résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb7306a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Classification par boosting de gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b20e666a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.093190</td>\n",
       "      <td>0.860550</td>\n",
       "      <td>0.012862</td>\n",
       "      <td>0.021001</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 1, 'learnin...</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.927350</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.914163</td>\n",
       "      <td>0.932929</td>\n",
       "      <td>0.017663</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.055762</td>\n",
       "      <td>0.510371</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.004839</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 1, 'learnin...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.948627</td>\n",
       "      <td>0.018354</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.860086</td>\n",
       "      <td>0.229322</td>\n",
       "      <td>0.014884</td>\n",
       "      <td>0.015673</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 1, 'learnin...</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.955763</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.968700</td>\n",
       "      <td>0.156967</td>\n",
       "      <td>0.005134</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.957192</td>\n",
       "      <td>0.013986</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.202521</td>\n",
       "      <td>0.844458</td>\n",
       "      <td>0.008908</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.962611</td>\n",
       "      <td>0.010786</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.668616</td>\n",
       "      <td>1.809543</td>\n",
       "      <td>0.019193</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.964896</td>\n",
       "      <td>0.007843</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.652802</td>\n",
       "      <td>0.100150</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>0.004450</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.955761</td>\n",
       "      <td>0.010337</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.877133</td>\n",
       "      <td>0.086036</td>\n",
       "      <td>0.012560</td>\n",
       "      <td>0.003485</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.958332</td>\n",
       "      <td>0.011427</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.416941</td>\n",
       "      <td>0.953988</td>\n",
       "      <td>0.015523</td>\n",
       "      <td>0.004341</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.962040</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.173314</td>\n",
       "      <td>0.914414</td>\n",
       "      <td>0.065880</td>\n",
       "      <td>0.208697</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.896996</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.937783</td>\n",
       "      <td>0.017481</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.695514</td>\n",
       "      <td>0.217784</td>\n",
       "      <td>0.013624</td>\n",
       "      <td>0.003643</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.901288</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.942632</td>\n",
       "      <td>0.019145</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.614617</td>\n",
       "      <td>0.746456</td>\n",
       "      <td>0.013660</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.896996</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.927350</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.944063</td>\n",
       "      <td>0.017937</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.583105</td>\n",
       "      <td>0.034720</td>\n",
       "      <td>0.003242</td>\n",
       "      <td>0.004099</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 1, 'learnin...</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.951193</td>\n",
       "      <td>0.017746</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.218032</td>\n",
       "      <td>0.299158</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>0.004410</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 1, 'learnin...</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.956045</td>\n",
       "      <td>0.012067</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.342180</td>\n",
       "      <td>0.712112</td>\n",
       "      <td>0.011252</td>\n",
       "      <td>0.002120</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 1, 'learnin...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>0.009452</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.348171</td>\n",
       "      <td>0.196909</td>\n",
       "      <td>0.005779</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.963466</td>\n",
       "      <td>0.011380</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>9.051839</td>\n",
       "      <td>0.366722</td>\n",
       "      <td>0.010906</td>\n",
       "      <td>0.008744</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.966322</td>\n",
       "      <td>0.009226</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13.239889</td>\n",
       "      <td>0.474504</td>\n",
       "      <td>0.012981</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965467</td>\n",
       "      <td>0.007883</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.197802</td>\n",
       "      <td>0.365063</td>\n",
       "      <td>0.007930</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.962330</td>\n",
       "      <td>0.010611</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.227695</td>\n",
       "      <td>0.669797</td>\n",
       "      <td>0.008950</td>\n",
       "      <td>0.002058</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.962903</td>\n",
       "      <td>0.010885</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10.288133</td>\n",
       "      <td>0.217459</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.963190</td>\n",
       "      <td>0.011331</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.944617</td>\n",
       "      <td>0.111439</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.941490</td>\n",
       "      <td>0.011889</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.693704</td>\n",
       "      <td>0.119217</td>\n",
       "      <td>0.008227</td>\n",
       "      <td>0.003161</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>0.014399</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9.198305</td>\n",
       "      <td>0.172457</td>\n",
       "      <td>0.010368</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.943214</td>\n",
       "      <td>0.013553</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.534527</td>\n",
       "      <td>0.022766</td>\n",
       "      <td>0.005549</td>\n",
       "      <td>0.004089</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 1, 'learnin...</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.953477</td>\n",
       "      <td>0.014495</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.041128</td>\n",
       "      <td>0.053561</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.004347</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 1, 'learnin...</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957479</td>\n",
       "      <td>0.011732</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>12.426462</td>\n",
       "      <td>0.090970</td>\n",
       "      <td>0.012847</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 1, 'learnin...</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957480</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4.139422</td>\n",
       "      <td>0.032950</td>\n",
       "      <td>0.003518</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.966037</td>\n",
       "      <td>0.007731</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.264264</td>\n",
       "      <td>0.172930</td>\n",
       "      <td>0.007562</td>\n",
       "      <td>0.003407</td>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.966041</td>\n",
       "      <td>0.008751</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>9.704475</td>\n",
       "      <td>0.336650</td>\n",
       "      <td>0.009597</td>\n",
       "      <td>0.002020</td>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 2, 'learnin...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.967180</td>\n",
       "      <td>0.007911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4.969511</td>\n",
       "      <td>0.101094</td>\n",
       "      <td>0.005678</td>\n",
       "      <td>0.004315</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.962614</td>\n",
       "      <td>0.009945</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.919818</td>\n",
       "      <td>0.300820</td>\n",
       "      <td>0.008523</td>\n",
       "      <td>0.004811</td>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.962616</td>\n",
       "      <td>0.010651</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>8.141540</td>\n",
       "      <td>0.157731</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.003218</td>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.966042</td>\n",
       "      <td>0.010760</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4.214375</td>\n",
       "      <td>0.098578</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.947487</td>\n",
       "      <td>0.015434</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4.928433</td>\n",
       "      <td>0.083142</td>\n",
       "      <td>0.006074</td>\n",
       "      <td>0.004241</td>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.944341</td>\n",
       "      <td>0.016194</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>7.069309</td>\n",
       "      <td>0.401386</td>\n",
       "      <td>0.007227</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>{'n_estimators': 500, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948344</td>\n",
       "      <td>0.013487</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        3.093190      0.860550         0.012862        0.021001   \n",
       "1        5.055762      0.510371         0.005413        0.004839   \n",
       "2       11.860086      0.229322         0.014884        0.015673   \n",
       "3        3.968700      0.156967         0.005134        0.004608   \n",
       "4        8.202521      0.844458         0.008908        0.002739   \n",
       "5       20.668616      1.809543         0.019193        0.002078   \n",
       "6        5.652802      0.100150         0.005535        0.004450   \n",
       "7       10.877133      0.086036         0.012560        0.003485   \n",
       "8       16.416941      0.953988         0.015523        0.004341   \n",
       "9       10.173314      0.914414         0.065880        0.208697   \n",
       "10      11.695514      0.217784         0.013624        0.003643   \n",
       "11      14.614617      0.746456         0.013660        0.004233   \n",
       "12       2.583105      0.034720         0.003242        0.004099   \n",
       "13       5.218032      0.299158         0.005953        0.004410   \n",
       "14      13.342180      0.712112         0.011252        0.002120   \n",
       "15       4.348171      0.196909         0.005779        0.003194   \n",
       "16       9.051839      0.366722         0.010906        0.008744   \n",
       "17      13.239889      0.474504         0.012981        0.003288   \n",
       "18       6.197802      0.365063         0.007930        0.002656   \n",
       "19       8.227695      0.669797         0.008950        0.002058   \n",
       "20      10.288133      0.217459         0.010133        0.000023   \n",
       "21       5.944617      0.111439         0.008089        0.003763   \n",
       "22       6.693704      0.119217         0.008227        0.003161   \n",
       "23       9.198305      0.172457         0.010368        0.002399   \n",
       "24       2.534527      0.022766         0.005549        0.004089   \n",
       "25       5.041128      0.053561         0.004608        0.004347   \n",
       "26      12.426462      0.090970         0.012847        0.003960   \n",
       "27       4.139422      0.032950         0.003518        0.003944   \n",
       "28       7.264264      0.172930         0.007562        0.003407   \n",
       "29       9.704475      0.336650         0.009597        0.002020   \n",
       "30       4.969511      0.101094         0.005678        0.004315   \n",
       "31       5.919818      0.300820         0.008523        0.004811   \n",
       "32       8.141540      0.157731         0.008297        0.003218   \n",
       "33       4.214375      0.098578         0.005942        0.003709   \n",
       "34       4.928433      0.083142         0.006074        0.004241   \n",
       "35       7.069309      0.401386         0.007227        0.003712   \n",
       "\n",
       "   param_n_estimators param_max_depth param_learning_rate  \\\n",
       "0                 100               1                 0.1   \n",
       "1                 200               1                 0.1   \n",
       "2                 500               1                 0.1   \n",
       "3                 100               2                 0.1   \n",
       "4                 200               2                 0.1   \n",
       "5                 500               2                 0.1   \n",
       "6                 100               3                 0.1   \n",
       "7                 200               3                 0.1   \n",
       "8                 500               3                 0.1   \n",
       "9                 100               5                 0.1   \n",
       "10                200               5                 0.1   \n",
       "11                500               5                 0.1   \n",
       "12                100               1                 0.2   \n",
       "13                200               1                 0.2   \n",
       "14                500               1                 0.2   \n",
       "15                100               2                 0.2   \n",
       "16                200               2                 0.2   \n",
       "17                500               2                 0.2   \n",
       "18                100               3                 0.2   \n",
       "19                200               3                 0.2   \n",
       "20                500               3                 0.2   \n",
       "21                100               5                 0.2   \n",
       "22                200               5                 0.2   \n",
       "23                500               5                 0.2   \n",
       "24                100               1                 0.3   \n",
       "25                200               1                 0.3   \n",
       "26                500               1                 0.3   \n",
       "27                100               2                 0.3   \n",
       "28                200               2                 0.3   \n",
       "29                500               2                 0.3   \n",
       "30                100               3                 0.3   \n",
       "31                200               3                 0.3   \n",
       "32                500               3                 0.3   \n",
       "33                100               5                 0.3   \n",
       "34                200               5                 0.3   \n",
       "35                500               5                 0.3   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'n_estimators': 100, 'max_depth': 1, 'learnin...           0.905983   \n",
       "1   {'n_estimators': 200, 'max_depth': 1, 'learnin...           0.923077   \n",
       "2   {'n_estimators': 500, 'max_depth': 1, 'learnin...           0.952991   \n",
       "3   {'n_estimators': 100, 'max_depth': 2, 'learnin...           0.961538   \n",
       "4   {'n_estimators': 200, 'max_depth': 2, 'learnin...           0.974359   \n",
       "5   {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.970085   \n",
       "6   {'n_estimators': 100, 'max_depth': 3, 'learnin...           0.957265   \n",
       "7   {'n_estimators': 200, 'max_depth': 3, 'learnin...           0.965812   \n",
       "8   {'n_estimators': 500, 'max_depth': 3, 'learnin...           0.970085   \n",
       "9   {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.901709   \n",
       "10  {'n_estimators': 200, 'max_depth': 5, 'learnin...           0.901709   \n",
       "11  {'n_estimators': 500, 'max_depth': 5, 'learnin...           0.918803   \n",
       "12  {'n_estimators': 100, 'max_depth': 1, 'learnin...           0.935897   \n",
       "13  {'n_estimators': 200, 'max_depth': 1, 'learnin...           0.957265   \n",
       "14  {'n_estimators': 500, 'max_depth': 1, 'learnin...           0.961538   \n",
       "15  {'n_estimators': 100, 'max_depth': 2, 'learnin...           0.974359   \n",
       "16  {'n_estimators': 200, 'max_depth': 2, 'learnin...           0.974359   \n",
       "17  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.974359   \n",
       "18  {'n_estimators': 100, 'max_depth': 3, 'learnin...           0.970085   \n",
       "19  {'n_estimators': 200, 'max_depth': 3, 'learnin...           0.970085   \n",
       "20  {'n_estimators': 500, 'max_depth': 3, 'learnin...           0.974359   \n",
       "21  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.923077   \n",
       "22  {'n_estimators': 200, 'max_depth': 5, 'learnin...           0.923077   \n",
       "23  {'n_estimators': 500, 'max_depth': 5, 'learnin...           0.914530   \n",
       "24  {'n_estimators': 100, 'max_depth': 1, 'learnin...           0.952991   \n",
       "25  {'n_estimators': 200, 'max_depth': 1, 'learnin...           0.948718   \n",
       "26  {'n_estimators': 500, 'max_depth': 1, 'learnin...           0.948718   \n",
       "27  {'n_estimators': 100, 'max_depth': 2, 'learnin...           0.978632   \n",
       "28  {'n_estimators': 200, 'max_depth': 2, 'learnin...           0.974359   \n",
       "29  {'n_estimators': 500, 'max_depth': 2, 'learnin...           0.974359   \n",
       "30  {'n_estimators': 100, 'max_depth': 3, 'learnin...           0.961538   \n",
       "31  {'n_estimators': 200, 'max_depth': 3, 'learnin...           0.961538   \n",
       "32  {'n_estimators': 500, 'max_depth': 3, 'learnin...           0.974359   \n",
       "33  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.923077   \n",
       "34  {'n_estimators': 200, 'max_depth': 5, 'learnin...           0.910256   \n",
       "35  {'n_estimators': 500, 'max_depth': 5, 'learnin...           0.918803   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.952991           0.940171           0.935622   \n",
       "1            0.961538           0.952991           0.957082   \n",
       "2            0.961538           0.965812           0.961373   \n",
       "3            0.970085           0.935897           0.969957   \n",
       "4            0.965812           0.948718           0.961373   \n",
       "5            0.965812           0.952991           0.961373   \n",
       "6            0.957265           0.944444           0.961373   \n",
       "7            0.957265           0.940171           0.965665   \n",
       "8            0.961538           0.944444           0.969957   \n",
       "9            0.944444           0.948718           0.939914   \n",
       "10           0.944444           0.952991           0.935622   \n",
       "11           0.944444           0.952991           0.948498   \n",
       "12           0.961538           0.952991           0.957082   \n",
       "13           0.965812           0.957265           0.948498   \n",
       "14           0.957265           0.957265           0.965665   \n",
       "15           0.974359           0.948718           0.969957   \n",
       "16           0.970085           0.957265           0.965665   \n",
       "17           0.965812           0.952991           0.961373   \n",
       "18           0.957265           0.944444           0.961373   \n",
       "19           0.961538           0.944444           0.965665   \n",
       "20           0.961538           0.940171           0.965665   \n",
       "21           0.948718           0.948718           0.948498   \n",
       "22           0.948718           0.952991           0.952790   \n",
       "23           0.940171           0.948718           0.948498   \n",
       "24           0.961538           0.952991           0.957082   \n",
       "25           0.961538           0.961538           0.961373   \n",
       "26           0.957265           0.961538           0.965665   \n",
       "27           0.974359           0.952991           0.969957   \n",
       "28           0.965812           0.952991           0.969957   \n",
       "29           0.965812           0.952991           0.969957   \n",
       "30           0.965812           0.952991           0.969957   \n",
       "31           0.961538           0.948718           0.965665   \n",
       "32           0.961538           0.952991           0.965665   \n",
       "33           0.948718           0.944444           0.948498   \n",
       "34           0.948718           0.944444           0.948498   \n",
       "35           0.944444           0.944444           0.948498   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.922747           0.927350           0.961538   \n",
       "1            0.931330           0.957265           0.974359   \n",
       "2            0.935622           0.961538           0.952991   \n",
       "3            0.939914           0.952991           0.965812   \n",
       "4            0.957082           0.965812           0.965812   \n",
       "5            0.961373           0.961538           0.970085   \n",
       "6            0.957082           0.957265           0.978632   \n",
       "7            0.948498           0.952991           0.982906   \n",
       "8            0.957082           0.957265           0.982906   \n",
       "9            0.948498           0.944444           0.944444   \n",
       "10           0.952790           0.935897           0.952991   \n",
       "11           0.957082           0.935897           0.944444   \n",
       "12           0.931330           0.961538           0.974359   \n",
       "13           0.939914           0.965812           0.965812   \n",
       "14           0.948498           0.961538           0.961538   \n",
       "15           0.957082           0.965812           0.970085   \n",
       "16           0.965665           0.957265           0.982906   \n",
       "17           0.965665           0.961538           0.974359   \n",
       "18           0.952790           0.952991           0.987179   \n",
       "19           0.952790           0.957265           0.982906   \n",
       "20           0.961373           0.952991           0.982906   \n",
       "21           0.939914           0.944444           0.957265   \n",
       "22           0.952790           0.957265           0.952991   \n",
       "23           0.948498           0.952991           0.944444   \n",
       "24           0.935622           0.965812           0.961538   \n",
       "25           0.944206           0.957265           0.965812   \n",
       "26           0.948498           0.961538           0.965812   \n",
       "27           0.957082           0.961538           0.974359   \n",
       "28           0.961373           0.965812           0.978632   \n",
       "29           0.961373           0.965812           0.978632   \n",
       "30           0.952790           0.952991           0.982906   \n",
       "31           0.952790           0.952991           0.982906   \n",
       "32           0.965665           0.957265           0.982906   \n",
       "33           0.965665           0.948718           0.974359   \n",
       "34           0.948498           0.952991           0.957265   \n",
       "35           0.961373           0.948718           0.961538   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0            0.940171           0.931330           0.927039   \n",
       "1            0.948718           0.939914           0.944206   \n",
       "2            0.957265           0.948498           0.957082   \n",
       "3            0.970085           0.935622           0.957082   \n",
       "4            0.974359           0.939914           0.957082   \n",
       "5            0.978632           0.961373           0.965665   \n",
       "6            0.965812           0.939914           0.957082   \n",
       "7            0.961538           0.944206           0.965665   \n",
       "8            0.978632           0.939914           0.965665   \n",
       "9            0.940171           0.896996           0.952790   \n",
       "10           0.948718           0.901288           0.952790   \n",
       "11           0.944444           0.896996           0.952790   \n",
       "12           0.952991           0.935622           0.944206   \n",
       "13           0.961538           0.948498           0.952790   \n",
       "14           0.961538           0.952790           0.961373   \n",
       "15           0.978632           0.939914           0.969957   \n",
       "16           0.978632           0.957082           0.965665   \n",
       "17           0.978632           0.957082           0.969957   \n",
       "18           0.970085           0.965665           0.965665   \n",
       "19           0.970085           0.965665           0.969957   \n",
       "20           0.970085           0.961373           0.974249   \n",
       "21           0.944444           0.918455           0.944206   \n",
       "22           0.944444           0.918455           0.944206   \n",
       "23           0.944444           0.918455           0.952790   \n",
       "24           0.961538           0.939914           0.948498   \n",
       "25           0.961538           0.948498           0.961373   \n",
       "26           0.965812           0.944206           0.969957   \n",
       "27           0.974359           0.961373           0.965665   \n",
       "28           0.974359           0.961373           0.974249   \n",
       "29           0.974359           0.961373           0.974249   \n",
       "30           0.970085           0.957082           0.969957   \n",
       "31           0.974359           0.965665           0.965665   \n",
       "32           0.965812           0.952790           0.974249   \n",
       "33           0.948718           0.927039           0.931330   \n",
       "34           0.944444           0.909871           0.935622   \n",
       "35           0.952991           0.927039           0.961373   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0             0.931624            0.897436            0.957265   \n",
       "1             0.948718            0.905983            0.974359   \n",
       "2             0.961538            0.923077            0.970085   \n",
       "3             0.935897            0.952991            0.970085   \n",
       "4             0.948718            0.957265            0.974359   \n",
       "5             0.957265            0.952991            0.978632   \n",
       "6             0.935897            0.952991            0.965812   \n",
       "7             0.944444            0.952991            0.970085   \n",
       "8             0.948718            0.952991            0.974359   \n",
       "9             0.918803            0.948718            0.957265   \n",
       "10            0.931624            0.957265            0.974359   \n",
       "11            0.927350            0.957265            0.974359   \n",
       "12            0.952991            0.910256            0.978632   \n",
       "13            0.957265            0.923077            0.970085   \n",
       "14            0.957265            0.931624            0.970085   \n",
       "15            0.948718            0.952991            0.974359   \n",
       "16            0.952991            0.952991            0.978632   \n",
       "17            0.957265            0.952991            0.974359   \n",
       "18            0.952991            0.952991            0.970085   \n",
       "19            0.948718            0.948718            0.970085   \n",
       "20            0.948718            0.952991            0.965812   \n",
       "21            0.918803            0.948718            0.957265   \n",
       "22            0.918803            0.952991            0.970085   \n",
       "23            0.923077            0.940171            0.957265   \n",
       "24            0.957265            0.914530            0.970085   \n",
       "25            0.961538            0.923077            0.970085   \n",
       "26            0.952991            0.931624            0.961538   \n",
       "27            0.952991            0.961538            0.970085   \n",
       "28            0.952991            0.948718            0.974359   \n",
       "29            0.952991            0.961538            0.978632   \n",
       "30            0.952991            0.957265            0.965812   \n",
       "31            0.952991            0.957265            0.965812   \n",
       "32            0.952991            0.957265            0.978632   \n",
       "33            0.923077            0.957265            0.965812   \n",
       "34            0.935897            0.970085            0.965812   \n",
       "35            0.935897            0.961538            0.970085   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.948498            0.914163         0.932929        0.017663   \n",
       "1             0.969957            0.939914         0.948627        0.018354   \n",
       "2             0.969957            0.957082         0.955763        0.012075   \n",
       "3             0.978541            0.961373         0.957192        0.013986   \n",
       "4             0.978541            0.969957         0.962611        0.010786   \n",
       "5             0.974249            0.961373         0.964896        0.007843   \n",
       "6             0.957082            0.948498         0.955761        0.010337   \n",
       "7             0.969957            0.952790         0.958332        0.011427   \n",
       "8             0.974249            0.952790         0.962040        0.012500   \n",
       "9             0.948498            0.931330         0.937783        0.017481   \n",
       "10            0.957082            0.939914         0.942632        0.019145   \n",
       "11            0.957082            0.948498         0.944063        0.017937   \n",
       "12            0.974249            0.944206         0.951193        0.017746   \n",
       "13            0.969957            0.957082         0.956045        0.012067   \n",
       "14            0.974249            0.957082         0.958621        0.009452   \n",
       "15            0.969957            0.957082         0.963466        0.011380   \n",
       "16            0.969957            0.965665         0.966322        0.009226   \n",
       "17            0.969957            0.965665         0.965467        0.007883   \n",
       "18            0.974249            0.957082         0.962330        0.010611   \n",
       "19            0.978541            0.957082         0.962903        0.010885   \n",
       "20            0.978541            0.957082         0.963190        0.011331   \n",
       "21            0.939914            0.939914         0.941490        0.011889   \n",
       "22            0.957082            0.948498         0.946346        0.014399   \n",
       "23            0.952790            0.961373         0.943214        0.013553   \n",
       "24            0.974249            0.948498         0.953477        0.014495   \n",
       "25            0.969957            0.965665         0.957479        0.011732   \n",
       "26            0.974249            0.952790         0.957480        0.010760   \n",
       "27            0.969957            0.965665         0.966037        0.007731   \n",
       "28            0.969957            0.965665         0.966041        0.008751   \n",
       "29            0.969957            0.965665         0.967180        0.007911   \n",
       "30            0.978541            0.948498         0.962614        0.009945   \n",
       "31            0.982833            0.948498         0.962616        0.010651   \n",
       "32            0.987124            0.961373         0.966042        0.010760   \n",
       "33            0.961373            0.944206         0.947487        0.015434   \n",
       "34            0.948498            0.944206         0.944341        0.016194   \n",
       "35            0.944206            0.944206         0.948344        0.013487   \n",
       "\n",
       "    rank_test_score  \n",
       "0                36  \n",
       "1                26  \n",
       "2                22  \n",
       "3                20  \n",
       "4                13  \n",
       "5                 7  \n",
       "6                23  \n",
       "7                17  \n",
       "8                15  \n",
       "9                35  \n",
       "10               33  \n",
       "11               31  \n",
       "12               25  \n",
       "13               21  \n",
       "14               16  \n",
       "15                8  \n",
       "16                2  \n",
       "17                6  \n",
       "18               14  \n",
       "19               10  \n",
       "20                9  \n",
       "21               34  \n",
       "22               29  \n",
       "23               32  \n",
       "24               24  \n",
       "25               19  \n",
       "26               18  \n",
       "27                5  \n",
       "28                4  \n",
       "29                1  \n",
       "30               12  \n",
       "31               11  \n",
       "32                3  \n",
       "33               28  \n",
       "34               30  \n",
       "35               27  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GB_model = GradientBoostingClassifier()\n",
    "GB_params = dict()\n",
    "GB_params['n_estimators'] = [100, 200, 500]\n",
    "GB_params['max_depth'] = [1, 2, 3, 5]\n",
    "GB_params['learning_rate'] = [0.1, 0.2, 0.3]\n",
    "\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(GB_model, GB_params, n_iter=36, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "GB = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(GB.cv_results_)\n",
    "\n",
    "# Stockage du meilleur résultat dans le tableau des résultats\n",
    "Evaluation_Results.iloc[3]['Best Mean Test Score'] = max(cv_results['mean_test_score'])\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406ccb19",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Pour améliorer la précision de notre modèle, nous pouvons faire varrier les trois paramètes suivants :\n",
    "* Le nombre d'estimation\n",
    "* La profondeur maximale\n",
    "* Le taux d'apprentissage\n",
    "\n",
    "#### Le nombre d'estimation\n",
    "\n",
    "Ce paramètre permet de jouer sur le nombre d'arbre du modèle.\n",
    "Plus ce paramètre est élevé, plus le modèle est précis.\n",
    "\n",
    "Néanmoins, une valeur trop élevé peut causer des problèmes de performance lors de l'apprentissage.\n",
    "\n",
    "#### La profondeur maximale\n",
    "\n",
    "Cette valeur définit la profondeur des arbres utilisé.\n",
    "\n",
    "Il est important de choisir une profondeur adaptée à notre jeu d'entrainement au risque de faire de l'`over fitting`.\n",
    "\n",
    "#### Le taux d'apprentissage\n",
    "\n",
    "Il permet d'éviter l'`under fitting` et l'`over fitting`.\n",
    "Un taux d'apprentissage trop élevé pourrait amener à de l'`over fitting` et donc un mauvais résultat avec le jeu de test.\n",
    "A l'inverse, un taux d'apprentissage trop faible conduirait à de l'`under fitting`.\n",
    "\n",
    "---\n",
    "\n",
    "> Source : [https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae](https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae)\n",
    "\n",
    "---\n",
    "\n",
    "### Analyse des résultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36f29fe7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.967180</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.966322</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.966042</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.966041</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.966037</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.965467</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.964896</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.963466</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.963190</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.962903</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.962616</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.962614</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.962611</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.962330</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>500</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.962040</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.958621</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.958332</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.957480</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.957479</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.957192</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.956045</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.955763</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.955761</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.953477</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.951193</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.948627</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.948344</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.947487</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.944341</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.944063</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>500</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.943214</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>200</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.942632</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.941490</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.937783</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.932929</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_n_estimators param_max_depth param_learning_rate  mean_test_score  \\\n",
       "29                500               2                 0.3         0.967180   \n",
       "16                200               2                 0.2         0.966322   \n",
       "32                500               3                 0.3         0.966042   \n",
       "28                200               2                 0.3         0.966041   \n",
       "27                100               2                 0.3         0.966037   \n",
       "17                500               2                 0.2         0.965467   \n",
       "5                 500               2                 0.1         0.964896   \n",
       "15                100               2                 0.2         0.963466   \n",
       "20                500               3                 0.2         0.963190   \n",
       "19                200               3                 0.2         0.962903   \n",
       "31                200               3                 0.3         0.962616   \n",
       "30                100               3                 0.3         0.962614   \n",
       "4                 200               2                 0.1         0.962611   \n",
       "18                100               3                 0.2         0.962330   \n",
       "8                 500               3                 0.1         0.962040   \n",
       "14                500               1                 0.2         0.958621   \n",
       "7                 200               3                 0.1         0.958332   \n",
       "26                500               1                 0.3         0.957480   \n",
       "25                200               1                 0.3         0.957479   \n",
       "3                 100               2                 0.1         0.957192   \n",
       "13                200               1                 0.2         0.956045   \n",
       "2                 500               1                 0.1         0.955763   \n",
       "6                 100               3                 0.1         0.955761   \n",
       "24                100               1                 0.3         0.953477   \n",
       "12                100               1                 0.2         0.951193   \n",
       "1                 200               1                 0.1         0.948627   \n",
       "35                500               5                 0.3         0.948344   \n",
       "33                100               5                 0.3         0.947487   \n",
       "22                200               5                 0.2         0.946346   \n",
       "34                200               5                 0.3         0.944341   \n",
       "11                500               5                 0.1         0.944063   \n",
       "23                500               5                 0.2         0.943214   \n",
       "10                200               5                 0.1         0.942632   \n",
       "21                100               5                 0.2         0.941490   \n",
       "9                 100               5                 0.1         0.937783   \n",
       "0                 100               1                 0.1         0.932929   \n",
       "\n",
       "    rank_test_score  \n",
       "29                1  \n",
       "16                2  \n",
       "32                3  \n",
       "28                4  \n",
       "27                5  \n",
       "17                6  \n",
       "5                 7  \n",
       "15                8  \n",
       "20                9  \n",
       "19               10  \n",
       "31               11  \n",
       "30               12  \n",
       "4                13  \n",
       "18               14  \n",
       "8                15  \n",
       "14               16  \n",
       "7                17  \n",
       "26               18  \n",
       "25               19  \n",
       "3                20  \n",
       "13               21  \n",
       "2                22  \n",
       "6                23  \n",
       "24               24  \n",
       "12               25  \n",
       "1                26  \n",
       "35               27  \n",
       "33               28  \n",
       "22               29  \n",
       "34               30  \n",
       "11               31  \n",
       "23               32  \n",
       "10               33  \n",
       "21               34  \n",
       "9                35  \n",
       "0                36  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[[\"param_n_estimators\",\"param_max_depth\",\"param_learning_rate\",\"mean_test_score\",\"rank_test_score\"]].sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92291371",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Le meilleur résultat semble être avec la configuration suivante :\n",
    "\n",
    "|  Paramètre  | Valeur  |\n",
    "|---|---|\n",
    "| n_estimators |  100 |\n",
    "| max_depth  | 3  |\n",
    "|  learning_rate | 0.1  |\n",
    "\n",
    "> Nous avons essayé d'augmenté *le nombre d'itération* mais cela a un impacte négligeable sur le résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f120c152",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Classification par machine à vecteurs de support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6401e53",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\paula\\desktop\\mines\\machine_learning\\mines-ai-number-recognition-project\\venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:292: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>param_C</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.134596</td>\n",
       "      <td>0.040605</td>\n",
       "      <td>0.044447</td>\n",
       "      <td>0.010245</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gamma': 0.01, 'C': 0.1}</td>\n",
       "      <td>0.106838</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.106838</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.106838</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.111588</td>\n",
       "      <td>0.110447</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.069274</td>\n",
       "      <td>0.004611</td>\n",
       "      <td>0.034562</td>\n",
       "      <td>0.004408</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gamma': 0.001, 'C': 0.1}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.952340</td>\n",
       "      <td>0.008972</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093539</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.038880</td>\n",
       "      <td>0.003997</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'gamma': 0.0001, 'C': 0.1}</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.785408</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.790598</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.776824</td>\n",
       "      <td>0.788798</td>\n",
       "      <td>0.015323</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.106632</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.038877</td>\n",
       "      <td>0.003084</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'gamma': 0.01, 'C': 0.5}</td>\n",
       "      <td>0.209402</td>\n",
       "      <td>0.200855</td>\n",
       "      <td>0.226496</td>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.206009</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>0.226496</td>\n",
       "      <td>0.196581</td>\n",
       "      <td>0.171674</td>\n",
       "      <td>0.197425</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>0.205128</td>\n",
       "      <td>0.213675</td>\n",
       "      <td>0.206009</td>\n",
       "      <td>0.197425</td>\n",
       "      <td>0.202898</td>\n",
       "      <td>0.014457</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.044320</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.022733</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'gamma': 0.001, 'C': 0.5}</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.984875</td>\n",
       "      <td>0.006970</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.046820</td>\n",
       "      <td>0.003685</td>\n",
       "      <td>0.031058</td>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'gamma': 0.0001, 'C': 0.5}</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.949485</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.121890</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.038311</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1</td>\n",
       "      <td>{'gamma': 0.01, 'C': 1}</td>\n",
       "      <td>0.696581</td>\n",
       "      <td>0.739316</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.712446</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.735043</td>\n",
       "      <td>0.721030</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.726496</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.755365</td>\n",
       "      <td>0.746872</td>\n",
       "      <td>0.029679</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043682</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.021268</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'gamma': 0.001, 'C': 1}</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.990297</td>\n",
       "      <td>0.005294</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033689</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.003837</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1</td>\n",
       "      <td>{'gamma': 0.0001, 'C': 1}</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.964896</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.119839</td>\n",
       "      <td>0.002970</td>\n",
       "      <td>0.038715</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2</td>\n",
       "      <td>{'gamma': 0.01, 'C': 2}</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.729614</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.709402</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.769695</td>\n",
       "      <td>0.032091</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.044777</td>\n",
       "      <td>0.005861</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.003491</td>\n",
       "      <td>0.001</td>\n",
       "      <td>2</td>\n",
       "      <td>{'gamma': 0.001, 'C': 2}</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.990013</td>\n",
       "      <td>0.004861</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.028011</td>\n",
       "      <td>0.003530</td>\n",
       "      <td>0.021923</td>\n",
       "      <td>0.003190</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>2</td>\n",
       "      <td>{'gamma': 0.0001, 'C': 2}</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.976883</td>\n",
       "      <td>0.006776</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_gamma  \\\n",
       "0        0.134596      0.040605         0.044447        0.010245        0.01   \n",
       "1        0.069274      0.004611         0.034562        0.004408       0.001   \n",
       "2        0.093539      0.004407         0.038880        0.003997      0.0001   \n",
       "3        0.106632      0.004299         0.038877        0.003084        0.01   \n",
       "4        0.044320      0.003759         0.022733        0.003926       0.001   \n",
       "5        0.046820      0.003685         0.031058        0.002533      0.0001   \n",
       "6        0.121890      0.003254         0.038311        0.003103        0.01   \n",
       "7        0.043682      0.004285         0.021268        0.002728       0.001   \n",
       "8        0.033689      0.004284         0.027340        0.003837      0.0001   \n",
       "9        0.119839      0.002970         0.038715        0.002687        0.01   \n",
       "10       0.044777      0.005861         0.022046        0.003491       0.001   \n",
       "11       0.028011      0.003530         0.021923        0.003190      0.0001   \n",
       "\n",
       "   param_C                       params  split0_test_score  split1_test_score  \\\n",
       "0      0.1    {'gamma': 0.01, 'C': 0.1}           0.106838           0.111111   \n",
       "1      0.1   {'gamma': 0.001, 'C': 0.1}           0.944444           0.952991   \n",
       "2      0.1  {'gamma': 0.0001, 'C': 0.1}           0.773504           0.816239   \n",
       "3      0.5    {'gamma': 0.01, 'C': 0.5}           0.209402           0.200855   \n",
       "4      0.5   {'gamma': 0.001, 'C': 0.5}           0.982906           0.991453   \n",
       "5      0.5  {'gamma': 0.0001, 'C': 0.5}           0.944444           0.944444   \n",
       "6        1      {'gamma': 0.01, 'C': 1}           0.696581           0.739316   \n",
       "7        1     {'gamma': 0.001, 'C': 1}           0.991453           0.991453   \n",
       "8        1    {'gamma': 0.0001, 'C': 1}           0.961538           0.957265   \n",
       "9        2      {'gamma': 0.01, 'C': 2}           0.730769           0.782051   \n",
       "10       2     {'gamma': 0.001, 'C': 2}           0.987179           0.991453   \n",
       "11       2    {'gamma': 0.0001, 'C': 2}           0.982906           0.970085   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0            0.111111           0.111588           0.111588   \n",
       "1            0.948718           0.961373           0.935622   \n",
       "2            0.799145           0.763948           0.793991   \n",
       "3            0.226496           0.193133           0.206009   \n",
       "4            0.978632           0.987124           0.987124   \n",
       "5            0.940171           0.961373           0.944206   \n",
       "6            0.782051           0.768240           0.712446   \n",
       "7            0.987179           0.991416           0.991416   \n",
       "8            0.970085           0.974249           0.952790   \n",
       "9            0.811966           0.781116           0.733906   \n",
       "10           0.987179           0.991416           0.991416   \n",
       "11           0.978632           0.982833           0.982833   \n",
       "\n",
       "    split5_test_score  split6_test_score  split7_test_score  \\\n",
       "0            0.106838           0.111111           0.111111   \n",
       "1            0.948718           0.961538           0.957265   \n",
       "2            0.773504           0.803419           0.786325   \n",
       "3            0.213675           0.226496           0.196581   \n",
       "4            0.982906           1.000000           0.982906   \n",
       "5            0.935897           0.970085           0.944444   \n",
       "6            0.786325           0.760684           0.735043   \n",
       "7            0.982906           1.000000           0.995726   \n",
       "8            0.952991           0.978632           0.965812   \n",
       "9            0.807692           0.786325           0.760684   \n",
       "10           0.982906           0.995726           0.991453   \n",
       "11           0.970085           0.995726           0.974359   \n",
       "\n",
       "    split8_test_score  split9_test_score  split10_test_score  \\\n",
       "0            0.111588           0.111588            0.106838   \n",
       "1            0.944206           0.965665            0.940171   \n",
       "2            0.785408           0.798283            0.799145   \n",
       "3            0.171674           0.197425            0.179487   \n",
       "4            0.969957           0.987124            0.978632   \n",
       "5            0.939914           0.961373            0.948718   \n",
       "6            0.721030           0.798283            0.705128   \n",
       "7            0.978541           0.995708            0.987179   \n",
       "8            0.961373           0.965665            0.952991   \n",
       "9            0.729614           0.824034            0.709402   \n",
       "10           0.978541           0.995708            0.987179   \n",
       "11           0.969957           0.969957            0.974359   \n",
       "\n",
       "    split11_test_score  split12_test_score  split13_test_score  \\\n",
       "0             0.111111            0.111111            0.111588   \n",
       "1             0.961538            0.957265            0.961373   \n",
       "2             0.807692            0.790598            0.763948   \n",
       "3             0.205128            0.213675            0.206009   \n",
       "4             0.982906            0.982906            0.982833   \n",
       "5             0.957265            0.965812            0.948498   \n",
       "6             0.726496            0.752137            0.763948   \n",
       "7             0.987179            0.987179            0.991416   \n",
       "8             0.974359            0.974359            0.974249   \n",
       "9             0.756410            0.769231            0.789700   \n",
       "10            0.987179            0.995726            0.991416   \n",
       "11            0.974359            0.974359            0.978541   \n",
       "\n",
       "    split14_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.111588         0.110447        0.001817               12  \n",
       "1             0.944206         0.952340        0.008972                6  \n",
       "2             0.776824         0.788798        0.015323                8  \n",
       "3             0.197425         0.202898        0.014457               11  \n",
       "4             0.995708         0.984875        0.006970                3  \n",
       "5             0.935622         0.949485        0.010630                7  \n",
       "6             0.755365         0.746872        0.029679               10  \n",
       "7             0.995708         0.990297        0.005294                1  \n",
       "8             0.957082         0.964896        0.008733                5  \n",
       "9             0.772532         0.769695        0.032091                9  \n",
       "10            0.995708         0.990013        0.004861                2  \n",
       "11            0.974249         0.976883        0.006776                4  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "SVC_model = svm.SVC()\n",
    "\n",
    "SVC_params = dict()\n",
    "SVC_params['gamma'] = [0.01, 0.001, 0.0001]\n",
    "SVC_params['C'] = [0.1, 0.5, 1, 2]\n",
    "\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(SVC_model, SVC_params, n_iter=50, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "SVC = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(SVC.cv_results_)\n",
    "\n",
    "# Stockage du meilleur résultat dans le tableau des résultats\n",
    "Evaluation_Results.iloc[4]['Best Mean Test Score'] = max(cv_results['mean_test_score'])\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ebadbd",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Paramètres\n",
    "\n",
    "* `gamma` : Permet de définir le niveau de précision du modèle. Le paramètre peut prendre une valeur entre 0 et 1. Plus la valeur est proche de 0, plus le model va s'adapter au jeu d'entrainement ce qui risque de provoquer de l'`under fitting`. Au contraire, une valeur trop proche de 0, risque de provoquer de l'`overfitting`.\n",
    "\n",
    "* `C` : Permet de définir l'importance des mauvaises classifications. Il permet de définir la marge entre deux classes.\n",
    "\n",
    "#### Analyse des résultats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfc5c42",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv_results[[\"param_gamma\",\"param_C\",\"mean_test_score\",\"rank_test_score\"]].sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46a848e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "La meilleure configuration semble être :\n",
    "\n",
    "| Paramètre  |  Valeur  |\n",
    "|---|---|\n",
    "| Gamma  | 0.001  |\n",
    "|  C | 1  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05090a64",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Sources :*\n",
    "* [https://www.quora.com/What-is-regularization-parameter-in-SVM](https://www.quora.com/What-is-regularization-parameter-in-SVM)\n",
    "* [https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python](https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python)\n",
    "* [https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html?highlight=svc#sklearn.svm.SVC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f6d316",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Classification par voisin le plus proche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da4875d9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_weights</th>\n",
       "      <th>param_p</th>\n",
       "      <th>param_n_neighbors</th>\n",
       "      <th>param_leaf_size</th>\n",
       "      <th>param_algorithm</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.000610</td>\n",
       "      <td>0.030462</td>\n",
       "      <td>0.012114</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.960620</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011430</td>\n",
       "      <td>0.007611</td>\n",
       "      <td>0.023027</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors':...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.980309</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014945</td>\n",
       "      <td>0.006903</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors':...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.979169</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001795</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.007326</td>\n",
       "      <td>0.003625</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.988296</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.002761</td>\n",
       "      <td>0.017844</td>\n",
       "      <td>0.005251</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.979448</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.009919</td>\n",
       "      <td>0.003965</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.976883</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.022771</td>\n",
       "      <td>0.009603</td>\n",
       "      <td>0.052643</td>\n",
       "      <td>0.008621</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.970889</td>\n",
       "      <td>0.005895</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.006819</td>\n",
       "      <td>0.022105</td>\n",
       "      <td>0.007698</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors':...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.978884</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.033316</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>0.255419</td>\n",
       "      <td>0.013758</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.964326</td>\n",
       "      <td>0.008067</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000537</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>0.021704</td>\n",
       "      <td>0.002707</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.972033</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.002014</td>\n",
       "      <td>0.022392</td>\n",
       "      <td>0.003449</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.960620</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.020619</td>\n",
       "      <td>0.000834</td>\n",
       "      <td>0.045639</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.970886</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.001615</td>\n",
       "      <td>0.003230</td>\n",
       "      <td>0.015881</td>\n",
       "      <td>0.004648</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors':...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.968323</td>\n",
       "      <td>0.006588</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.002427</td>\n",
       "      <td>0.003778</td>\n",
       "      <td>0.017691</td>\n",
       "      <td>0.003391</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.979169</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.029723</td>\n",
       "      <td>0.002140</td>\n",
       "      <td>0.100933</td>\n",
       "      <td>0.006913</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.960906</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010646</td>\n",
       "      <td>0.003570</td>\n",
       "      <td>0.019154</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.988296</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.023059</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.960620</td>\n",
       "      <td>0.008569</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.014576</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.027356</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.988296</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.001215</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.008932</td>\n",
       "      <td>0.002735</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.970886</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.008819</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.976883</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000825</td>\n",
       "      <td>0.001010</td>\n",
       "      <td>0.008948</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.970886</td>\n",
       "      <td>0.006869</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.001020</td>\n",
       "      <td>0.002052</td>\n",
       "      <td>0.022092</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.972033</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.031962</td>\n",
       "      <td>0.003560</td>\n",
       "      <td>0.058520</td>\n",
       "      <td>0.004467</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors':...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.978884</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.001079</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.008494</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.976883</td>\n",
       "      <td>0.006013</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.013354</td>\n",
       "      <td>0.003673</td>\n",
       "      <td>0.039485</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965185</td>\n",
       "      <td>0.006961</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.031678</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.224574</td>\n",
       "      <td>0.006379</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.970889</td>\n",
       "      <td>0.005895</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023992</td>\n",
       "      <td>0.003611</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.965472</td>\n",
       "      <td>0.006516</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.003354</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.988296</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.015502</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.003081</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors':...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.980024</td>\n",
       "      <td>0.009722</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.013865</td>\n",
       "      <td>0.004165</td>\n",
       "      <td>0.027209</td>\n",
       "      <td>0.003895</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.988296</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.009967</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.024493</td>\n",
       "      <td>0.004006</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.988296</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.020606</td>\n",
       "      <td>0.001516</td>\n",
       "      <td>0.041320</td>\n",
       "      <td>0.003588</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.985440</td>\n",
       "      <td>0.009099</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.014136</td>\n",
       "      <td>0.004242</td>\n",
       "      <td>0.041805</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.971175</td>\n",
       "      <td>0.005519</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.004203</td>\n",
       "      <td>0.028522</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>30</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.972032</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.014374</td>\n",
       "      <td>0.004645</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.971460</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.014631</td>\n",
       "      <td>0.004065</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.964041</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.001892</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.021957</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.965472</td>\n",
       "      <td>0.006516</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.001352</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>0.005970</td>\n",
       "      <td>0.004155</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.988296</td>\n",
       "      <td>0.007410</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.001355</td>\n",
       "      <td>0.002733</td>\n",
       "      <td>0.022480</td>\n",
       "      <td>0.003093</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.972033</td>\n",
       "      <td>0.009103</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.001888</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.015036</td>\n",
       "      <td>0.004483</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>30</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.964041</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.020315</td>\n",
       "      <td>0.002955</td>\n",
       "      <td>0.028247</td>\n",
       "      <td>0.004831</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors':...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.978884</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000138</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>0.016830</td>\n",
       "      <td>0.006009</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.964041</td>\n",
       "      <td>0.008806</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.003973</td>\n",
       "      <td>0.006542</td>\n",
       "      <td>0.004218</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.985440</td>\n",
       "      <td>0.009099</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000678</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.015586</td>\n",
       "      <td>0.004082</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.995708</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.979448</td>\n",
       "      <td>0.008604</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000814</td>\n",
       "      <td>0.002070</td>\n",
       "      <td>0.013548</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>auto</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors':...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.979169</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.001211</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.004449</td>\n",
       "      <td>uniform</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 2, 'n_neighbors': ...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.971460</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.004304</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.015969</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.995726</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.979169</td>\n",
       "      <td>0.007303</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.015131</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.038584</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>distance</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>ball_tree</td>\n",
       "      <td>{'weights': 'distance', 'p': 2, 'n_neighbors':...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.976598</td>\n",
       "      <td>0.005606</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.019211</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>distance</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>brute</td>\n",
       "      <td>{'weights': 'distance', 'p': 1, 'n_neighbors':...</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.991416</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.979739</td>\n",
       "      <td>0.009570</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.021071</td>\n",
       "      <td>0.002077</td>\n",
       "      <td>0.032222</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>uniform</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>kd_tree</td>\n",
       "      <td>{'weights': 'uniform', 'p': 1, 'n_neighbors': ...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.978884</td>\n",
       "      <td>0.006710</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.000398      0.000610         0.030462        0.012114   \n",
       "1        0.011430      0.007611         0.023027        0.006447   \n",
       "2        0.000000      0.000000         0.014945        0.006903   \n",
       "3        0.001795      0.003000         0.007326        0.003625   \n",
       "4        0.001226      0.002761         0.017844        0.005251   \n",
       "5        0.002171      0.003600         0.009919        0.003965   \n",
       "6        0.022771      0.009603         0.052643        0.008621   \n",
       "7        0.008350      0.006819         0.022105        0.007698   \n",
       "8        0.033316      0.003815         0.255419        0.013758   \n",
       "9        0.000537      0.002010         0.021704        0.002707   \n",
       "10       0.000538      0.002014         0.022392        0.003449   \n",
       "11       0.020619      0.000834         0.045639        0.005359   \n",
       "12       0.001615      0.003230         0.015881        0.004648   \n",
       "13       0.002427      0.003778         0.017691        0.003391   \n",
       "14       0.029723      0.002140         0.100933        0.006913   \n",
       "15       0.010646      0.003570         0.019154        0.002827   \n",
       "16       0.001215      0.002742         0.023059        0.003893   \n",
       "17       0.014576      0.004311         0.027356        0.003893   \n",
       "18       0.001215      0.002742         0.008932        0.002735   \n",
       "19       0.001350      0.003103         0.008819        0.002733   \n",
       "20       0.000825      0.001010         0.008948        0.002067   \n",
       "21       0.001020      0.002052         0.022092        0.003287   \n",
       "22       0.031962      0.003560         0.058520        0.004467   \n",
       "23       0.001079      0.002752         0.008494        0.003227   \n",
       "24       0.013354      0.003673         0.039485        0.003622   \n",
       "25       0.031678      0.002733         0.224574        0.006379   \n",
       "26       0.000000      0.000000         0.023992        0.003611   \n",
       "27       0.005258      0.003352         0.025079        0.003354   \n",
       "28       0.015502      0.004326         0.028169        0.003081   \n",
       "29       0.013865      0.004165         0.027209        0.003895   \n",
       "30       0.009967      0.000514         0.024493        0.004006   \n",
       "31       0.020606      0.001516         0.041320        0.003588   \n",
       "32       0.014136      0.004242         0.041805        0.002695   \n",
       "33       0.004481      0.004203         0.028522        0.003119   \n",
       "34       0.001358      0.002734         0.014374        0.004645   \n",
       "35       0.000951      0.002072         0.014631        0.004065   \n",
       "36       0.001892      0.003173         0.021957        0.003507   \n",
       "37       0.001352      0.002730         0.005970        0.004155   \n",
       "38       0.001355      0.002733         0.022480        0.003093   \n",
       "39       0.001888      0.003498         0.015036        0.004483   \n",
       "40       0.020315      0.002955         0.028247        0.004831   \n",
       "41       0.000138      0.000516         0.016830        0.006009   \n",
       "42       0.003244      0.003973         0.006542        0.004218   \n",
       "43       0.000678      0.002051         0.015586        0.004082   \n",
       "44       0.000814      0.002070         0.013548        0.004304   \n",
       "45       0.001211      0.002736         0.014635        0.004449   \n",
       "46       0.004304      0.004026         0.015969        0.004036   \n",
       "47       0.015131      0.004356         0.038584        0.002984   \n",
       "48       0.000274      0.000698         0.019211        0.004176   \n",
       "49       0.021071      0.002077         0.032222        0.002628   \n",
       "\n",
       "   param_weights param_p param_n_neighbors param_leaf_size param_algorithm  \\\n",
       "0        uniform       1                16              30            auto   \n",
       "1       distance       1                 6              10       ball_tree   \n",
       "2       distance       1                 1              10           brute   \n",
       "3       distance       2                 1              30            auto   \n",
       "4        uniform       2                 6              30           brute   \n",
       "5       distance       2                11               1            auto   \n",
       "6        uniform       2                11              10         kd_tree   \n",
       "7       distance       1                 1              30       ball_tree   \n",
       "8        uniform       2                16               1         kd_tree   \n",
       "9        uniform       1                 6              30           brute   \n",
       "10       uniform       1                16              10           brute   \n",
       "11      distance       2                16              10         kd_tree   \n",
       "12      distance       1                16              10            auto   \n",
       "13       uniform       1                 1              10            auto   \n",
       "14       uniform       1                16               1         kd_tree   \n",
       "15      distance       2                 1              10       ball_tree   \n",
       "16       uniform       1                16              10            auto   \n",
       "17      distance       2                 1               1       ball_tree   \n",
       "18      distance       2                16              10            auto   \n",
       "19      distance       2                11               1           brute   \n",
       "20      distance       2                16              30            auto   \n",
       "21       uniform       1                 6               1            auto   \n",
       "22      distance       1                 1               1         kd_tree   \n",
       "23      distance       2                11              30           brute   \n",
       "24       uniform       1                11               1       ball_tree   \n",
       "25       uniform       2                11               1         kd_tree   \n",
       "26       uniform       1                11               1           brute   \n",
       "27       uniform       2                 1              30       ball_tree   \n",
       "28      distance       1                 6               1       ball_tree   \n",
       "29       uniform       2                 1              30         kd_tree   \n",
       "30       uniform       2                 1              10       ball_tree   \n",
       "31      distance       2                 6              10         kd_tree   \n",
       "32       uniform       2                11               1       ball_tree   \n",
       "33       uniform       1                 6              30       ball_tree   \n",
       "34       uniform       2                11              30           brute   \n",
       "35       uniform       2                16               1            auto   \n",
       "36       uniform       1                11              30            auto   \n",
       "37      distance       2                 1              10            auto   \n",
       "38       uniform       1                 6              10           brute   \n",
       "39       uniform       2                16              30           brute   \n",
       "40      distance       1                 1              10         kd_tree   \n",
       "41       uniform       2                16              10           brute   \n",
       "42      distance       2                 6              10           brute   \n",
       "43       uniform       2                 6               1           brute   \n",
       "44      distance       1                 1              30            auto   \n",
       "45       uniform       2                11              10           brute   \n",
       "46       uniform       1                 1              10           brute   \n",
       "47      distance       2                11               1       ball_tree   \n",
       "48      distance       1                 6              10           brute   \n",
       "49       uniform       1                 1              10         kd_tree   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.948718   \n",
       "1   {'weights': 'distance', 'p': 1, 'n_neighbors':...           0.987179   \n",
       "2   {'weights': 'distance', 'p': 1, 'n_neighbors':...           0.978632   \n",
       "3   {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.987179   \n",
       "4   {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.982906   \n",
       "5   {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.970085   \n",
       "6   {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.961538   \n",
       "7   {'weights': 'distance', 'p': 1, 'n_neighbors':...           0.978632   \n",
       "8   {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.944444   \n",
       "9   {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.978632   \n",
       "10  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.948718   \n",
       "11  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.957265   \n",
       "12  {'weights': 'distance', 'p': 1, 'n_neighbors':...           0.961538   \n",
       "13  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.978632   \n",
       "14  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.944444   \n",
       "15  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.987179   \n",
       "16  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.948718   \n",
       "17  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.987179   \n",
       "18  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.957265   \n",
       "19  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.970085   \n",
       "20  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.957265   \n",
       "21  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.978632   \n",
       "22  {'weights': 'distance', 'p': 1, 'n_neighbors':...           0.978632   \n",
       "23  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.970085   \n",
       "24  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.965812   \n",
       "25  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.961538   \n",
       "26  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.965812   \n",
       "27  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.987179   \n",
       "28  {'weights': 'distance', 'p': 1, 'n_neighbors':...           0.987179   \n",
       "29  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.987179   \n",
       "30  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.987179   \n",
       "31  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.982906   \n",
       "32  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.961538   \n",
       "33  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.982906   \n",
       "34  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.961538   \n",
       "35  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.940171   \n",
       "36  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.965812   \n",
       "37  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.987179   \n",
       "38  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.978632   \n",
       "39  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.940171   \n",
       "40  {'weights': 'distance', 'p': 1, 'n_neighbors':...           0.978632   \n",
       "41  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.940171   \n",
       "42  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.982906   \n",
       "43  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.982906   \n",
       "44  {'weights': 'distance', 'p': 1, 'n_neighbors':...           0.978632   \n",
       "45  {'weights': 'uniform', 'p': 2, 'n_neighbors': ...           0.961538   \n",
       "46  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.978632   \n",
       "47  {'weights': 'distance', 'p': 2, 'n_neighbors':...           0.970085   \n",
       "48  {'weights': 'distance', 'p': 1, 'n_neighbors':...           0.982906   \n",
       "49  {'weights': 'uniform', 'p': 1, 'n_neighbors': ...           0.978632   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.961538           0.970085           0.969957   \n",
       "1            0.970085           0.974359           0.982833   \n",
       "2            0.978632           0.970085           0.987124   \n",
       "3            0.987179           0.978632           0.978541   \n",
       "4            0.991453           0.970085           0.965665   \n",
       "5            0.982906           0.965812           0.978541   \n",
       "6            0.978632           0.965812           0.974249   \n",
       "7            0.978632           0.970085           0.987124   \n",
       "8            0.970085           0.965812           0.969957   \n",
       "9            0.974359           0.965812           0.969957   \n",
       "10           0.961538           0.970085           0.969957   \n",
       "11           0.970085           0.970085           0.974249   \n",
       "12           0.961538           0.970085           0.974249   \n",
       "13           0.978632           0.970085           0.987124   \n",
       "14           0.961538           0.970085           0.974249   \n",
       "15           0.987179           0.978632           0.978541   \n",
       "16           0.961538           0.970085           0.969957   \n",
       "17           0.987179           0.978632           0.978541   \n",
       "18           0.970085           0.970085           0.974249   \n",
       "19           0.982906           0.965812           0.978541   \n",
       "20           0.970085           0.970085           0.974249   \n",
       "21           0.974359           0.965812           0.969957   \n",
       "22           0.978632           0.970085           0.987124   \n",
       "23           0.982906           0.965812           0.978541   \n",
       "24           0.974359           0.957265           0.965665   \n",
       "25           0.978632           0.965812           0.974249   \n",
       "26           0.970085           0.957265           0.965665   \n",
       "27           0.987179           0.978632           0.978541   \n",
       "28           0.970085           0.974359           0.982833   \n",
       "29           0.987179           0.978632           0.978541   \n",
       "30           0.987179           0.978632           0.978541   \n",
       "31           0.991453           0.970085           0.974249   \n",
       "32           0.978632           0.965812           0.974249   \n",
       "33           0.974359           0.965812           0.969957   \n",
       "34           0.978632           0.965812           0.974249   \n",
       "35           0.970085           0.965812           0.969957   \n",
       "36           0.970085           0.957265           0.965665   \n",
       "37           0.987179           0.978632           0.978541   \n",
       "38           0.974359           0.965812           0.969957   \n",
       "39           0.970085           0.965812           0.969957   \n",
       "40           0.978632           0.970085           0.987124   \n",
       "41           0.970085           0.965812           0.969957   \n",
       "42           0.991453           0.970085           0.974249   \n",
       "43           0.991453           0.970085           0.965665   \n",
       "44           0.978632           0.970085           0.987124   \n",
       "45           0.978632           0.965812           0.974249   \n",
       "46           0.978632           0.970085           0.987124   \n",
       "47           0.982906           0.965812           0.978541   \n",
       "48           0.970085           0.974359           0.982833   \n",
       "49           0.978632           0.970085           0.987124   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.957082           0.961538           0.970085   \n",
       "1            0.982833           0.982906           0.995726   \n",
       "2            0.982833           0.974359           0.982906   \n",
       "3            0.991416           0.978632           1.000000   \n",
       "4            0.995708           0.978632           0.995726   \n",
       "5            0.969957           0.974359           0.982906   \n",
       "6            0.965665           0.965812           0.978632   \n",
       "7            0.982833           0.974359           0.982906   \n",
       "8            0.957082           0.970085           0.974359   \n",
       "9            0.978541           0.965812           0.982906   \n",
       "10           0.957082           0.961538           0.970085   \n",
       "11           0.957082           0.978632           0.978632   \n",
       "12           0.965665           0.974359           0.978632   \n",
       "13           0.982833           0.974359           0.982906   \n",
       "14           0.957082           0.961538           0.970085   \n",
       "15           0.991416           0.978632           1.000000   \n",
       "16           0.957082           0.961538           0.970085   \n",
       "17           0.991416           0.978632           1.000000   \n",
       "18           0.957082           0.978632           0.978632   \n",
       "19           0.969957           0.974359           0.982906   \n",
       "20           0.957082           0.978632           0.978632   \n",
       "21           0.978541           0.965812           0.982906   \n",
       "22           0.982833           0.974359           0.982906   \n",
       "23           0.969957           0.974359           0.982906   \n",
       "24           0.957082           0.957265           0.974359   \n",
       "25           0.965665           0.965812           0.978632   \n",
       "26           0.957082           0.961538           0.974359   \n",
       "27           0.991416           0.978632           1.000000   \n",
       "28           0.982833           0.982906           0.991453   \n",
       "29           0.991416           0.978632           1.000000   \n",
       "30           0.991416           0.978632           1.000000   \n",
       "31           0.995708           0.982906           1.000000   \n",
       "32           0.965665           0.965812           0.978632   \n",
       "33           0.982833           0.965812           0.982906   \n",
       "34           0.965665           0.965812           0.978632   \n",
       "35           0.957082           0.970085           0.974359   \n",
       "36           0.957082           0.961538           0.974359   \n",
       "37           0.991416           0.978632           1.000000   \n",
       "38           0.978541           0.965812           0.982906   \n",
       "39           0.957082           0.970085           0.974359   \n",
       "40           0.982833           0.974359           0.982906   \n",
       "41           0.957082           0.970085           0.974359   \n",
       "42           0.995708           0.982906           1.000000   \n",
       "43           0.995708           0.978632           0.995726   \n",
       "44           0.982833           0.974359           0.982906   \n",
       "45           0.965665           0.965812           0.978632   \n",
       "46           0.982833           0.974359           0.982906   \n",
       "47           0.969957           0.974359           0.982906   \n",
       "48           0.982833           0.982906           0.991453   \n",
       "49           0.982833           0.974359           0.982906   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0            0.944444           0.952790           0.969957   \n",
       "1            0.991453           0.957082           0.991416   \n",
       "2            0.995726           0.965665           0.982833   \n",
       "3            1.000000           0.978541           0.987124   \n",
       "4            0.974359           0.969957           0.978541   \n",
       "5            0.974359           0.969957           0.982833   \n",
       "6            0.974359           0.961373           0.974249   \n",
       "7            0.991453           0.965665           0.982833   \n",
       "8            0.952991           0.957082           0.965665   \n",
       "9            0.974359           0.948498           0.982833   \n",
       "10           0.944444           0.952790           0.969957   \n",
       "11           0.974359           0.961373           0.969957   \n",
       "12           0.961538           0.961373           0.978541   \n",
       "13           0.995726           0.965665           0.982833   \n",
       "14           0.948718           0.952790           0.969957   \n",
       "15           1.000000           0.978541           0.987124   \n",
       "16           0.944444           0.952790           0.969957   \n",
       "17           1.000000           0.978541           0.987124   \n",
       "18           0.974359           0.961373           0.969957   \n",
       "19           0.974359           0.969957           0.982833   \n",
       "20           0.974359           0.961373           0.969957   \n",
       "21           0.974359           0.948498           0.982833   \n",
       "22           0.991453           0.965665           0.982833   \n",
       "23           0.974359           0.969957           0.982833   \n",
       "24           0.961538           0.957082           0.978541   \n",
       "25           0.974359           0.961373           0.974249   \n",
       "26           0.961538           0.961373           0.978541   \n",
       "27           1.000000           0.978541           0.987124   \n",
       "28           0.991453           0.957082           0.991416   \n",
       "29           1.000000           0.978541           0.987124   \n",
       "30           1.000000           0.978541           0.987124   \n",
       "31           0.995726           0.969957           0.978541   \n",
       "32           0.974359           0.965665           0.974249   \n",
       "33           0.974359           0.948498           0.982833   \n",
       "34           0.974359           0.965665           0.974249   \n",
       "35           0.952991           0.957082           0.965665   \n",
       "36           0.961538           0.961373           0.978541   \n",
       "37           1.000000           0.978541           0.987124   \n",
       "38           0.974359           0.948498           0.982833   \n",
       "39           0.952991           0.957082           0.965665   \n",
       "40           0.991453           0.965665           0.982833   \n",
       "41           0.952991           0.957082           0.965665   \n",
       "42           0.995726           0.969957           0.978541   \n",
       "43           0.974359           0.969957           0.978541   \n",
       "44           0.995726           0.965665           0.982833   \n",
       "45           0.974359           0.965665           0.974249   \n",
       "46           0.995726           0.965665           0.982833   \n",
       "47           0.974359           0.969957           0.982833   \n",
       "48           0.991453           0.957082           0.991416   \n",
       "49           0.991453           0.965665           0.982833   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0             0.948718            0.965812            0.961538   \n",
       "1             0.965812            0.974359            0.978632   \n",
       "2             0.974359            0.974359            0.974359   \n",
       "3             0.987179            0.987179            1.000000   \n",
       "4             0.978632            0.978632            0.978632   \n",
       "5             0.982906            0.974359            0.987179   \n",
       "6             0.965812            0.974359            0.978632   \n",
       "7             0.974359            0.974359            0.974359   \n",
       "8             0.965812            0.970085            0.965812   \n",
       "9             0.965812            0.961538            0.974359   \n",
       "10            0.948718            0.965812            0.961538   \n",
       "11            0.974359            0.974359            0.974359   \n",
       "12            0.961538            0.965812            0.974359   \n",
       "13            0.974359            0.974359            0.974359   \n",
       "14            0.948718            0.965812            0.961538   \n",
       "15            0.987179            0.987179            1.000000   \n",
       "16            0.948718            0.965812            0.961538   \n",
       "17            0.987179            0.987179            1.000000   \n",
       "18            0.974359            0.974359            0.974359   \n",
       "19            0.982906            0.974359            0.987179   \n",
       "20            0.974359            0.974359            0.974359   \n",
       "21            0.965812            0.961538            0.974359   \n",
       "22            0.974359            0.974359            0.974359   \n",
       "23            0.982906            0.974359            0.987179   \n",
       "24            0.961538            0.961538            0.965812   \n",
       "25            0.965812            0.974359            0.978632   \n",
       "26            0.957265            0.961538            0.965812   \n",
       "27            0.987179            0.987179            1.000000   \n",
       "28            0.965812            0.974359            0.978632   \n",
       "29            0.987179            0.987179            1.000000   \n",
       "30            0.987179            0.987179            1.000000   \n",
       "31            0.991453            0.982906            0.991453   \n",
       "32            0.965812            0.974359            0.978632   \n",
       "33            0.965812            0.961538            0.974359   \n",
       "34            0.965812            0.974359            0.982906   \n",
       "35            0.965812            0.970085            0.965812   \n",
       "36            0.957265            0.961538            0.965812   \n",
       "37            0.987179            0.987179            1.000000   \n",
       "38            0.965812            0.961538            0.974359   \n",
       "39            0.965812            0.970085            0.965812   \n",
       "40            0.974359            0.974359            0.974359   \n",
       "41            0.965812            0.970085            0.965812   \n",
       "42            0.991453            0.982906            0.991453   \n",
       "43            0.978632            0.978632            0.978632   \n",
       "44            0.974359            0.974359            0.974359   \n",
       "45            0.965812            0.974359            0.982906   \n",
       "46            0.974359            0.974359            0.974359   \n",
       "47            0.982906            0.974359            0.982906   \n",
       "48            0.965812            0.974359            0.978632   \n",
       "49            0.974359            0.974359            0.974359   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.969957            0.957082         0.960620        0.008569   \n",
       "1             0.982833            0.987124         0.980309        0.010108   \n",
       "2             0.978541            0.987124         0.979169        0.007303   \n",
       "3             0.991416            0.991416         0.988296        0.007410   \n",
       "4             0.974249            0.978541         0.979448        0.008604   \n",
       "5             0.978541            0.978541         0.976883        0.006013   \n",
       "6             0.974249            0.969957         0.970889        0.005895   \n",
       "7             0.978541            0.987124         0.978884        0.006710   \n",
       "8             0.974249            0.961373         0.964326        0.008067   \n",
       "9             0.982833            0.974249         0.972033        0.009103   \n",
       "10            0.969957            0.957082         0.960620        0.008569   \n",
       "11            0.978541            0.969957         0.970886        0.006869   \n",
       "12            0.974249            0.961373         0.968323        0.006588   \n",
       "13            0.978541            0.987124         0.979169        0.007303   \n",
       "14            0.969957            0.957082         0.960906        0.008940   \n",
       "15            0.991416            0.991416         0.988296        0.007410   \n",
       "16            0.969957            0.957082         0.960620        0.008569   \n",
       "17            0.991416            0.991416         0.988296        0.007410   \n",
       "18            0.978541            0.969957         0.970886        0.006869   \n",
       "19            0.978541            0.978541         0.976883        0.006013   \n",
       "20            0.978541            0.969957         0.970886        0.006869   \n",
       "21            0.982833            0.974249         0.972033        0.009103   \n",
       "22            0.978541            0.987124         0.978884        0.006710   \n",
       "23            0.978541            0.978541         0.976883        0.006013   \n",
       "24            0.974249            0.965665         0.965185        0.006961   \n",
       "25            0.974249            0.969957         0.970889        0.005895   \n",
       "26            0.974249            0.969957         0.965472        0.006516   \n",
       "27            0.991416            0.991416         0.988296        0.007410   \n",
       "28            0.982833            0.987124         0.980024        0.009722   \n",
       "29            0.991416            0.991416         0.988296        0.007410   \n",
       "30            0.991416            0.991416         0.988296        0.007410   \n",
       "31            0.982833            0.991416         0.985440        0.009099   \n",
       "32            0.974249            0.969957         0.971175        0.005519   \n",
       "33            0.974249            0.974249         0.972032        0.009238   \n",
       "34            0.974249            0.969957         0.971460        0.005987   \n",
       "35            0.974249            0.961373         0.964041        0.008806   \n",
       "36            0.974249            0.969957         0.965472        0.006516   \n",
       "37            0.991416            0.991416         0.988296        0.007410   \n",
       "38            0.982833            0.974249         0.972033        0.009103   \n",
       "39            0.974249            0.961373         0.964041        0.008806   \n",
       "40            0.978541            0.987124         0.978884        0.006710   \n",
       "41            0.974249            0.961373         0.964041        0.008806   \n",
       "42            0.982833            0.991416         0.985440        0.009099   \n",
       "43            0.974249            0.978541         0.979448        0.008604   \n",
       "44            0.978541            0.987124         0.979169        0.007303   \n",
       "45            0.974249            0.969957         0.971460        0.005987   \n",
       "46            0.978541            0.987124         0.979169        0.007303   \n",
       "47            0.978541            0.978541         0.976598        0.005606   \n",
       "48            0.982833            0.987124         0.979739        0.009570   \n",
       "49            0.978541            0.987124         0.978884        0.006710   \n",
       "\n",
       "    rank_test_score  \n",
       "0                48  \n",
       "1                10  \n",
       "2                15  \n",
       "3                 1  \n",
       "4                13  \n",
       "5                23  \n",
       "6                34  \n",
       "7                19  \n",
       "8                43  \n",
       "9                27  \n",
       "10               48  \n",
       "11               36  \n",
       "12               39  \n",
       "13               15  \n",
       "14               47  \n",
       "15                1  \n",
       "16               48  \n",
       "17                1  \n",
       "18               36  \n",
       "19               23  \n",
       "20               36  \n",
       "21               27  \n",
       "22               19  \n",
       "23               23  \n",
       "24               42  \n",
       "25               34  \n",
       "26               40  \n",
       "27                1  \n",
       "28               11  \n",
       "29                1  \n",
       "30                1  \n",
       "31                8  \n",
       "32               33  \n",
       "33               30  \n",
       "34               31  \n",
       "35               44  \n",
       "36               40  \n",
       "37                1  \n",
       "38               27  \n",
       "39               44  \n",
       "40               19  \n",
       "41               44  \n",
       "42                8  \n",
       "43               13  \n",
       "44               15  \n",
       "45               31  \n",
       "46               15  \n",
       "47               26  \n",
       "48               12  \n",
       "49               19  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KNN_model = KNeighborsClassifier()\n",
    "\n",
    "KNN_params = dict()\n",
    "KNN_params['n_neighbors'] = [i for i in range(1, 20, 5)]\n",
    "KNN_params['weights'] = [\"uniform\", \"distance\"]\n",
    "KNN_params['algorithm'] = [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "KNN_params['leaf_size'] = [1, 10, 30]\n",
    "KNN_params['p'] = [1, 2]\n",
    "\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(KNN_model, KNN_params, n_iter=50, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "KNN = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(KNN.cv_results_)\n",
    "\n",
    "# Stockage du meilleur résultat dans le tableau des résultats\n",
    "Evaluation_Results.iloc[5]['Best Mean Test Score'] = max(cv_results['mean_test_score'])\n",
    "\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79efd13",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Paramètres\n",
    "\n",
    "* `n_neighbors`: Permet de définir le nombre de voisins le plus proche. C'est-à-dire, le nombre de points à prendre dans la décision de classification. Ces points étant au plus proche de l'élément à classifier. C'est généralement un nombre pair.\n",
    "\n",
    "* `weights`: Permet de définir le poids de chaque point proches pris en compte dans la decision.\n",
    "    * *uniform* : Tous les points ont le même poids\n",
    "    * *distance* : Le poids de chaque point est déterminé en fonction de sa distance avec l'élément qu'on essaie de classifier.\n",
    "* `algorithm` : C'est l'algorithme utilisé pour trouver les points les plus proches de l'élément qu'on essaie de classifier.\n",
    "* `leaf_size` : Permet de définir la taille des feuilles utilisée dans les algorithmes *BallTree* et *KDTree*.\n",
    "\n",
    "#### Analyse des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b851472",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cv_results[[\"param_n_neighbors\",\"param_weights\",\"param_algorithm\",\"param_leaf_size\",\"mean_test_score\",\"rank_test_score\"]].sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c25f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Il semble difficile de déterminer quelle est la meilleure configuration au vu des résultats mais on peut on extraire une certaine tendance.\n",
    "\n",
    "Le paramètre `weights` n'a pas beaucoup d'importance.\n",
    "\n",
    "La différence se fait sur les paramètres `algotithm` et `n_neighbors` avec comme valeur pour le premier `kd_tree`/`ball_tree`/`auto` et pour le second `1`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e0efd4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "*Sources :*\n",
    "* [https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html)\n",
    "* [https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn](https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn)\n",
    "* [https://www.datasklr.com/select-classification-methods/k-nearest-neighbors](https://www.datasklr.com/select-classification-methods/k-nearest-neighbors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a310ff60",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Comparaison des résultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fcca1c5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Best Mean Test Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression (LR)</th>\n",
       "      <td>0.972313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naïve Bayes Classifier (NB)</th>\n",
       "      <td>0.864722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree Classifier (DT)</th>\n",
       "      <td>0.831629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gradient Boosting (GB)</th>\n",
       "      <td>0.967180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support Vector Machines (SVM)</th>\n",
       "      <td>0.990297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K Nearest Neighbours (KNN)</th>\n",
       "      <td>0.988296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Best Mean Test Score\n",
       "Logistic Regression (LR)                   0.972313\n",
       "Naïve Bayes Classifier (NB)                0.864722\n",
       "Decision Tree Classifier (DT)              0.831629\n",
       "Gradient Boosting (GB)                     0.967180\n",
       "Support Vector Machines (SVM)              0.990297\n",
       "K Nearest Neighbours (KNN)                 0.988296"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(Evaluation_Results)\n",
    "df.plot(kind = 'bar')\n",
    "plt.show()\n",
    "\n",
    "Evaluation_Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da478c88",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Au vu des résultats, le modèle ayant la meilleure exactitude semble être la classification machine à vecteurs de support avec pour paramètre 'gamma' = 0.001 et 'C'= 1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1eef281",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Entrainement et test d'un prédicteur\n",
    "\n",
    "Maintenant que l'on connait le modèle le plus efficace, nous allons créer un predicteur afin de répondre à notre problematique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d88ecaec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "SVC_definitive_model = svm.SVC(gamma=0.001, C=1)\n",
    "\n",
    "SVC_fitted = SVC_definitive_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15a5fd0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4fa26554",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "predicted = SVC_fitted.predict(x_test)\n",
    "disp = metrics.ConfusionMatrixDisplay.from_predictions(y_test, predicted, cmap=plt.cm.gray_r)\n",
    "disp.figure_.suptitle(\"Confusion Matrix\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ed6773",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "La matrice de confusion nous permet de constater que les rares erreurs sont souvent sur les labels 2, 5.\n",
    "Une solution envisageable serait d'ajouter plus de données pour les labels 2, 5 pour entrainer le modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158c219c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test du prédicteur avec des données externes\n",
    "\n",
    "Essayons à présent de tester notre prédicteur sur des images que nous avons créées grâce au logiciel paint.\n",
    "Les images créées pour le test sont assez différentes des images d'entrainements. En effet, les images d'entrainements ressemblent à des images créées avec une résolution élevée puis \"downscalées\" contrairement à nos images de test qui ont été réalisées directement en 8x8 pixel. Cette différence est visible au niveau de la plage de niveau de gris qui est plus large sur les images d'entrainement que sur les images de test ou un pixel est blanc ou noir uniquement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb5bfac6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image, ImageChops\n",
    "\n",
    "# Import de nos images et inversion des niveaux de gris\n",
    "image_test_1 = np.array(ImageChops.invert(Image.open('test_images/1.bmp'))) - 240\n",
    "image_test_2 = np.array(ImageChops.invert(Image.open('test_images/2.bmp'))) - 240\n",
    "image_test_3 = np.array(ImageChops.invert(Image.open('test_images/3.bmp'))) - 240\n",
    "image_test_4 = np.array(ImageChops.invert(Image.open('test_images/4.bmp'))) - 240\n",
    "image_test_5 = np.array(ImageChops.invert(Image.open('test_images/5.bmp'))) - 240\n",
    "image_test_6 = np.array(ImageChops.invert(Image.open('test_images/6.bmp'))) - 240\n",
    "image_test_7 = np.array(ImageChops.invert(Image.open('test_images/7.bmp'))) - 240\n",
    "image_test_8 = np.array(ImageChops.invert(Image.open('test_images/8.bmp'))) - 240\n",
    "image_test_9 = np.array(ImageChops.invert(Image.open('test_images/9.bmp'))) - 240\n",
    "\n",
    "\n",
    "images_test = np.array([image_test_1, image_test_2, image_test_3, image_test_4, image_test_5, image_test_6, image_test_7, image_test_8, image_test_9])\n",
    "\n",
    "# Création de 10 figures de 10 par 3 pixels\n",
    "_, axes = plt.subplots(nrows=1, ncols=9, figsize=(10, 3))\n",
    "\n",
    "# prédiction du prédicteur\n",
    "y_pred = SVC_fitted.predict(images_test.reshape(len(images_test), -1))\n",
    "\n",
    "# Pour chaque figure, on affiche l'image du chiffre et son label en titre\n",
    "for ax, image, label in zip(axes, images_test, y_pred):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_title(\"Pred: %i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b7a3bc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Malgrès les différences entre le jeu de test créé et le jeu d'entrainement, le prédicteur semble capable de reconnaitre les chiffres présents dans les images la plupart du temps. Cependant, après avoir modifié les images de test et réessayer plusieurs fois le test, on remarque que notre prédicteur à du mal à prédire les chiffres 3 et 6."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e661809a",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "Bien que notre prédicteur puisse atteindre 99% de véridicité sur le dataset initial, une fois confronté à des données rédigées à la main sur le logiciel paint sans anticrénelage, ce dernier semble perdre en efficacité. Cette perte s'explique par la spécificité du dataset initial. Afin de palier cette perte, nous pourrions completer le dataset en en ajoutant une version dupliquée dans laquelle nous supprimons l'antialiasing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3db89f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}