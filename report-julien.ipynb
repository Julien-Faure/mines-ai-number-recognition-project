{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02cc466",
   "metadata": {},
   "source": [
    "# Rapport du projet de résolution de problème\n",
    "\n",
    "- Paul Achard\n",
    "- Julien Faure\n",
    "\n",
    "    \n",
    "- *Date : 20/01/2022*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb09770",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b48d6",
   "metadata": {},
   "source": [
    "## Problématique\n",
    "\n",
    "Notre problématique est d'identifier un chiffre à partir d'une image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e9fea9",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "\n",
    "- Trouver un modèle permettant d'identifier un chiffre à partir d'une image\n",
    "- Comparer différentes stratégies de solveur pour le modèle trouvé\n",
    "\n",
    "## Analyse du dataset\n",
    "\n",
    "Identifier un chiffre à partir d'une image est une tache qui peut s'avérer très complexe. Afin d'avoir une difficulté raisonnable et adapté au contexte de ce projet, nous avons fixé certains paramètres dans notre dataset.\n",
    "\n",
    "- La résolution de nos images est identiques pour tout le dataset. Cette résolution est **8 pixels par 8 pixels**.\n",
    "- Chaque pixel est codé sur **4 bits**.\n",
    "- Les images contiennent uniquement un chiffre sans élément parasite, sans effet et sans traitement.\n",
    "\n",
    "Nous utilisons le dataset `digits` de `seaborn`.\n",
    "\n",
    "### Forme du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7058757",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Data Shape (1797, 64)\n",
      "Label Data Shape (1797,)\n"
     ]
    }
   ],
   "source": [
    "# Import du dataset\n",
    "digits = datasets.load_digits()\n",
    "\n",
    "# Affiche le nombre d'images et leur format\n",
    "print(\"Image Data Shape\" , digits.data.shape)\n",
    "\n",
    "# Affiche le nombre de labels\n",
    "print(\"Label Data Shape\", digits.target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2249071",
   "metadata": {},
   "source": [
    "Comme nous pouvons le voir ci-dessus, le dataset est composé de **1797** images labellisées."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83361c1",
   "metadata": {},
   "source": [
    "### Répartition des images du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c719dd6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0.5, 0, 'n° labellisé'), Text(0, 0.5, 'Occurrence')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graphique = sns.countplot(x=digits.target)\n",
    "graphique.set(xlabel=\"n° labellisé\", ylabel = \"Occurrence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "113cc60d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Les données labellisées sont équitablement distribuées (environ 175 par label)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0263bcfc",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Représentation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22165d88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x216 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Création de 10 figures de 10 par 3 pixels\n",
    "_, axes = plt.subplots(nrows=1, ncols=10, figsize=(10, 3))\n",
    "\n",
    "# Pour chaque figure, on affiche l'image du chiffre et son label en titre\n",
    "for ax, image, label in zip(axes, digits.images, digits.target):\n",
    "    ax.set_axis_off()\n",
    "    ax.imshow(image, cmap=plt.cm.gray_r)\n",
    "    ax.set_title(\"Label: %i\" % label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08eef31",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Représentation des images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8646744b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  5. 13.  9.  1.  0.  0.]\n",
      " [ 0.  0. 13. 15. 10. 15.  5.  0.]\n",
      " [ 0.  3. 15.  2.  0. 11.  8.  0.]\n",
      " [ 0.  4. 12.  0.  0.  8.  8.  0.]\n",
      " [ 0.  5.  8.  0.  0.  9.  8.  0.]\n",
      " [ 0.  4. 11.  0.  1. 12.  7.  0.]\n",
      " [ 0.  2. 14.  5. 10. 12.  0.  0.]\n",
      " [ 0.  0.  6. 13. 10.  0.  0.  0.]]\n",
      "\n",
      " Type de chaque valeur : <class 'numpy.float64'>\n"
     ]
    }
   ],
   "source": [
    "# Affiche le tableau représentant la première image\n",
    "print(digits.images[0])\n",
    "print(\"\\n Type de chaque valeur :\", type(digits.images[0][0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e11e40",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "> Comme nous l'avons vu précédemment, chaque image possède une résolution de 8x8 pixels en niveaux de gris codés sur 4bits par pixel.\n",
    "\n",
    "Dans notre programme, une image est représentée par une matrice de dimension 8x8. Chaque élément représente un pixel avec un niveau de gris codé sur 4bits (de 0 à 15). Plus la valeur est élevée, plus la couleur est foncée.\n",
    "\n",
    "> Exemple :\n",
    "* 0 : Blanc\n",
    "* 15 : Noir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef9955d",
   "metadata": {},
   "source": [
    "\n",
    "## Modèles\n",
    "\n",
    "Pour résoudre notre problème, nous allons essayer les modèles suivants :\n",
    "* [Modèle de regréssion logistique multiclasse](#Mod%C3%A8le-de-regr%C3%A9ssion-logistique-multiclasse)\n",
    "* [Modèle de Bayes](#Mod%C3%A8le-de-Bayes)\n",
    "\n",
    "### Mise en forme des données d'entrées\n",
    "\n",
    "Pour commencer, nous devons redimenssionner nos données d'entrées.\n",
    "\n",
    "Actuellement, nous avons des données sous la forme d'un tableau de matrice.\n",
    "\n",
    "Il nous faut les mettre sous forme d'une matrice où chaque vecteur correspond aux pixels de l'image.\n",
    "\n",
    "Donc si nous avons 1797 images, la matrice d'entrée est composée de 1797 vecteurs.\n",
    "\n",
    "Avec une résolution de 8x8, la taille d'un vecteur est de 64 valeurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3eda88d6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  5. 13.  9.  1.  0.  0.  0.  0. 13. 15. 10. 15.  5.  0.  0.  3.\n",
      " 15.  2.  0. 11.  8.  0.  0.  4. 12.  0.  0.  8.  8.  0.  0.  5.  8.  0.\n",
      "  0.  9.  8.  0.  0.  4. 11.  0.  1. 12.  7.  0.  0.  2. 14.  5. 10. 12.\n",
      "  0.  0.  0.  0.  6. 13. 10.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "# Redimensionne la matrice en vecteur\n",
    "print(digits.images[0].reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e2601f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold, GridSearchCV\n",
    "\n",
    "# Redimenssionne le tableau de matrice en matrice\n",
    "x = digits.images.reshape((len(digits.images), -1))\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a43546e",
   "metadata": {},
   "source": [
    "### Jeu de test et jeu d'entraînement\n",
    "\n",
    "Il nous faut maintenant séparer notre jeu de test et notre jeu d'entraînement du dataset.\n",
    "\n",
    "Pour choisir la taille de notre jeu de test, il est nécessaire de faire attention à plusieurs points :\n",
    "* Le temps d'entrainement de notre modèle\n",
    "* La taille de notre dataset\n",
    "\n",
    "Plus la proportion du jeu d'entraînement est faible, plus notre modèle à un niveau de variance élevé. Ainsi, on augmente les chances d'avoir de l'*over fitting*.\n",
    "\n",
    "A contrario, plus la proportion du jeu de test est faible, plus notre modèle à un niveau de variance faible. Ainsi, on augmente les chances d'avoir de l'*under fitting*.\n",
    "\n",
    "Le but est donc de trouver la valeur qui nous permet d'avoir le taux de variance optimal.\n",
    "\n",
    "\n",
    "Pour trouver cette valeur, nous avons appliqué la procédure suivante, nous avons essayé avec plusieurs valeurs en partant de 20% jusqu'à 80% avec un pas de 5%. Nous avons déterminé que la meilleure valeur est **35%**.\n",
    "\n",
    "\n",
    "> [https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio](https://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ad00a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# séparation du dataset en données \"d'apprentissage\" et de test\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.35, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa5e89",
   "metadata": {},
   "source": [
    "### Modèle de regréssion logistique multiclasse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39c0da8b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 18 candidates, totalling 270 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "45 fits failed out of a total of 270.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "45 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py\", line 464, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.97231332 0.97231332 0.96489613 0.96631329 0.95546507        nan\n",
      " 0.96917575 0.96917575 0.95719648 0.96631329 0.95546507        nan\n",
      " 0.96889207 0.96946187 0.95633934 0.96631329 0.95546507        nan]\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the train scores are non-finite: [1.         1.         0.99600438 1.         1.                nan\n",
      " 1.         1.         0.99978594 1.         1.                nan\n",
      " 1.         1.         1.         1.         1.                nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>param_solver</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>split5_test_score</th>\n",
       "      <th>split6_test_score</th>\n",
       "      <th>split7_test_score</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>split5_train_score</th>\n",
       "      <th>split6_train_score</th>\n",
       "      <th>split7_train_score</th>\n",
       "      <th>split8_train_score</th>\n",
       "      <th>split9_train_score</th>\n",
       "      <th>split10_train_score</th>\n",
       "      <th>split11_train_score</th>\n",
       "      <th>split12_train_score</th>\n",
       "      <th>split13_train_score</th>\n",
       "      <th>split14_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.625355</td>\n",
       "      <td>0.055884</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.972313</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.618404</td>\n",
       "      <td>0.534624</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.987179</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.972313</td>\n",
       "      <td>0.009115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088304</td>\n",
       "      <td>0.008677</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.1</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'l2', 'solver': 'libline...</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.982833</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.964896</td>\n",
       "      <td>0.010858</td>\n",
       "      <td>10</td>\n",
       "      <td>0.994647</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>0.994647</td>\n",
       "      <td>0.995722</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.992505</td>\n",
       "      <td>0.996788</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.995722</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.996788</td>\n",
       "      <td>0.995717</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>0.996004</td>\n",
       "      <td>0.001381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175708</td>\n",
       "      <td>0.020515</td>\n",
       "      <td>0.000533</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.1</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'none', 'solver': 'newto...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.966313</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.063431</td>\n",
       "      <td>0.005503</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.1</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 0.1, 'penalty': 'none', 'solver': 'libli...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.942083</td>\n",
       "      <td>0.156450</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969176</td>\n",
       "      <td>0.010046</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.515374</td>\n",
       "      <td>0.713929</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969176</td>\n",
       "      <td>0.010046</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.155098</td>\n",
       "      <td>0.028966</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.000062</td>\n",
       "      <td>5</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.927350</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.957196</td>\n",
       "      <td>0.013863</td>\n",
       "      <td>11</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998930</td>\n",
       "      <td>0.999786</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.176597</td>\n",
       "      <td>0.013957</td>\n",
       "      <td>0.000550</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 5, 'penalty': 'none', 'solver': 'newton-...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.966313</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.058872</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 5, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 5, 'penalty': 'none', 'solver': 'libline...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.839482</td>\n",
       "      <td>0.118927</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.968892</td>\n",
       "      <td>0.010662</td>\n",
       "      <td>6</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.685158</td>\n",
       "      <td>0.901583</td>\n",
       "      <td>0.000560</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.978541</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.987124</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.969462</td>\n",
       "      <td>0.010246</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.146287</td>\n",
       "      <td>0.017993</td>\n",
       "      <td>0.000597</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.956339</td>\n",
       "      <td>0.013886</td>\n",
       "      <td>12</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.164898</td>\n",
       "      <td>0.021833</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>newton-cg</td>\n",
       "      <td>{'C': 10, 'penalty': 'none', 'solver': 'newton...</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.961373</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.982906</td>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.974249</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.978632</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.966313</td>\n",
       "      <td>0.011621</td>\n",
       "      <td>7</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.059620</td>\n",
       "      <td>0.004877</td>\n",
       "      <td>0.000529</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>lbfgs</td>\n",
       "      <td>{'C': 10, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.970085</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.969957</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.957265</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.957082</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.955465</td>\n",
       "      <td>0.013029</td>\n",
       "      <td>13</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>liblinear</td>\n",
       "      <td>{'C': 10, 'penalty': 'none', 'solver': 'liblin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.625355      0.055884         0.000564        0.000081     0.1   \n",
       "1        1.618404      0.534624         0.000552        0.000050     0.1   \n",
       "2        0.088304      0.008677         0.000625        0.000065     0.1   \n",
       "3        0.175708      0.020515         0.000533        0.000109     0.1   \n",
       "4        0.063431      0.005503         0.000558        0.000100     0.1   \n",
       "5        0.000475      0.000084         0.000000        0.000000     0.1   \n",
       "6        0.942083      0.156450         0.000588        0.000061       5   \n",
       "7        2.515374      0.713929         0.000547        0.000101       5   \n",
       "8        0.155098      0.028966         0.000627        0.000062       5   \n",
       "9        0.176597      0.013957         0.000550        0.000054       5   \n",
       "10       0.058872      0.006545         0.000547        0.000079       5   \n",
       "11       0.000492      0.000320         0.000000        0.000000       5   \n",
       "12       0.839482      0.118927         0.000538        0.000095      10   \n",
       "13       2.685158      0.901583         0.000560        0.000069      10   \n",
       "14       0.146287      0.017993         0.000597        0.000091      10   \n",
       "15       0.164898      0.021833         0.000528        0.000085      10   \n",
       "16       0.059620      0.004877         0.000529        0.000084      10   \n",
       "17       0.000474      0.000129         0.000000        0.000000      10   \n",
       "\n",
       "   param_penalty param_solver  \\\n",
       "0             l2    newton-cg   \n",
       "1             l2        lbfgs   \n",
       "2             l2    liblinear   \n",
       "3           none    newton-cg   \n",
       "4           none        lbfgs   \n",
       "5           none    liblinear   \n",
       "6             l2    newton-cg   \n",
       "7             l2        lbfgs   \n",
       "8             l2    liblinear   \n",
       "9           none    newton-cg   \n",
       "10          none        lbfgs   \n",
       "11          none    liblinear   \n",
       "12            l2    newton-cg   \n",
       "13            l2        lbfgs   \n",
       "14            l2    liblinear   \n",
       "15          none    newton-cg   \n",
       "16          none        lbfgs   \n",
       "17          none    liblinear   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-...           0.978632   \n",
       "1      {'C': 0.1, 'penalty': 'l2', 'solver': 'lbfgs'}           0.978632   \n",
       "2   {'C': 0.1, 'penalty': 'l2', 'solver': 'libline...           0.978632   \n",
       "3   {'C': 0.1, 'penalty': 'none', 'solver': 'newto...           0.970085   \n",
       "4    {'C': 0.1, 'penalty': 'none', 'solver': 'lbfgs'}           0.957265   \n",
       "5   {'C': 0.1, 'penalty': 'none', 'solver': 'libli...                NaN   \n",
       "6    {'C': 5, 'penalty': 'l2', 'solver': 'newton-cg'}           0.978632   \n",
       "7        {'C': 5, 'penalty': 'l2', 'solver': 'lbfgs'}           0.978632   \n",
       "8    {'C': 5, 'penalty': 'l2', 'solver': 'liblinear'}           0.970085   \n",
       "9   {'C': 5, 'penalty': 'none', 'solver': 'newton-...           0.970085   \n",
       "10     {'C': 5, 'penalty': 'none', 'solver': 'lbfgs'}           0.957265   \n",
       "11  {'C': 5, 'penalty': 'none', 'solver': 'libline...                NaN   \n",
       "12  {'C': 10, 'penalty': 'l2', 'solver': 'newton-cg'}           0.974359   \n",
       "13      {'C': 10, 'penalty': 'l2', 'solver': 'lbfgs'}           0.974359   \n",
       "14  {'C': 10, 'penalty': 'l2', 'solver': 'liblinear'}           0.970085   \n",
       "15  {'C': 10, 'penalty': 'none', 'solver': 'newton...           0.970085   \n",
       "16    {'C': 10, 'penalty': 'none', 'solver': 'lbfgs'}           0.957265   \n",
       "17  {'C': 10, 'penalty': 'none', 'solver': 'liblin...                NaN   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.965812           0.974359           0.982833   \n",
       "1            0.965812           0.974359           0.982833   \n",
       "2            0.965812           0.961538           0.969957   \n",
       "3            0.957265           0.965812           0.974249   \n",
       "4            0.948718           0.965812           0.944206   \n",
       "5                 NaN                NaN                NaN   \n",
       "6            0.970085           0.965812           0.974249   \n",
       "7            0.970085           0.965812           0.974249   \n",
       "8            0.965812           0.952991           0.965665   \n",
       "9            0.957265           0.965812           0.974249   \n",
       "10           0.948718           0.965812           0.944206   \n",
       "11                NaN                NaN                NaN   \n",
       "12           0.965812           0.965812           0.978541   \n",
       "13           0.970085           0.965812           0.978541   \n",
       "14           0.965812           0.944444           0.969957   \n",
       "15           0.957265           0.965812           0.974249   \n",
       "16           0.948718           0.965812           0.944206   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split4_test_score  split5_test_score  split6_test_score  \\\n",
       "0            0.969957           0.974359           0.987179   \n",
       "1            0.969957           0.974359           0.987179   \n",
       "2            0.952790           0.957265           0.982906   \n",
       "3            0.961373           0.978632           0.982906   \n",
       "4            0.948498           0.970085           0.970085   \n",
       "5                 NaN                NaN                NaN   \n",
       "6            0.965665           0.974359           0.978632   \n",
       "7            0.965665           0.974359           0.978632   \n",
       "8            0.952790           0.957265           0.974359   \n",
       "9            0.961373           0.978632           0.982906   \n",
       "10           0.948498           0.970085           0.970085   \n",
       "11                NaN                NaN                NaN   \n",
       "12           0.965665           0.978632           0.978632   \n",
       "13           0.965665           0.978632           0.978632   \n",
       "14           0.952790           0.957265           0.974359   \n",
       "15           0.961373           0.978632           0.982906   \n",
       "16           0.948498           0.970085           0.970085   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split7_test_score  split8_test_score  split9_test_score  \\\n",
       "0            0.970085           0.957082           0.982833   \n",
       "1            0.970085           0.957082           0.982833   \n",
       "2            0.952991           0.948498           0.982833   \n",
       "3            0.974359           0.957082           0.974249   \n",
       "4            0.965812           0.922747           0.969957   \n",
       "5                 NaN                NaN                NaN   \n",
       "6            0.965812           0.965665           0.987124   \n",
       "7            0.965812           0.965665           0.987124   \n",
       "8            0.927350           0.948498           0.969957   \n",
       "9            0.974359           0.957082           0.974249   \n",
       "10           0.965812           0.922747           0.969957   \n",
       "11                NaN                NaN                NaN   \n",
       "12           0.965812           0.965665           0.987124   \n",
       "13           0.965812           0.965665           0.987124   \n",
       "14           0.935897           0.944206           0.965665   \n",
       "15           0.974359           0.957082           0.974249   \n",
       "16           0.965812           0.922747           0.969957   \n",
       "17                NaN                NaN                NaN   \n",
       "\n",
       "    split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0             0.970085            0.961538            0.982906   \n",
       "1             0.970085            0.961538            0.982906   \n",
       "2             0.952991            0.961538            0.974359   \n",
       "3             0.965812            0.961538            0.978632   \n",
       "4             0.948718            0.957265            0.965812   \n",
       "5                  NaN                 NaN                 NaN   \n",
       "6             0.957265            0.957265            0.982906   \n",
       "7             0.957265            0.957265            0.982906   \n",
       "8             0.935897            0.940171            0.974359   \n",
       "9             0.965812            0.961538            0.978632   \n",
       "10            0.948718            0.957265            0.965812   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "12            0.952991            0.957265            0.982906   \n",
       "13            0.957265            0.957265            0.982906   \n",
       "14            0.931624            0.940171            0.974359   \n",
       "15            0.965812            0.961538            0.978632   \n",
       "16            0.948718            0.957265            0.965812   \n",
       "17                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0             0.969957            0.957082         0.972313        0.009115   \n",
       "1             0.969957            0.957082         0.972313        0.009115   \n",
       "2             0.961373            0.969957         0.964896        0.010858   \n",
       "3             0.957082            0.935622         0.966313        0.011621   \n",
       "4             0.957082            0.939914         0.955465        0.013029   \n",
       "5                  NaN                 NaN              NaN             NaN   \n",
       "6             0.965665            0.948498         0.969176        0.010046   \n",
       "7             0.965665            0.948498         0.969176        0.010046   \n",
       "8             0.965665            0.957082         0.957196        0.013863   \n",
       "9             0.957082            0.935622         0.966313        0.011621   \n",
       "10            0.957082            0.939914         0.955465        0.013029   \n",
       "11                 NaN                 NaN              NaN             NaN   \n",
       "12            0.965665            0.948498         0.968892        0.010662   \n",
       "13            0.965665            0.948498         0.969462        0.010246   \n",
       "14            0.965665            0.952790         0.956339        0.013886   \n",
       "15            0.957082            0.935622         0.966313        0.011621   \n",
       "16            0.957082            0.939914         0.955465        0.013029   \n",
       "17                 NaN                 NaN              NaN             NaN   \n",
       "\n",
       "    rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                 1            1.000000            1.000000   \n",
       "1                 1            1.000000            1.000000   \n",
       "2                10            0.994647            0.998929   \n",
       "3                 7            1.000000            1.000000   \n",
       "4                13            1.000000            1.000000   \n",
       "5                17                 NaN                 NaN   \n",
       "6                 4            1.000000            1.000000   \n",
       "7                 4            1.000000            1.000000   \n",
       "8                11            0.998929            1.000000   \n",
       "9                 7            1.000000            1.000000   \n",
       "10               13            1.000000            1.000000   \n",
       "11               16                 NaN                 NaN   \n",
       "12                6            1.000000            1.000000   \n",
       "13                3            1.000000            1.000000   \n",
       "14               12            1.000000            1.000000   \n",
       "15                7            1.000000            1.000000   \n",
       "16               13            1.000000            1.000000   \n",
       "17               18                 NaN                 NaN   \n",
       "\n",
       "    split2_train_score  split3_train_score  split4_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             1.000000            1.000000            1.000000   \n",
       "2             0.994647            0.995722            0.996791   \n",
       "3             1.000000            1.000000            1.000000   \n",
       "4             1.000000            1.000000            1.000000   \n",
       "5                  NaN                 NaN                 NaN   \n",
       "6             1.000000            1.000000            1.000000   \n",
       "7             1.000000            1.000000            1.000000   \n",
       "8             1.000000            1.000000            1.000000   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "12            1.000000            1.000000            1.000000   \n",
       "13            1.000000            1.000000            1.000000   \n",
       "14            1.000000            1.000000            1.000000   \n",
       "15            1.000000            1.000000            1.000000   \n",
       "16            1.000000            1.000000            1.000000   \n",
       "17                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split5_train_score  split6_train_score  split7_train_score  \\\n",
       "0             1.000000            1.000000            1.000000   \n",
       "1             1.000000            1.000000            1.000000   \n",
       "2             0.992505            0.996788            0.995717   \n",
       "3             1.000000            1.000000            1.000000   \n",
       "4             1.000000            1.000000            1.000000   \n",
       "5                  NaN                 NaN                 NaN   \n",
       "6             1.000000            1.000000            1.000000   \n",
       "7             1.000000            1.000000            1.000000   \n",
       "8             1.000000            0.998929            1.000000   \n",
       "9             1.000000            1.000000            1.000000   \n",
       "10            1.000000            1.000000            1.000000   \n",
       "11                 NaN                 NaN                 NaN   \n",
       "12            1.000000            1.000000            1.000000   \n",
       "13            1.000000            1.000000            1.000000   \n",
       "14            1.000000            1.000000            1.000000   \n",
       "15            1.000000            1.000000            1.000000   \n",
       "16            1.000000            1.000000            1.000000   \n",
       "17                 NaN                 NaN                 NaN   \n",
       "\n",
       "    split8_train_score  split9_train_score  split10_train_score  \\\n",
       "0             1.000000            1.000000             1.000000   \n",
       "1             1.000000            1.000000             1.000000   \n",
       "2             0.995722            0.996791             0.995717   \n",
       "3             1.000000            1.000000             1.000000   \n",
       "4             1.000000            1.000000             1.000000   \n",
       "5                  NaN                 NaN                  NaN   \n",
       "6             1.000000            1.000000             1.000000   \n",
       "7             1.000000            1.000000             1.000000   \n",
       "8             1.000000            1.000000             1.000000   \n",
       "9             1.000000            1.000000             1.000000   \n",
       "10            1.000000            1.000000             1.000000   \n",
       "11                 NaN                 NaN                  NaN   \n",
       "12            1.000000            1.000000             1.000000   \n",
       "13            1.000000            1.000000             1.000000   \n",
       "14            1.000000            1.000000             1.000000   \n",
       "15            1.000000            1.000000             1.000000   \n",
       "16            1.000000            1.000000             1.000000   \n",
       "17                 NaN                 NaN                  NaN   \n",
       "\n",
       "    split11_train_score  split12_train_score  split13_train_score  \\\n",
       "0              1.000000             1.000000             1.000000   \n",
       "1              1.000000             1.000000             1.000000   \n",
       "2              0.996788             0.995717             0.996791   \n",
       "3              1.000000             1.000000             1.000000   \n",
       "4              1.000000             1.000000             1.000000   \n",
       "5                   NaN                  NaN                  NaN   \n",
       "6              1.000000             1.000000             1.000000   \n",
       "7              1.000000             1.000000             1.000000   \n",
       "8              1.000000             1.000000             1.000000   \n",
       "9              1.000000             1.000000             1.000000   \n",
       "10             1.000000             1.000000             1.000000   \n",
       "11                  NaN                  NaN                  NaN   \n",
       "12             1.000000             1.000000             1.000000   \n",
       "13             1.000000             1.000000             1.000000   \n",
       "14             1.000000             1.000000             1.000000   \n",
       "15             1.000000             1.000000             1.000000   \n",
       "16             1.000000             1.000000             1.000000   \n",
       "17                  NaN                  NaN                  NaN   \n",
       "\n",
       "    split14_train_score  mean_train_score  std_train_score  \n",
       "0              1.000000          1.000000         0.000000  \n",
       "1              1.000000          1.000000         0.000000  \n",
       "2              0.996791          0.996004         0.001381  \n",
       "3              1.000000          1.000000         0.000000  \n",
       "4              1.000000          1.000000         0.000000  \n",
       "5                   NaN               NaN              NaN  \n",
       "6              1.000000          1.000000         0.000000  \n",
       "7              1.000000          1.000000         0.000000  \n",
       "8              0.998930          0.999786         0.000428  \n",
       "9              1.000000          1.000000         0.000000  \n",
       "10             1.000000          1.000000         0.000000  \n",
       "11                  NaN               NaN              NaN  \n",
       "12             1.000000          1.000000         0.000000  \n",
       "13             1.000000          1.000000         0.000000  \n",
       "14             1.000000          1.000000         0.000000  \n",
       "15             1.000000          1.000000         0.000000  \n",
       "16             1.000000          1.000000         0.000000  \n",
       "17                  NaN               NaN              NaN  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Création du modèle de régression\n",
    "LR_model = LogisticRegression(verbose=False, max_iter=10000)\n",
    "\n",
    "# Dictionnaire contenant les différents paramètres à essayer\n",
    "LR_params = dict()\n",
    "LR_params['solver'] = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "LR_params['penalty'] = ['l2', 'none']\n",
    "LR_params['C'] = [0.1, 5, 10]\n",
    "\n",
    "# Création de nos itérations\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "# Création de notre modèle de validation croisée\n",
    "model_cv = GridSearchCV(estimator=LR_model,\n",
    "                        param_grid=LR_params,\n",
    "                        scoring='accuracy',\n",
    "                        cv=kFold,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        return_train_score=True)\n",
    "\n",
    "# Entrainement du modèle\n",
    "model_cv.fit(x_train, y_train)\n",
    "# cv results\n",
    "pd.set_option('display.max_columns', None)\n",
    "cv_results = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab8139c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "La validation croisée nous permet de determiner les paramètres optimaux pour notre modèle d'apprentissage.\n",
    "Les résultats de nos tests avec de nombreux paramètres différents (dont la plupart ne sont pas présent dans l'exemple ci-dessus).\n",
    "* Le **paramètre C** correspond à l'inverse de la force de régularisation des données. Plus ce paramètre est grand, plus le risque d'overfitting est grand. Une valeur de 0.1 semble être optimale.\n",
    "* Le **paramètre de pénalité** permet de réduire les coefficients θ. On remarque une perte de précision si l'on n'applique pas de pénalité. La meilleure pénalité semble être la norme L2.\n",
    "* Le **solveur** correspond à l'algorithme d'optimisation utilisé pour l'entrainement. Dans notre cas, lbfgs permet d'obtenir la precision la plus élevée malgré un temps d'entrainement significativement plus long que ses concurrents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82b1e15",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification naïve bayésienne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08e85b2f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010691</td>\n",
       "      <td>0.005078</td>\n",
       "      <td>0.003557</td>\n",
       "      <td>0.002598</td>\n",
       "      <td>0</td>\n",
       "      <td>{'alpha': 0}</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.853594</td>\n",
       "      <td>0.015985</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010525</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.003512</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.863296</td>\n",
       "      <td>0.015941</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.012197</td>\n",
       "      <td>0.006658</td>\n",
       "      <td>0.003644</td>\n",
       "      <td>0.002018</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.864722</td>\n",
       "      <td>0.014346</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009348</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.864154</td>\n",
       "      <td>0.012277</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006661</td>\n",
       "      <td>0.001018</td>\n",
       "      <td>0.002198</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.888412</td>\n",
       "      <td>0.864442</td>\n",
       "      <td>0.012759</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006939</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>0.5</td>\n",
       "      <td>{'alpha': 0.5}</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.859300</td>\n",
       "      <td>0.013215</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006219</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>0.001792</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{'alpha': 1.0}</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.857587</td>\n",
       "      <td>0.013731</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0       0.010691      0.005078         0.003557        0.002598           0   \n",
       "1       0.010525      0.001966         0.003512        0.001588      0.0001   \n",
       "2       0.012197      0.006658         0.003644        0.002018       0.001   \n",
       "3       0.009348      0.001941         0.003311        0.001723        0.01   \n",
       "4       0.006661      0.001018         0.002198        0.000877         0.1   \n",
       "5       0.006939      0.001241         0.001852        0.000252         0.5   \n",
       "6       0.006219      0.001013         0.001792        0.000311         1.0   \n",
       "\n",
       "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0       {'alpha': 0}           0.837607           0.871795           0.854701   \n",
       "1  {'alpha': 0.0001}           0.841880           0.884615           0.854701   \n",
       "2   {'alpha': 0.001}           0.846154           0.884615           0.854701   \n",
       "3    {'alpha': 0.01}           0.850427           0.884615           0.854701   \n",
       "4     {'alpha': 0.1}           0.854701           0.880342           0.854701   \n",
       "5     {'alpha': 0.5}           0.850427           0.876068           0.850427   \n",
       "6     {'alpha': 1.0}           0.850427           0.871795           0.850427   \n",
       "\n",
       "   split3_test_score  ...  split8_test_score  split9_test_score  \\\n",
       "0           0.836910  ...           0.819742           0.875536   \n",
       "1           0.849785  ...           0.828326           0.879828   \n",
       "2           0.849785  ...           0.836910           0.875536   \n",
       "3           0.849785  ...           0.841202           0.875536   \n",
       "4           0.849785  ...           0.841202           0.884120   \n",
       "5           0.845494  ...           0.836910           0.884120   \n",
       "6           0.841202  ...           0.832618           0.879828   \n",
       "\n",
       "   split10_test_score  split11_test_score  split12_test_score  \\\n",
       "0            0.833333            0.854701            0.858974   \n",
       "1            0.854701            0.858974            0.867521   \n",
       "2            0.854701            0.858974            0.867521   \n",
       "3            0.858974            0.858974            0.863248   \n",
       "4            0.867521            0.858974            0.854701   \n",
       "5            0.871795            0.850427            0.854701   \n",
       "6            0.871795            0.841880            0.854701   \n",
       "\n",
       "   split13_test_score  split14_test_score  mean_test_score  std_test_score  \\\n",
       "0            0.866953            0.871245         0.853594        0.015985   \n",
       "1            0.871245            0.884120         0.863296        0.015941   \n",
       "2            0.871245            0.884120         0.864722        0.014346   \n",
       "3            0.871245            0.884120         0.864154        0.012277   \n",
       "4            0.871245            0.888412         0.864442        0.012759   \n",
       "5            0.854077            0.875536         0.859300        0.013215   \n",
       "6            0.854077            0.875536         0.857587        0.013731   \n",
       "\n",
       "   rank_test_score  \n",
       "0                7  \n",
       "1                4  \n",
       "2                1  \n",
       "3                3  \n",
       "4                2  \n",
       "5                5  \n",
       "6                6  \n",
       "\n",
       "[7 rows x 24 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "NB_model = BernoulliNB()\n",
    "\n",
    "NB_params = {'alpha': [0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0]}\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(NB_model, NB_params, n_iter=7, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "# NB = RCV.fit(x_train, y_train).best_estimator_\n",
    "RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(RCV.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dce8c9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Le seul paramètre testé dans ce modèle, alpha, correspond à la force du lissage de Laplace a appliqué au modèle.\n",
    "En d'autres termes, ce paramètre permet de palier la présence d'une caractéristique dans le jeu de test qui n'existe pas dans le jeu d'entrainement.\n",
    "> https://towardsdatascience.com/laplace-smoothing-in-na%C3%AFve-bayes-algorithm-9c237a8bdece\n",
    "\n",
    "Au vu des résultats, le paramètre alpha semble être optimal autour de 0.001\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52e82f2",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification par arbre de décision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6e3eb0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/model_selection/_search.py:292: UserWarning: The total space of parameters 32 is smaller than n_iter=50. Running 32 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_splitter</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_criterion</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013529</td>\n",
       "      <td>0.002957</td>\n",
       "      <td>0.001409</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.467811</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.442060</td>\n",
       "      <td>0.452941</td>\n",
       "      <td>0.025060</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005404</td>\n",
       "      <td>0.001093</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 1, ...</td>\n",
       "      <td>0.431624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.542735</td>\n",
       "      <td>0.478632</td>\n",
       "      <td>0.489270</td>\n",
       "      <td>0.480687</td>\n",
       "      <td>0.495466</td>\n",
       "      <td>0.043511</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.013018</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.446352</td>\n",
       "      <td>0.453514</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.006497</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.001706</td>\n",
       "      <td>0.001761</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 2, ...</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.523605</td>\n",
       "      <td>0.459227</td>\n",
       "      <td>0.482906</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.416309</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.478899</td>\n",
       "      <td>0.047122</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013622</td>\n",
       "      <td>0.002056</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>best</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.467811</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.442060</td>\n",
       "      <td>0.452941</td>\n",
       "      <td>0.025060</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.006401</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>0.001139</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 3, ...</td>\n",
       "      <td>0.431624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.502146</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.440171</td>\n",
       "      <td>0.572650</td>\n",
       "      <td>0.506438</td>\n",
       "      <td>0.506438</td>\n",
       "      <td>0.480023</td>\n",
       "      <td>0.049381</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.011536</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.001109</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>...</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.472103</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.452991</td>\n",
       "      <td>0.465812</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.446352</td>\n",
       "      <td>0.453514</td>\n",
       "      <td>0.025147</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005277</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000992</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 4, ...</td>\n",
       "      <td>0.517094</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493562</td>\n",
       "      <td>0.437768</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>0.467811</td>\n",
       "      <td>0.480687</td>\n",
       "      <td>0.489113</td>\n",
       "      <td>0.036240</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.029272</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.001365</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.862661</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.818747</td>\n",
       "      <td>0.032519</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.011556</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>0.001618</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 1, ...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.822774</td>\n",
       "      <td>0.032455</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.027574</td>\n",
       "      <td>0.003686</td>\n",
       "      <td>0.001290</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.755365</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.807903</td>\n",
       "      <td>0.032118</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.010135</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 2, ...</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.809943</td>\n",
       "      <td>0.032042</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.026547</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>best</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.759657</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.799626</td>\n",
       "      <td>0.030002</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.010060</td>\n",
       "      <td>0.001546</td>\n",
       "      <td>0.001128</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 3, ...</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.813378</td>\n",
       "      <td>0.028521</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.026192</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.746781</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.799056</td>\n",
       "      <td>0.037100</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.001583</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>gini</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 4, ...</td>\n",
       "      <td>0.739316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.790598</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.785408</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.801643</td>\n",
       "      <td>0.031105</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.015973</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.001246</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.566524</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 1, ...</td>\n",
       "      <td>0.491453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.497854</td>\n",
       "      <td>0.478632</td>\n",
       "      <td>0.478632</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.433476</td>\n",
       "      <td>0.600858</td>\n",
       "      <td>0.521117</td>\n",
       "      <td>0.044243</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.016651</td>\n",
       "      <td>0.004608</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.566524</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.005220</td>\n",
       "      <td>0.000744</td>\n",
       "      <td>0.000991</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 2, ...</td>\n",
       "      <td>0.508547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.508547</td>\n",
       "      <td>0.517094</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.523605</td>\n",
       "      <td>0.519313</td>\n",
       "      <td>0.519099</td>\n",
       "      <td>0.026562</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.013769</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.001441</td>\n",
       "      <td>0.001709</td>\n",
       "      <td>best</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.566524</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.005151</td>\n",
       "      <td>0.000802</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 3, ...</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463519</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.553648</td>\n",
       "      <td>0.536481</td>\n",
       "      <td>0.541619</td>\n",
       "      <td>0.045123</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.015042</td>\n",
       "      <td>0.003867</td>\n",
       "      <td>0.001196</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.495726</td>\n",
       "      <td>...</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.566524</td>\n",
       "      <td>0.559829</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.581197</td>\n",
       "      <td>0.549356</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.554508</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.005833</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 4, ...</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>...</td>\n",
       "      <td>0.527897</td>\n",
       "      <td>0.545064</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.508547</td>\n",
       "      <td>0.532189</td>\n",
       "      <td>0.506438</td>\n",
       "      <td>0.518009</td>\n",
       "      <td>0.031863</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.036111</td>\n",
       "      <td>0.005470</td>\n",
       "      <td>0.001198</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>best</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 1, 'm...</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.825903</td>\n",
       "      <td>0.037466</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.002279</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>random</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 1, ...</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.830767</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.036049</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.001202</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>best</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 2, 'm...</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755365</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.816771</td>\n",
       "      <td>0.039098</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.012542</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000374</td>\n",
       "      <td>random</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 2, ...</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.823601</td>\n",
       "      <td>0.026823</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.034414</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.001207</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>best</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 3, 'm...</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746781</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.790598</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.818476</td>\n",
       "      <td>0.037935</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.011175</td>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>random</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 3, ...</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.807931</td>\n",
       "      <td>0.033351</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.031073</td>\n",
       "      <td>0.004539</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>best</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'best', 'min_samples_leaf': 4, 'm...</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.725322</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>0.880342</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.862661</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.815054</td>\n",
       "      <td>0.040598</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.010144</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>0.001267</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>random</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>entropy</td>\n",
       "      <td>{'splitter': 'random', 'min_samples_leaf': 4, ...</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.814199</td>\n",
       "      <td>0.029468</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.013529      0.002957         0.001409        0.000601   \n",
       "1        0.005404      0.001093         0.001000        0.000245   \n",
       "2        0.013018      0.002847         0.001193        0.000176   \n",
       "3        0.006497      0.001823         0.001706        0.001761   \n",
       "4        0.013622      0.002056         0.001236        0.000220   \n",
       "5        0.006401      0.000354         0.001139        0.000096   \n",
       "6        0.011536      0.002078         0.001109        0.000208   \n",
       "7        0.005277      0.000813         0.000992        0.000216   \n",
       "8        0.029272      0.005057         0.001365        0.000287   \n",
       "9        0.011556      0.002577         0.001679        0.001618   \n",
       "10       0.027574      0.003686         0.001290        0.000338   \n",
       "11       0.010135      0.001202         0.001194        0.000270   \n",
       "12       0.026547      0.003886         0.001434        0.000521   \n",
       "13       0.010060      0.001546         0.001128        0.000240   \n",
       "14       0.026192      0.003103         0.001316        0.000211   \n",
       "15       0.010790      0.001583         0.001220        0.000186   \n",
       "16       0.015973      0.003134         0.001246        0.000377   \n",
       "17       0.006672      0.001687         0.001150        0.000187   \n",
       "18       0.016651      0.004608         0.001243        0.000193   \n",
       "19       0.005220      0.000744         0.000991        0.000201   \n",
       "20       0.013769      0.002233         0.001441        0.001709   \n",
       "21       0.005151      0.000802         0.000898        0.000166   \n",
       "22       0.015042      0.003867         0.001196        0.000167   \n",
       "23       0.005833      0.001539         0.001019        0.000250   \n",
       "24       0.036111      0.005470         0.001198        0.000167   \n",
       "25       0.011570      0.002279         0.001040        0.000162   \n",
       "26       0.036049      0.003900         0.001202        0.000183   \n",
       "27       0.012542      0.001617         0.001258        0.000374   \n",
       "28       0.034414      0.002919         0.001207        0.000199   \n",
       "29       0.011175      0.001450         0.001152        0.000207   \n",
       "30       0.031073      0.004539         0.001096        0.000134   \n",
       "31       0.010144      0.001089         0.001267        0.000362   \n",
       "\n",
       "   param_splitter param_min_samples_leaf param_max_depth param_criterion  \\\n",
       "0            best                      1               3            gini   \n",
       "1          random                      1               3            gini   \n",
       "2            best                      2               3            gini   \n",
       "3          random                      2               3            gini   \n",
       "4            best                      3               3            gini   \n",
       "5          random                      3               3            gini   \n",
       "6            best                      4               3            gini   \n",
       "7          random                      4               3            gini   \n",
       "8            best                      1            None            gini   \n",
       "9          random                      1            None            gini   \n",
       "10           best                      2            None            gini   \n",
       "11         random                      2            None            gini   \n",
       "12           best                      3            None            gini   \n",
       "13         random                      3            None            gini   \n",
       "14           best                      4            None            gini   \n",
       "15         random                      4            None            gini   \n",
       "16           best                      1               3         entropy   \n",
       "17         random                      1               3         entropy   \n",
       "18           best                      2               3         entropy   \n",
       "19         random                      2               3         entropy   \n",
       "20           best                      3               3         entropy   \n",
       "21         random                      3               3         entropy   \n",
       "22           best                      4               3         entropy   \n",
       "23         random                      4               3         entropy   \n",
       "24           best                      1            None         entropy   \n",
       "25         random                      1            None         entropy   \n",
       "26           best                      2            None         entropy   \n",
       "27         random                      2            None         entropy   \n",
       "28           best                      3            None         entropy   \n",
       "29         random                      3            None         entropy   \n",
       "30           best                      4            None         entropy   \n",
       "31         random                      4            None         entropy   \n",
       "\n",
       "                                               params  split0_test_score  ...  \\\n",
       "0   {'splitter': 'best', 'min_samples_leaf': 1, 'm...           0.410256  ...   \n",
       "1   {'splitter': 'random', 'min_samples_leaf': 1, ...           0.431624  ...   \n",
       "2   {'splitter': 'best', 'min_samples_leaf': 2, 'm...           0.410256  ...   \n",
       "3   {'splitter': 'random', 'min_samples_leaf': 2, ...           0.397436  ...   \n",
       "4   {'splitter': 'best', 'min_samples_leaf': 3, 'm...           0.410256  ...   \n",
       "5   {'splitter': 'random', 'min_samples_leaf': 3, ...           0.431624  ...   \n",
       "6   {'splitter': 'best', 'min_samples_leaf': 4, 'm...           0.410256  ...   \n",
       "7   {'splitter': 'random', 'min_samples_leaf': 4, ...           0.517094  ...   \n",
       "8   {'splitter': 'best', 'min_samples_leaf': 1, 'm...           0.786325  ...   \n",
       "9   {'splitter': 'random', 'min_samples_leaf': 1, ...           0.777778  ...   \n",
       "10  {'splitter': 'best', 'min_samples_leaf': 2, 'm...           0.764957  ...   \n",
       "11  {'splitter': 'random', 'min_samples_leaf': 2, ...           0.799145  ...   \n",
       "12  {'splitter': 'best', 'min_samples_leaf': 3, 'm...           0.756410  ...   \n",
       "13  {'splitter': 'random', 'min_samples_leaf': 3, ...           0.756410  ...   \n",
       "14  {'splitter': 'best', 'min_samples_leaf': 4, 'm...           0.730769  ...   \n",
       "15  {'splitter': 'random', 'min_samples_leaf': 4, ...           0.739316  ...   \n",
       "16  {'splitter': 'best', 'min_samples_leaf': 1, 'm...           0.495726  ...   \n",
       "17  {'splitter': 'random', 'min_samples_leaf': 1, ...           0.491453  ...   \n",
       "18  {'splitter': 'best', 'min_samples_leaf': 2, 'm...           0.495726  ...   \n",
       "19  {'splitter': 'random', 'min_samples_leaf': 2, ...           0.508547  ...   \n",
       "20  {'splitter': 'best', 'min_samples_leaf': 3, 'm...           0.495726  ...   \n",
       "21  {'splitter': 'random', 'min_samples_leaf': 3, ...           0.559829  ...   \n",
       "22  {'splitter': 'best', 'min_samples_leaf': 4, 'm...           0.495726  ...   \n",
       "23  {'splitter': 'random', 'min_samples_leaf': 4, ...           0.525641  ...   \n",
       "24  {'splitter': 'best', 'min_samples_leaf': 1, 'm...           0.782051  ...   \n",
       "25  {'splitter': 'random', 'min_samples_leaf': 1, ...           0.799145  ...   \n",
       "26  {'splitter': 'best', 'min_samples_leaf': 2, 'm...           0.782051  ...   \n",
       "27  {'splitter': 'random', 'min_samples_leaf': 2, ...           0.820513  ...   \n",
       "28  {'splitter': 'best', 'min_samples_leaf': 3, 'm...           0.773504  ...   \n",
       "29  {'splitter': 'random', 'min_samples_leaf': 3, ...           0.756410  ...   \n",
       "30  {'splitter': 'best', 'min_samples_leaf': 4, 'm...           0.777778  ...   \n",
       "31  {'splitter': 'random', 'min_samples_leaf': 4, ...           0.807692  ...   \n",
       "\n",
       "    split8_test_score  split9_test_score  split10_test_score  \\\n",
       "0            0.472103           0.467811            0.423077   \n",
       "1            0.519313           0.519313            0.495726   \n",
       "2            0.472103           0.472103            0.423077   \n",
       "3            0.523605           0.459227            0.482906   \n",
       "4            0.472103           0.467811            0.423077   \n",
       "5            0.502146           0.463519            0.410256   \n",
       "6            0.472103           0.472103            0.423077   \n",
       "7            0.493562           0.437768            0.461538   \n",
       "8            0.763948           0.763948            0.794872   \n",
       "9            0.772532           0.884120            0.799145   \n",
       "10           0.768240           0.755365            0.786325   \n",
       "11           0.793991           0.811159            0.743590   \n",
       "12           0.751073           0.759657            0.773504   \n",
       "13           0.824034           0.832618            0.799145   \n",
       "14           0.751073           0.746781            0.769231   \n",
       "15           0.789700           0.789700            0.777778   \n",
       "16           0.532189           0.566524            0.559829   \n",
       "17           0.532189           0.497854            0.478632   \n",
       "18           0.532189           0.566524            0.559829   \n",
       "19           0.463519           0.532189            0.508547   \n",
       "20           0.532189           0.566524            0.559829   \n",
       "21           0.463519           0.532189            0.589744   \n",
       "22           0.532189           0.566524            0.559829   \n",
       "23           0.527897           0.545064            0.474359   \n",
       "24           0.768240           0.815451            0.773504   \n",
       "25           0.828326           0.858369            0.837607   \n",
       "26           0.755365           0.802575            0.760684   \n",
       "27           0.819742           0.768240            0.816239   \n",
       "28           0.746781           0.828326            0.782051   \n",
       "29           0.772532           0.832618            0.782051   \n",
       "30           0.725322           0.819742            0.764957   \n",
       "31           0.763948           0.836910            0.858974   \n",
       "\n",
       "    split11_test_score  split12_test_score  split13_test_score  \\\n",
       "0             0.452991            0.465812            0.493562   \n",
       "1             0.542735            0.478632            0.489270   \n",
       "2             0.452991            0.465812            0.493562   \n",
       "3             0.551282            0.555556            0.416309   \n",
       "4             0.452991            0.465812            0.493562   \n",
       "5             0.440171            0.572650            0.506438   \n",
       "6             0.452991            0.465812            0.493562   \n",
       "7             0.529915            0.495726            0.467811   \n",
       "8             0.854701            0.841880            0.862661   \n",
       "9             0.858974            0.799145            0.828326   \n",
       "10            0.837607            0.837607            0.854077   \n",
       "11            0.811966            0.829060            0.819742   \n",
       "12            0.824786            0.816239            0.828326   \n",
       "13            0.782051            0.829060            0.858369   \n",
       "14            0.811966            0.816239            0.836910   \n",
       "15            0.790598            0.829060            0.785408   \n",
       "16            0.576923            0.581197            0.549356   \n",
       "17            0.478632            0.512821            0.433476   \n",
       "18            0.576923            0.581197            0.549356   \n",
       "19            0.517094            0.551282            0.523605   \n",
       "20            0.576923            0.581197            0.549356   \n",
       "21            0.564103            0.564103            0.553648   \n",
       "22            0.576923            0.581197            0.549356   \n",
       "23            0.512821            0.508547            0.532189   \n",
       "24            0.884615            0.794872            0.832618   \n",
       "25            0.820513            0.850427            0.841202   \n",
       "26            0.910256            0.782051            0.841202   \n",
       "27            0.816239            0.850427            0.836910   \n",
       "28            0.897436            0.790598            0.849785   \n",
       "29            0.799145            0.816239            0.832618   \n",
       "30            0.880342            0.773504            0.862661   \n",
       "31            0.807692            0.782051            0.832618   \n",
       "\n",
       "    split14_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0             0.442060         0.452941        0.025060               31  \n",
       "1             0.480687         0.495466        0.043511               25  \n",
       "2             0.446352         0.453514        0.025147               29  \n",
       "3             0.493562         0.478899        0.047122               28  \n",
       "4             0.442060         0.452941        0.025060               31  \n",
       "5             0.506438         0.480023        0.049381               27  \n",
       "6             0.446352         0.453514        0.025147               29  \n",
       "7             0.480687         0.489113        0.036240               26  \n",
       "8             0.806867         0.818747        0.032519                5  \n",
       "9             0.802575         0.822774        0.032455                4  \n",
       "10            0.768240         0.807903        0.032118               13  \n",
       "11            0.875536         0.809943        0.032042               11  \n",
       "12            0.781116         0.799626        0.030002               15  \n",
       "13            0.819742         0.813378        0.028521               10  \n",
       "14            0.789700         0.799056        0.037100               16  \n",
       "15            0.781116         0.801643        0.031105               14  \n",
       "16            0.545064         0.554508        0.023036               17  \n",
       "17            0.600858         0.521117        0.044243               22  \n",
       "18            0.545064         0.554508        0.023036               17  \n",
       "19            0.519313         0.519099        0.026562               23  \n",
       "20            0.545064         0.554508        0.023036               17  \n",
       "21            0.536481         0.541619        0.045123               21  \n",
       "22            0.545064         0.554508        0.023036               17  \n",
       "23            0.506438         0.518009        0.031863               24  \n",
       "24            0.815451         0.825903        0.037466                2  \n",
       "25            0.793991         0.830767        0.016667                1  \n",
       "26            0.806867         0.816771        0.039098                7  \n",
       "27            0.789700         0.823601        0.026823                3  \n",
       "28            0.798283         0.818476        0.037935                6  \n",
       "29            0.849785         0.807931        0.033351               12  \n",
       "30            0.789700         0.815054        0.040598                8  \n",
       "31            0.751073         0.814199        0.029468                9  \n",
       "\n",
       "[32 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "DT_model = DecisionTreeClassifier()\n",
    "\n",
    "DT_params = dict()\n",
    "DT_params['max_depth'] = [3, None]\n",
    "DT_params['min_samples_leaf'] = [1, 2, 3, 4]\n",
    "DT_params['criterion'] = [\"gini\", \"entropy\"]\n",
    "DT_params['splitter'] = [\"best\", \"random\"]\n",
    "\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "RCV = RandomizedSearchCV(DT_model, DT_params, n_iter=50, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "DT = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(DT.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920513f8",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification par boosting de gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "156f4de0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>split8_test_score</th>\n",
       "      <th>split9_test_score</th>\n",
       "      <th>split10_test_score</th>\n",
       "      <th>split11_test_score</th>\n",
       "      <th>split12_test_score</th>\n",
       "      <th>split13_test_score</th>\n",
       "      <th>split14_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.321370</td>\n",
       "      <td>0.013692</td>\n",
       "      <td>0.001676</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 3, 'learning_...</td>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.790598</td>\n",
       "      <td>0.755365</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.768271</td>\n",
       "      <td>0.022569</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.230638</td>\n",
       "      <td>0.054162</td>\n",
       "      <td>0.002291</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 3, 'learning...</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.827339</td>\n",
       "      <td>0.026545</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.015413</td>\n",
       "      <td>0.082584</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862661</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.890681</td>\n",
       "      <td>0.025456</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.481627</td>\n",
       "      <td>0.021382</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 5, 'learning_...</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.793991</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.814796</td>\n",
       "      <td>0.025827</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.027705</td>\n",
       "      <td>0.049751</td>\n",
       "      <td>0.002997</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 5, 'learning...</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.842473</td>\n",
       "      <td>0.023561</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.953583</td>\n",
       "      <td>0.113209</td>\n",
       "      <td>0.009817</td>\n",
       "      <td>0.001344</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.892704</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.877003</td>\n",
       "      <td>0.024551</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.671573</td>\n",
       "      <td>0.033080</td>\n",
       "      <td>0.001811</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 7, 'learning_...</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.820488</td>\n",
       "      <td>0.024931</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.146465</td>\n",
       "      <td>0.234148</td>\n",
       "      <td>0.003923</td>\n",
       "      <td>0.001544</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 7, 'learning...</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.835613</td>\n",
       "      <td>0.025791</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>16.270429</td>\n",
       "      <td>0.955499</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>0.003109</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 7, 'learnin...</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.852178</td>\n",
       "      <td>0.021681</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.294750</td>\n",
       "      <td>0.025379</td>\n",
       "      <td>0.001505</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 3, 'learning_...</td>\n",
       "      <td>0.790598</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>...</td>\n",
       "      <td>0.836910</td>\n",
       "      <td>0.871245</td>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.858730</td>\n",
       "      <td>0.026146</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.238560</td>\n",
       "      <td>0.104194</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 3, 'learning...</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.931624</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.892704</td>\n",
       "      <td>0.917806</td>\n",
       "      <td>0.018633</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.439002</td>\n",
       "      <td>0.264916</td>\n",
       "      <td>0.007417</td>\n",
       "      <td>0.001539</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.965812</td>\n",
       "      <td>0.965665</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.955480</td>\n",
       "      <td>0.010684</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.512772</td>\n",
       "      <td>0.044005</td>\n",
       "      <td>0.001970</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 5, 'learning_...</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.862661</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.862661</td>\n",
       "      <td>0.862661</td>\n",
       "      <td>0.853320</td>\n",
       "      <td>0.022929</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.262773</td>\n",
       "      <td>0.098389</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 5, 'learning...</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.888412</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.901709</td>\n",
       "      <td>0.901288</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.895823</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10.027575</td>\n",
       "      <td>0.515363</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.001152</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.901288</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.952790</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.938643</td>\n",
       "      <td>0.015453</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.656812</td>\n",
       "      <td>0.014964</td>\n",
       "      <td>0.001699</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 7, 'learning_...</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>...</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.845494</td>\n",
       "      <td>0.828210</td>\n",
       "      <td>0.022251</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.780563</td>\n",
       "      <td>0.032487</td>\n",
       "      <td>0.003690</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 7, 'learning...</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.841880</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.858369</td>\n",
       "      <td>0.866953</td>\n",
       "      <td>0.848753</td>\n",
       "      <td>0.015109</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12.092438</td>\n",
       "      <td>0.219762</td>\n",
       "      <td>0.012214</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 7, 'learnin...</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>...</td>\n",
       "      <td>0.862661</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.884120</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.886706</td>\n",
       "      <td>0.021723</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.280384</td>\n",
       "      <td>0.008510</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 3, 'learning_...</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.854077</td>\n",
       "      <td>0.863248</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.828326</td>\n",
       "      <td>0.858718</td>\n",
       "      <td>0.026587</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.139732</td>\n",
       "      <td>0.013471</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 3, 'learning...</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.896996</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.799863</td>\n",
       "      <td>0.294242</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.363769</td>\n",
       "      <td>1.353422</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.888412</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.925478</td>\n",
       "      <td>0.047249</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.510680</td>\n",
       "      <td>0.012819</td>\n",
       "      <td>0.001688</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 5, 'learning_...</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.867521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>0.888412</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.854701</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.892704</td>\n",
       "      <td>0.901288</td>\n",
       "      <td>0.881577</td>\n",
       "      <td>0.020497</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.594160</td>\n",
       "      <td>0.216926</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>0.000381</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 5, 'learning...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.952991</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.927039</td>\n",
       "      <td>0.876006</td>\n",
       "      <td>0.191255</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.445487</td>\n",
       "      <td>1.058634</td>\n",
       "      <td>0.003318</td>\n",
       "      <td>0.000595</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.935897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.918455</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.914163</td>\n",
       "      <td>0.922747</td>\n",
       "      <td>0.933490</td>\n",
       "      <td>0.013776</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.675762</td>\n",
       "      <td>0.046098</td>\n",
       "      <td>0.001823</td>\n",
       "      <td>0.000130</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 7, 'learning_...</td>\n",
       "      <td>0.871795</td>\n",
       "      <td>0.914530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888412</td>\n",
       "      <td>0.896996</td>\n",
       "      <td>0.893162</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>0.906676</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.192446</td>\n",
       "      <td>0.052432</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 7, 'learning...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.879828</td>\n",
       "      <td>0.944206</td>\n",
       "      <td>0.918803</td>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.940171</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>0.935622</td>\n",
       "      <td>0.921517</td>\n",
       "      <td>0.018497</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2.054611</td>\n",
       "      <td>0.167328</td>\n",
       "      <td>0.003341</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 7, 'learnin...</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>0.948498</td>\n",
       "      <td>0.905983</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.909871</td>\n",
       "      <td>0.931330</td>\n",
       "      <td>0.923806</td>\n",
       "      <td>0.012890</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.338072</td>\n",
       "      <td>0.014886</td>\n",
       "      <td>0.001686</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 3, 'learning_...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081545</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.004292</td>\n",
       "      <td>0.274678</td>\n",
       "      <td>0.151223</td>\n",
       "      <td>0.095660</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1.241186</td>\n",
       "      <td>0.112691</td>\n",
       "      <td>0.002194</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 3, 'learning...</td>\n",
       "      <td>0.072650</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.064378</td>\n",
       "      <td>0.085837</td>\n",
       "      <td>0.226496</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.135259</td>\n",
       "      <td>0.085309</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>7.266024</td>\n",
       "      <td>0.735404</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.000727</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 3, 'learnin...</td>\n",
       "      <td>0.072650</td>\n",
       "      <td>0.059829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081545</td>\n",
       "      <td>0.270386</td>\n",
       "      <td>0.209402</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.193133</td>\n",
       "      <td>0.266094</td>\n",
       "      <td>0.155829</td>\n",
       "      <td>0.081599</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.462138</td>\n",
       "      <td>0.090062</td>\n",
       "      <td>0.001619</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 5, 'learning_...</td>\n",
       "      <td>0.226496</td>\n",
       "      <td>0.226496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.759657</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.401709</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.698207</td>\n",
       "      <td>0.211206</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1.172363</td>\n",
       "      <td>0.528563</td>\n",
       "      <td>0.001948</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 5, 'learning...</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>...</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.029915</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.704231</td>\n",
       "      <td>0.248119</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4.094484</td>\n",
       "      <td>2.726701</td>\n",
       "      <td>0.004982</td>\n",
       "      <td>0.004290</td>\n",
       "      <td>100</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 5, 'learnin...</td>\n",
       "      <td>0.649573</td>\n",
       "      <td>0.094017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.763948</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.047009</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.841202</td>\n",
       "      <td>0.646445</td>\n",
       "      <td>0.295788</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.193680</td>\n",
       "      <td>0.027148</td>\n",
       "      <td>0.001258</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 5, 'max_depth': 7, 'learning_...</td>\n",
       "      <td>0.739316</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.733906</td>\n",
       "      <td>0.811159</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.788822</td>\n",
       "      <td>0.027965</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.381831</td>\n",
       "      <td>0.079485</td>\n",
       "      <td>0.001491</td>\n",
       "      <td>0.000071</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 20, 'max_depth': 7, 'learning...</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.712446</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.803419</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.782528</td>\n",
       "      <td>0.028415</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.302670</td>\n",
       "      <td>0.214760</td>\n",
       "      <td>0.002113</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>100</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 7, 'learnin...</td>\n",
       "      <td>0.726496</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751073</td>\n",
       "      <td>0.776824</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.815451</td>\n",
       "      <td>0.789700</td>\n",
       "      <td>0.783965</td>\n",
       "      <td>0.026287</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_n_estimators param_max_depth param_learning_rate                                             params  split0_test_score  split1_test_score  ...  split8_test_score  split9_test_score  split10_test_score  split11_test_score  split12_test_score  split13_test_score  split14_test_score  mean_test_score  std_test_score  rank_test_score\n",
       "0        0.321370      0.013692         0.001676        0.000464                  5               3                0.01  {'n_estimators': 5, 'max_depth': 3, 'learning_...           0.705128           0.777778  ...           0.751073           0.798283            0.760684            0.756410            0.790598            0.755365            0.751073         0.768271        0.022569               30\n",
       "1        1.230638      0.054162         0.002291        0.000401                 20               3                0.01  {'n_estimators': 20, 'max_depth': 3, 'learning...           0.756410           0.837607  ...           0.811159           0.841202            0.824786            0.811966            0.867521            0.802575            0.806867         0.827339        0.026545               23\n",
       "2        6.015413      0.082584         0.007531        0.001484                100               3                0.01  {'n_estimators': 100, 'max_depth': 3, 'learnin...           0.841880           0.901709  ...           0.862661           0.909871            0.876068            0.897436            0.901709            0.884120            0.841202         0.890681        0.025456               10\n",
       "3        0.481627      0.021382         0.001539        0.000264                  5               5                0.01  {'n_estimators': 5, 'max_depth': 5, 'learning_...           0.743590           0.803419  ...           0.793991           0.819742            0.811966            0.782051            0.837607            0.815451            0.815451         0.814796        0.025827               25\n",
       "4        2.027705      0.049751         0.002997        0.000342                 20               5                0.01  {'n_estimators': 20, 'max_depth': 5, 'learning...           0.782051           0.833333  ...           0.811159           0.841202            0.833333            0.846154            0.858974            0.845494            0.832618         0.842473        0.023561               20\n",
       "5        9.953583      0.113209         0.009817        0.001344                100               5                0.01  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.816239           0.867521  ...           0.841202           0.884120            0.871795            0.888889            0.863248            0.892704            0.871245         0.877003        0.024551               13\n",
       "6        0.671573      0.033080         0.001811        0.000307                  5               7                0.01  {'n_estimators': 5, 'max_depth': 7, 'learning_...           0.760684           0.799145  ...           0.789700           0.832618            0.833333            0.807692            0.846154            0.841202            0.802575         0.820488        0.024931               24\n",
       "7        3.146465      0.234148         0.003923        0.001544                 20               7                0.01  {'n_estimators': 20, 'max_depth': 7, 'learning...           0.782051           0.820513  ...           0.798283           0.845494            0.854701            0.829060            0.863248            0.832618            0.802575         0.835613        0.025791               21\n",
       "8       16.270429      0.955499         0.015479        0.003109                100               7                0.01  {'n_estimators': 100, 'max_depth': 7, 'learnin...           0.786325           0.833333  ...           0.832618           0.854077            0.863248            0.850427            0.867521            0.866953            0.849785         0.852178        0.021681               18\n",
       "9        0.294750      0.025379         0.001505        0.000131                  5               3                 0.1  {'n_estimators': 5, 'max_depth': 3, 'learning_...           0.790598           0.854701  ...           0.836910           0.871245            0.858974            0.871795            0.893162            0.841202            0.841202         0.858730        0.026146               15\n",
       "10       1.238560      0.104194         0.002384        0.000489                 20               3                 0.1  {'n_estimators': 20, 'max_depth': 3, 'learning...           0.871795           0.931624  ...           0.918455           0.918455            0.897436            0.923077            0.931624            0.931330            0.892704         0.917806        0.018633                7\n",
       "11       6.439002      0.264916         0.007417        0.001539                100               3                 0.1  {'n_estimators': 100, 'max_depth': 3, 'learnin...           0.961538           0.952991  ...           0.944206           0.952790            0.935897            0.952991            0.965812            0.965665            0.948498         0.955480        0.010684                1\n",
       "12       0.512772      0.044005         0.001970        0.000867                  5               5                 0.1  {'n_estimators': 5, 'max_depth': 5, 'learning_...           0.807692           0.850427  ...           0.815451           0.862661            0.841880            0.871795            0.837607            0.862661            0.862661         0.853320        0.022929               17\n",
       "13       2.262773      0.098389         0.005052        0.002492                 20               5                 0.1  {'n_estimators': 20, 'max_depth': 5, 'learning...           0.837607           0.897436  ...           0.849785           0.888412            0.897436            0.910256            0.901709            0.901288            0.884120         0.895823        0.023100                9\n",
       "14      10.027575      0.515363         0.010908        0.001152                100               5                 0.1  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.905983           0.948718  ...           0.901288           0.952790            0.923077            0.944444            0.948718            0.952790            0.944206         0.938643        0.015453                2\n",
       "15       0.656812      0.014964         0.001699        0.000150                  5               7                 0.1  {'n_estimators': 5, 'max_depth': 7, 'learning_...           0.769231           0.807692  ...           0.806867           0.849785            0.837607            0.820513            0.850427            0.824034            0.845494         0.828210        0.022251               22\n",
       "16       2.780563      0.032487         0.003690        0.000188                 20               7                 0.1  {'n_estimators': 20, 'max_depth': 7, 'learning...           0.811966           0.846154  ...           0.828326           0.854077            0.841880            0.841880            0.854701            0.858369            0.866953         0.848753        0.015109               19\n",
       "17      12.092438      0.219762         0.012214        0.000338                100               7                 0.1  {'n_estimators': 100, 'max_depth': 7, 'learnin...           0.829060           0.897436  ...           0.862661           0.879828            0.876068            0.884615            0.914530            0.884120            0.918455         0.886706        0.021723               11\n",
       "18       0.280384      0.008510         0.001335        0.000128                  5               3                   1  {'n_estimators': 5, 'max_depth': 3, 'learning_...           0.786325           0.893162  ...           0.841202           0.854077            0.863248            0.871795            0.888889            0.832618            0.828326         0.858718        0.026587               16\n",
       "19       1.139732      0.013471         0.002347        0.000365                 20               3                   1  {'n_estimators': 20, 'max_depth': 3, 'learning...           0.064103           0.935897  ...           0.918455           0.896996            0.923077            0.923077            0.914530            0.918455            0.811159         0.799863        0.294242               26\n",
       "20       3.363769      1.353422         0.005049        0.002478                100               3                   1  {'n_estimators': 100, 'max_depth': 3, 'learnin...           0.897436           0.948718  ...           0.931330           0.888412            0.948718            0.940171            0.948718            0.939914            0.763948         0.925478        0.047249                4\n",
       "21       0.510680      0.012819         0.001688        0.000215                  5               5                   1  {'n_estimators': 5, 'max_depth': 5, 'learning_...           0.820513           0.867521  ...           0.879828           0.888412            0.884615            0.854701            0.893162            0.892704            0.901288         0.881577        0.020497               12\n",
       "22       1.594160      0.216926         0.002905        0.000381                 20               5                   1  {'n_estimators': 20, 'max_depth': 5, 'learning...           0.888889           0.952991  ...           0.927039           0.905579            0.918803            0.910256            0.952991            0.927039            0.927039         0.876006        0.191255               14\n",
       "23       2.445487      1.058634         0.003318        0.000595                100               5                   1  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.923077           0.935897  ...           0.918455           0.918455            0.918803            0.944444            0.961538            0.914163            0.922747         0.933490        0.013776                3\n",
       "24       0.675762      0.046098         0.001823        0.000130                  5               7                   1  {'n_estimators': 5, 'max_depth': 7, 'learning_...           0.871795           0.914530  ...           0.888412           0.896996            0.893162            0.905983            0.918803            0.905579            0.909871         0.906676        0.014520                8\n",
       "25       1.192446      0.052432         0.002320        0.000139                 20               7                   1  {'n_estimators': 20, 'max_depth': 7, 'learning...           0.888889           0.923077  ...           0.879828           0.944206            0.918803            0.910256            0.940171            0.909871            0.935622         0.921517        0.018497                6\n",
       "26       2.054611      0.167328         0.003341        0.000451                100               7                   1  {'n_estimators': 100, 'max_depth': 7, 'learnin...           0.905983           0.923077  ...           0.909871           0.948498            0.905983            0.923077            0.944444            0.909871            0.931330         0.923806        0.012890                5\n",
       "27       0.338072      0.014886         0.001686        0.000152                  5               3                  10  {'n_estimators': 5, 'max_depth': 3, 'learning_...           0.153846           0.055556  ...           0.081545           0.270386            0.222222            0.192308            0.064103            0.004292            0.274678         0.151223        0.095660               35\n",
       "28       1.241186      0.112691         0.002194        0.000154                 20               3                  10  {'n_estimators': 20, 'max_depth': 3, 'learning...           0.072650           0.059829  ...           0.064378           0.085837            0.226496            0.192308            0.064103            0.193133            0.266094         0.135259        0.085309               36\n",
       "29       7.266024      0.735404         0.005565        0.000727                100               3                  10  {'n_estimators': 100, 'max_depth': 3, 'learnin...           0.072650           0.059829  ...           0.081545           0.270386            0.209402            0.192308            0.064103            0.193133            0.266094         0.155829        0.081599               34\n",
       "30       0.462138      0.090062         0.001619        0.000163                  5               5                  10  {'n_estimators': 5, 'max_depth': 5, 'learning_...           0.226496           0.226496  ...           0.772532           0.759657            0.829060            0.401709            0.811966            0.781116            0.819742         0.698207        0.211206               32\n",
       "31       1.172363      0.528563         0.001948        0.000410                 20               5                  10  {'n_estimators': 20, 'max_depth': 5, 'learning...           0.641026           0.141026  ...           0.772532           0.798283            0.811966            0.029915            0.816239            0.772532            0.849785         0.704231        0.248119               31\n",
       "32       4.094484      2.726701         0.004982        0.004290                100               5                  10  {'n_estimators': 100, 'max_depth': 5, 'learnin...           0.649573           0.094017  ...           0.763948           0.789700            0.820513            0.047009            0.807692            0.781116            0.841202         0.646445        0.295788               33\n",
       "33       0.193680      0.027148         0.001258        0.000115                  5               7                  10  {'n_estimators': 5, 'max_depth': 7, 'learning_...           0.739316           0.760684  ...           0.733906           0.811159            0.803419            0.769231            0.816239            0.802575            0.815451         0.788822        0.027965               27\n",
       "34       0.381831      0.079485         0.001491        0.000071                 20               7                  10  {'n_estimators': 20, 'max_depth': 7, 'learning...           0.752137           0.782051  ...           0.712446           0.789700            0.803419            0.756410            0.829060            0.789700            0.781116         0.782528        0.028415               29\n",
       "35       1.302670      0.214760         0.002113        0.000315                100               7                  10  {'n_estimators': 100, 'max_depth': 7, 'learnin...           0.726496           0.777778  ...           0.751073           0.776824            0.799145            0.752137            0.807692            0.815451            0.789700         0.783965        0.026287               28\n",
       "\n",
       "[36 rows x 26 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "GB_model = GradientBoostingClassifier()\n",
    "GB_params = dict()\n",
    "GB_params['n_estimators'] = [5, 20, 100]\n",
    "GB_params['max_depth'] = [3, 5, 7]\n",
    "GB_params['learning_rate'] = [0.01, 0.1, 1, 10]\n",
    "\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(GB_model, GB_params, n_iter=36, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "GB = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(GB.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0a7b4",
   "metadata": {},
   "source": [
    "Pour améliorer la précision de notre modèle, nous pouvons faire varrier les trois paramètes suivants :\n",
    "* Le nombre d'estimation\n",
    "* La profondeur maximale\n",
    "* Le taux d'apprentissage\n",
    "\n",
    "#### Le nombre d'estimation\n",
    "\n",
    "Ce paramètre permet de jouer sur le nombre d'arbre du modèle.\n",
    "Plus ce paramètre est élevé, plus le modèle est précis.\n",
    "\n",
    "Néanmoins, une valeur trop élevé peut causer des problèmes de performance lors de l'apprentissage.\n",
    "\n",
    "#### La profondeur maximale\n",
    "\n",
    "Cette valeur définit la profondeur des arbres utilisé.\n",
    "\n",
    "Il est important de choisir une profondeur adaptée à notre jeu d'entrainement au risque de faire de l'`over fitting`.\n",
    "\n",
    "#### Le taux d'apprentissage\n",
    "\n",
    "Il permet d'éviter l'`under fitting` et l'`over fitting`.\n",
    "Un taux d'apprentissage trop élevé pourrait amener à de l'`over fitting` et donc un mauvais résultat avec le jeu de test.\n",
    "A l'inverse, un taux d'apprentissage trop faible conduirait à de l'`under fitting`.\n",
    "\n",
    "---\n",
    "\n",
    "> Source : [https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae](https://medium.com/all-things-ai/in-depth-parameter-tuning-for-gradient-boosting-3363992e9bae)\n",
    "\n",
    "---\n",
    "\n",
    "### Analyse des résultats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "672fd335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.961188</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.960900</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_n_estimators param_max_depth param_learning_rate  mean_test_score  rank_test_score\n",
       "1               2000               3                 0.1         0.961188                1\n",
       "0               1000               3                 0.1         0.960900                2"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results[[\"param_n_estimators\",\"param_max_depth\",\"param_learning_rate\",\"mean_test_score\",\"rank_test_score\"]].sort_values(\"rank_test_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01da5b57",
   "metadata": {},
   "source": [
    "Le meilleur résultat semble être avec la configuration suivante :\n",
    "\n",
    "|  Paramètre  | Valeur  |\n",
    "|---|---|\n",
    "| n_estimators |  100 |\n",
    "| max_depth  | 3  |\n",
    "|  learning_rate | 0.1  |\n",
    "\n",
    "> Nous avons essayé d'augmenté *le nombre d'itération* mais cela a un impacte négligeable sur le résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec81b5f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Classification par voisin le plus proche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ea8ff5f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "KNN_model = KNeighborsClassifier()\n",
    "\n",
    "KNN_params = dict()\n",
    "KNN_params['n_neighbors'] = [i for i in range(1, 20, 5)]\n",
    "KNN_params['weights'] = [\"uniform\", \"distance\"]\n",
    "KNN_params['algorithm'] = [\"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "KNN_params['leaf_size'] = [1, 10, 30]\n",
    "KNN_params['p'] = [1, 2]\n",
    "\n",
    "kFold = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\n",
    "RCV = RandomizedSearchCV(KNN_model, KNN_params, n_iter=50, scoring='accuracy', n_jobs=-1, cv=kFold, random_state=1)\n",
    "\n",
    "KNN = RCV.fit(x_train, y_train)\n",
    "cv_results = pd.DataFrame(KNN.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d590819",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Citation :\n",
    "Stephanie Glen. \"Regularization: Simple Definition, L1 & L2 Penalties\" From StatisticsHowTo.com: Elementary Statistics for the rest of us! https://www.statisticshowto.com/regularization/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
